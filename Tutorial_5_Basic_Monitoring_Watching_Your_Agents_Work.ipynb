{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYiRB/coW3QVx5PRWeR8/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/Neuron/blob/main/Tutorial_5_Basic_Monitoring_Watching_Your_Agents_Work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In previous tutorials, you've built agents that can communicate, remember, and make intelligent decisions. Now we're adding comprehensive monitoring so you can see exactly what's happening inside your agent systems in real-time.\n",
        "\n",
        " What you'll build:\n",
        "\n",
        " â€¢ NeuroMonitor system for real-time agent observation\n",
        "\n",
        " â€¢ Performance metrics collection and analysis\n",
        "\n",
        " â€¢ Event logging and trace visualization\n",
        "\n",
        " â€¢ Health monitoring with alerts and notifications\n",
        "\n",
        " â€¢ Interactive debugging dashboard with live updates\n",
        "\n",
        " Why this matters:\n",
        "\n",
        " Production AI systems need observability to debug issues, optimize performance, and ensure reliability. Understanding how to monitor distributed agent systems is crucial for building scalable, maintainable AI applications.\n",
        "\n",
        " By the end, you'll understand:\n",
        "\n",
        " â€¢ How to instrument agent systems for observability\n",
        "\n",
        " â€¢ Real-time monitoring and alerting patterns\n",
        "\n",
        " â€¢ Performance bottleneck identification\n",
        "\n",
        " â€¢ Event correlation and trace analysis\n",
        "\n",
        " â€¢ Building production-ready monitoring dashboards"
      ],
      "metadata": {
        "id": "CRXXoksEkuPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tutorial 5: Basic Monitoring - Watching Your Agents Work\")\n",
        "print(\"=\" * 58)\n",
        "print()\n",
        "print(\"Building comprehensive observability for intelligent agent systems...\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-6y7ruJq2pr",
        "outputId": "65803474-8772-4821-e131-97a1d4ee9da8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 5: Basic Monitoring - Watching Your Agents Work\n",
            "==========================================================\n",
            "\n",
            "Building comprehensive observability for intelligent agent systems...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essential imports\n",
        "import uuid\n",
        "import time\n",
        "import threading\n",
        "import queue\n",
        "import json\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Set, Callable, Tuple\n",
        "from enum import Enum\n",
        "from collections import defaultdict, deque\n",
        "import copy\n",
        "from datetime import datetime, timedelta\n",
        "import statistics"
      ],
      "metadata": {
        "id": "7TPUYI_Pq6AN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our foundation from previous tutorials\n",
        "AgentID = str\n",
        "MessageID = str\n",
        "\n",
        "class MessagePriority(Enum):\n",
        "    LOW = 1\n",
        "    NORMAL = 2\n",
        "    HIGH = 3\n",
        "    URGENT = 4\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    id: MessageID\n",
        "    sender: AgentID\n",
        "    recipients: List[AgentID]\n",
        "    content: Any\n",
        "    priority: MessagePriority = MessagePriority.NORMAL\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "    created_at: float = field(default_factory=time.time)\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, sender: AgentID, recipients: List[AgentID], content: Any,\n",
        "               priority: MessagePriority = MessagePriority.NORMAL) -> 'Message':\n",
        "        return cls(\n",
        "            id=str(uuid.uuid4()),\n",
        "            sender=sender,\n",
        "            recipients=recipients,\n",
        "            content=content,\n",
        "            priority=priority\n",
        "        )\n",
        "\n",
        "class EventType(Enum):\n",
        "    \"\"\"\n",
        "    Different types of events that can occur in the agent system\n",
        "\n",
        "    This provides a structured way to categorize and filter\n",
        "    system events for monitoring and debugging.\n",
        "    \"\"\"\n",
        "    AGENT_STARTED = \"agent_started\"\n",
        "    AGENT_STOPPED = \"agent_stopped\"\n",
        "    MESSAGE_SENT = \"message_sent\"\n",
        "    MESSAGE_RECEIVED = \"message_received\"\n",
        "    MESSAGE_PROCESSED = \"message_processed\"\n",
        "    ERROR_OCCURRED = \"error_occurred\"\n",
        "    PERFORMANCE_ALERT = \"performance_alert\"\n",
        "    CUSTOM_EVENT = \"custom_event\"\n",
        "\n",
        "class AlertLevel(Enum):\n",
        "    \"\"\"Alert severity levels for monitoring system\"\"\"\n",
        "    INFO = 1\n",
        "    WARNING = 2\n",
        "    ERROR = 3\n",
        "    CRITICAL = 4\n",
        "\n",
        "@dataclass\n",
        "class MonitoringEvent:\n",
        "    \"\"\"\n",
        "    A single monitoring event with context and metadata\n",
        "\n",
        "    Events are the basic unit of observability - they capture\n",
        "    what happened, when, and in what context.\n",
        "    \"\"\"\n",
        "    id: str\n",
        "    event_type: EventType\n",
        "    agent_id: AgentID\n",
        "    timestamp: float = field(default_factory=time.time)\n",
        "    data: Dict[str, Any] = field(default_factory=dict)\n",
        "    alert_level: AlertLevel = AlertLevel.INFO\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, event_type: EventType, agent_id: AgentID,\n",
        "               data: Dict[str, Any] = None, alert_level: AlertLevel = AlertLevel.INFO) -> 'MonitoringEvent':\n",
        "        \"\"\"Factory method to create monitoring events\"\"\"\n",
        "        return cls(\n",
        "            id=str(uuid.uuid4()),\n",
        "            event_type=event_type,\n",
        "            agent_id=agent_id,\n",
        "            data=data or {},\n",
        "            alert_level=alert_level\n",
        "        )\n",
        "\n",
        "@dataclass\n",
        "class PerformanceMetrics:\n",
        "    \"\"\"\n",
        "    Performance metrics for an agent or system component\n",
        "    \"\"\"\n",
        "    component_id: str\n",
        "    timestamp: float = field(default_factory=time.time)\n",
        "    messages_processed: int = 0\n",
        "    processing_time_total: float = 0.0\n",
        "    processing_time_avg: float = 0.0\n",
        "    messages_sent: int = 0\n",
        "    messages_received: int = 0\n",
        "    errors_total: int = 0\n",
        "    queue_size: int = 0\n",
        "    uptime_seconds: float = 0.0\n",
        "\n",
        "    def calculate_derived_metrics(self):\n",
        "        \"\"\"Calculate derived metrics from base measurements\"\"\"\n",
        "        if self.messages_processed > 0:\n",
        "            self.processing_time_avg = self.processing_time_total / self.messages_processed\n",
        "\n",
        "class NeuroMonitor:\n",
        "    \"\"\"\n",
        "    Comprehensive monitoring system for agent networks\n",
        "\n",
        "    NeuroMonitor provides real-time observability into agent behavior,\n",
        "    performance metrics, and system health.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_events: int = 1000):\n",
        "        self.events: deque = deque(maxlen=max_events)\n",
        "        self.monitored_agents: Dict[AgentID, 'MonitoredAgent'] = {}\n",
        "        self.metrics: Dict[str, PerformanceMetrics] = {}\n",
        "        self.event_lock = threading.Lock()\n",
        "        self.metrics_lock = threading.Lock()\n",
        "        self.running = False\n",
        "        self.monitor_thread = None\n",
        "\n",
        "        # Statistics\n",
        "        self.system_stats = {\n",
        "            'start_time': time.time(),\n",
        "            'total_events': 0,\n",
        "            'events_by_type': defaultdict(int),\n",
        "            'alerts_by_level': defaultdict(int)\n",
        "        }\n",
        "\n",
        "        print(f\"ğŸ” NeuroMonitor initialized with max {max_events} events\")\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the monitoring system\"\"\"\n",
        "        if self.running:\n",
        "            print(\"âš ï¸  NeuroMonitor is already running\")\n",
        "            return\n",
        "\n",
        "        self.running = True\n",
        "        self.monitor_thread = threading.Thread(\n",
        "            target=self._monitoring_loop,\n",
        "            daemon=True,\n",
        "            name=\"NeuroMonitor\"\n",
        "        )\n",
        "        self.monitor_thread.start()\n",
        "        print(\"â–¶ï¸  NeuroMonitor started\")\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the monitoring system\"\"\"\n",
        "        if not self.running:\n",
        "            return\n",
        "\n",
        "        self.running = False\n",
        "        if self.monitor_thread:\n",
        "            self.monitor_thread.join(timeout=2.0)\n",
        "        print(\"â¹ï¸  NeuroMonitor stopped\")\n",
        "\n",
        "    def register_agent(self, agent: 'MonitoredAgent'):\n",
        "        \"\"\"Register an agent for monitoring\"\"\"\n",
        "        try:\n",
        "            with self.event_lock:\n",
        "                self.monitored_agents[agent.id] = agent\n",
        "\n",
        "                with self.metrics_lock:\n",
        "                    self.metrics[agent.id] = PerformanceMetrics(component_id=agent.id)\n",
        "\n",
        "                print(f\"ğŸ“Š Registered agent for monitoring: {agent.name}\")\n",
        "\n",
        "            # Set monitor after registration to avoid deadlock\n",
        "            agent._set_monitor(self)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error registering agent {agent.name}: {e}\")\n",
        "            # Remove from monitored agents if registration failed\n",
        "            with self.event_lock:\n",
        "                if agent.id in self.monitored_agents:\n",
        "                    del self.monitored_agents[agent.id]\n",
        "            raise\n",
        "\n",
        "    def log_event(self, event: MonitoringEvent):\n",
        "        \"\"\"Log a monitoring event\"\"\"\n",
        "        with self.event_lock:\n",
        "            self.events.append(event)\n",
        "\n",
        "            # Update statistics\n",
        "            self.system_stats['total_events'] += 1\n",
        "            self.system_stats['events_by_type'][event.event_type.value] += 1\n",
        "            self.system_stats['alerts_by_level'][event.alert_level.value] += 1\n",
        "\n",
        "        # Print important events\n",
        "        if event.alert_level in [AlertLevel.WARNING, AlertLevel.ERROR, AlertLevel.CRITICAL]:\n",
        "            level_emoji = {\"WARNING\": \"âš ï¸\", \"ERROR\": \"âŒ\", \"CRITICAL\": \"ğŸš¨\"}\n",
        "            emoji = level_emoji.get(event.alert_level.name, \"ğŸ“Š\")\n",
        "            agent_name = \"Unknown\"\n",
        "            if event.agent_id in self.monitored_agents:\n",
        "                agent_name = self.monitored_agents[event.agent_id].name\n",
        "\n",
        "            print(f\"{emoji} {event.alert_level.name}: {agent_name} - {event.event_type.value}\")\n",
        "\n",
        "    def update_metrics(self, agent_id: AgentID, metrics_update: Dict[str, Any]):\n",
        "        \"\"\"Update performance metrics for an agent\"\"\"\n",
        "        with self.metrics_lock:\n",
        "            if agent_id not in self.metrics:\n",
        "                self.metrics[agent_id] = PerformanceMetrics(component_id=agent_id)\n",
        "\n",
        "            current_metrics = self.metrics[agent_id]\n",
        "            for key, value in metrics_update.items():\n",
        "                if hasattr(current_metrics, key):\n",
        "                    setattr(current_metrics, key, value)\n",
        "\n",
        "            current_metrics.timestamp = time.time()\n",
        "            current_metrics.calculate_derived_metrics()\n",
        "\n",
        "    def get_recent_events(self, count: int = 50) -> List[MonitoringEvent]:\n",
        "        \"\"\"Get recent events\"\"\"\n",
        "        with self.event_lock:\n",
        "            return list(self.events)[-count:]\n",
        "\n",
        "    def get_system_health(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get overall system health summary\"\"\"\n",
        "        with self.metrics_lock:\n",
        "            active_agents = len(self.monitored_agents)\n",
        "            total_messages = sum(m.messages_processed for m in self.metrics.values())\n",
        "            total_errors = sum(m.errors_total for m in self.metrics.values())\n",
        "\n",
        "            avg_processing_times = [m.processing_time_avg for m in self.metrics.values() if m.processing_time_avg > 0]\n",
        "            system_avg_processing = statistics.mean(avg_processing_times) if avg_processing_times else 0.0\n",
        "\n",
        "            uptime = time.time() - self.system_stats['start_time']\n",
        "\n",
        "            return {\n",
        "                'system_uptime_seconds': uptime,\n",
        "                'active_agents': active_agents,\n",
        "                'total_events': self.system_stats['total_events'],\n",
        "                'total_messages_processed': total_messages,\n",
        "                'total_errors': total_errors,\n",
        "                'error_rate': total_errors / max(total_messages, 1),\n",
        "                'average_processing_time': system_avg_processing,\n",
        "                'events_by_type': dict(self.system_stats['events_by_type'])\n",
        "            }\n",
        "\n",
        "    def get_agent_metrics(self, agent_id: AgentID) -> Optional[PerformanceMetrics]:\n",
        "        \"\"\"Get current metrics for a specific agent\"\"\"\n",
        "        with self.metrics_lock:\n",
        "            return self.metrics.get(agent_id)\n",
        "\n",
        "    def _monitoring_loop(self):\n",
        "        \"\"\"Main monitoring loop\"\"\"\n",
        "        print(\"ğŸ”„ NeuroMonitor background loop started\")\n",
        "\n",
        "        while self.running:\n",
        "            try:\n",
        "                # Collect metrics from all agents\n",
        "                for agent_id, agent in self.monitored_agents.items():\n",
        "                    try:\n",
        "                        agent_metrics = agent.get_monitoring_metrics()\n",
        "                        self.update_metrics(agent_id, agent_metrics)\n",
        "\n",
        "                        # Check for performance alerts\n",
        "                        metrics = self.metrics[agent_id]\n",
        "                        if metrics.processing_time_avg > 0.5:  # Alert if avg > 0.5s\n",
        "                            event = MonitoringEvent.create(\n",
        "                                event_type=EventType.PERFORMANCE_ALERT,\n",
        "                                agent_id=agent_id,\n",
        "                                data={'avg_processing_time': metrics.processing_time_avg},\n",
        "                                alert_level=AlertLevel.WARNING\n",
        "                            )\n",
        "                            self.log_event(event)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"âŒ Error collecting metrics for {agent_id[:8]}...: {e}\")\n",
        "\n",
        "                time.sleep(2.0)  # Check every 2 seconds\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error in monitoring loop: {e}\")\n",
        "                time.sleep(1.0)\n",
        "\n",
        "        print(\"ğŸ›‘ NeuroMonitor background loop stopped\")\n",
        "\n",
        "class MonitoredAgent:\n",
        "    \"\"\"\n",
        "    Base class for agents that can be monitored by NeuroMonitor\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id: Optional[AgentID] = None, name: str = \"\"):\n",
        "        self.id = agent_id or str(uuid.uuid4())\n",
        "        self.name = name or self.__class__.__name__\n",
        "\n",
        "        # Message processing\n",
        "        self._message_queue = queue.Queue()\n",
        "        self._stop_event = threading.Event()\n",
        "        self._processing_thread = None\n",
        "\n",
        "        # Monitoring integration\n",
        "        self._monitor: Optional[NeuroMonitor] = None\n",
        "        self._start_time = time.time()\n",
        "        self._monitoring_metrics = {\n",
        "            'messages_processed': 0,\n",
        "            'processing_time_total': 0.0,\n",
        "            'messages_sent': 0,\n",
        "            'messages_received': 0,\n",
        "            'errors_total': 0\n",
        "        }\n",
        "        self._metrics_lock = threading.Lock()\n",
        "        self._running = False\n",
        "\n",
        "        print(f\"ğŸ¤– Initialized MonitoredAgent: {self.name} ({self.id[:8]}...)\")\n",
        "\n",
        "    def _set_monitor(self, monitor: NeuroMonitor):\n",
        "        \"\"\"Set the monitor for this agent\"\"\"\n",
        "        self._monitor = monitor\n",
        "\n",
        "        # Log initialization event (but don't block if monitor is busy)\n",
        "        if self._monitor:\n",
        "            try:\n",
        "                event = MonitoringEvent.create(\n",
        "                    event_type=EventType.AGENT_STARTED,\n",
        "                    agent_id=self.id,\n",
        "                    data={'agent_name': self.name, 'agent_type': self.__class__.__name__}\n",
        "                )\n",
        "                # Use a separate thread to avoid blocking\n",
        "                threading.Thread(\n",
        "                    target=lambda: self._monitor.log_event(event),\n",
        "                    daemon=True\n",
        "                ).start()\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Warning: Could not log agent registration event: {e}\")\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the agent with monitoring\"\"\"\n",
        "        if self._running:\n",
        "            print(f\"âš ï¸  Agent {self.name} is already running\")\n",
        "            return\n",
        "\n",
        "        self._stop_event.clear()\n",
        "        self._processing_thread = threading.Thread(\n",
        "            target=self._processing_loop,\n",
        "            daemon=True,\n",
        "            name=f\"MonitoredAgent-{self.name}\"\n",
        "        )\n",
        "        self._processing_thread.start()\n",
        "        self._running = True\n",
        "\n",
        "        print(f\"â–¶ï¸  MonitoredAgent {self.name} started\")\n",
        "\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.AGENT_STARTED,\n",
        "                agent_id=self.id,\n",
        "                data={'action': 'started'}\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the agent with monitoring\"\"\"\n",
        "        if not self._running:\n",
        "            return\n",
        "\n",
        "        self._stop_event.set()\n",
        "\n",
        "        if self._processing_thread:\n",
        "            self._processing_thread.join(timeout=2.0)\n",
        "\n",
        "        self._running = False\n",
        "        print(f\"â¹ï¸  MonitoredAgent {self.name} stopped\")\n",
        "\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.AGENT_STOPPED,\n",
        "                agent_id=self.id,\n",
        "                data={'uptime': time.time() - self._start_time}\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "    def receive_message(self, message: Message):\n",
        "        \"\"\"Receive a message with monitoring\"\"\"\n",
        "        self._message_queue.put(message)\n",
        "\n",
        "        with self._metrics_lock:\n",
        "            self._monitoring_metrics['messages_received'] += 1\n",
        "\n",
        "        print(f\"ğŸ“¬ {self.name} received: {str(message.content)[:50]}{'...' if len(str(message.content)) > 50 else ''}\")\n",
        "\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.MESSAGE_RECEIVED,\n",
        "                agent_id=self.id,\n",
        "                data={\n",
        "                    'message_id': message.id,\n",
        "                    'sender': message.sender,\n",
        "                    'content_length': len(str(message.content))\n",
        "                }\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "    def send_message(self, recipients: List[AgentID], content: Any) -> Message:\n",
        "        \"\"\"Send a message with monitoring\"\"\"\n",
        "        message = Message.create(\n",
        "            sender=self.id,\n",
        "            recipients=recipients,\n",
        "            content=content\n",
        "        )\n",
        "\n",
        "        with self._metrics_lock:\n",
        "            self._monitoring_metrics['messages_sent'] += 1\n",
        "\n",
        "        print(f\"ğŸ“¤ {self.name} sent: {str(content)[:50]}{'...' if len(str(content)) > 50 else ''}\")\n",
        "\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.MESSAGE_SENT,\n",
        "                agent_id=self.id,\n",
        "                data={\n",
        "                    'message_id': message.id,\n",
        "                    'recipients': recipients,\n",
        "                    'content_length': len(str(content))\n",
        "                }\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "        return message\n",
        "\n",
        "    def process_message(self, message: Message):\n",
        "        \"\"\"Process a message - override this in subclasses\"\"\"\n",
        "        print(f\"ğŸ¯ {self.name} processing: {message.content}\")\n",
        "\n",
        "        # Simulate processing\n",
        "        time.sleep(0.01)\n",
        "\n",
        "        # Echo response\n",
        "        response = self.send_message(\n",
        "            recipients=[message.sender],\n",
        "            content=f\"Echo: {message.content}\"\n",
        "        )\n",
        "\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.MESSAGE_PROCESSED,\n",
        "                agent_id=self.id,\n",
        "                data={\n",
        "                    'input_message_id': message.id,\n",
        "                    'output_message_id': response.id\n",
        "                }\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "    def _processing_loop(self):\n",
        "        \"\"\"Main message processing loop with monitoring\"\"\"\n",
        "        print(f\"ğŸ”„ {self.name} processing loop started\")\n",
        "\n",
        "        while not self._stop_event.is_set():\n",
        "            try:\n",
        "                message = self._message_queue.get(timeout=0.1)\n",
        "\n",
        "                start_time = time.time()\n",
        "                self.process_message(message)\n",
        "                processing_time = time.time() - start_time\n",
        "\n",
        "                with self._metrics_lock:\n",
        "                    self._monitoring_metrics['messages_processed'] += 1\n",
        "                    self._monitoring_metrics['processing_time_total'] += processing_time\n",
        "\n",
        "                self._message_queue.task_done()\n",
        "\n",
        "                print(f\"âœ… {self.name} processed message in {processing_time:.3f}s\")\n",
        "\n",
        "            except queue.Empty:\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error processing message in {self.name}: {e}\")\n",
        "\n",
        "                with self._metrics_lock:\n",
        "                    self._monitoring_metrics['errors_total'] += 1\n",
        "\n",
        "                if self._monitor:\n",
        "                    event = MonitoringEvent.create(\n",
        "                        event_type=EventType.ERROR_OCCURRED,\n",
        "                        agent_id=self.id,\n",
        "                        data={\n",
        "                            'error_type': type(e).__name__,\n",
        "                            'error_message': str(e)\n",
        "                        },\n",
        "                        alert_level=AlertLevel.ERROR\n",
        "                    )\n",
        "                    self._monitor.log_event(event)\n",
        "\n",
        "        print(f\"ğŸ›‘ {self.name} processing loop stopped\")\n",
        "\n",
        "    def get_monitoring_metrics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get current monitoring metrics for this agent\"\"\"\n",
        "        with self._metrics_lock:\n",
        "            metrics = self._monitoring_metrics.copy()\n",
        "\n",
        "        uptime = time.time() - self._start_time\n",
        "        queue_size = self._message_queue.qsize()\n",
        "\n",
        "        metrics.update({\n",
        "            'uptime_seconds': uptime,\n",
        "            'queue_size': queue_size,\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "        return metrics\n",
        "\n",
        "class SmartMonitoredAgent(MonitoredAgent):\n",
        "    \"\"\"\n",
        "    A sophisticated monitored agent with personality-based behaviors\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id: Optional[AgentID] = None, name: str = \"\",\n",
        "                 personality: str = \"balanced\"):\n",
        "        super().__init__(agent_id, name)\n",
        "        self.personality = personality\n",
        "        self.conversation_count = 0\n",
        "\n",
        "        print(f\"ğŸ§  SmartMonitoredAgent personality: {personality}\")\n",
        "\n",
        "    def process_message(self, message: Message):\n",
        "        \"\"\"Smart message processing with personality\"\"\"\n",
        "        content = str(message.content).lower()\n",
        "        self.conversation_count += 1\n",
        "\n",
        "        print(f\"ğŸ¯ {self.name} ({self.personality}) processing: {message.content}\")\n",
        "\n",
        "        # Determine response based on personality\n",
        "        response = self._generate_response(content)\n",
        "\n",
        "        # Add personality-based delay\n",
        "        if self.personality == \"thoughtful\":\n",
        "            time.sleep(0.05)\n",
        "        elif self.personality == \"quick\":\n",
        "            time.sleep(0.01)\n",
        "        else:\n",
        "            time.sleep(0.02)\n",
        "\n",
        "        # Send response\n",
        "        response_msg = self.send_message(\n",
        "            recipients=[message.sender],\n",
        "            content=response\n",
        "        )\n",
        "\n",
        "        # Log processing\n",
        "        if self._monitor:\n",
        "            event = MonitoringEvent.create(\n",
        "                event_type=EventType.MESSAGE_PROCESSED,\n",
        "                agent_id=self.id,\n",
        "                data={\n",
        "                    'personality': self.personality,\n",
        "                    'conversation_count': self.conversation_count,\n",
        "                    'input_message_id': message.id,\n",
        "                    'output_message_id': response_msg.id\n",
        "                }\n",
        "            )\n",
        "            self._monitor.log_event(event)\n",
        "\n",
        "    def _generate_response(self, content: str) -> str:\n",
        "        \"\"\"Generate personality-based responses\"\"\"\n",
        "        if self.personality == \"friendly\":\n",
        "            if \"hello\" in content:\n",
        "                return \"Hello there! It's wonderful to meet you! ğŸ˜Š\"\n",
        "            elif \"?\" in content:\n",
        "                return \"That's such an interesting question! I love chatting!\"\n",
        "            else:\n",
        "                return \"That's really cool! Thanks for sharing!\"\n",
        "\n",
        "        elif self.personality == \"analytical\":\n",
        "            if \"hello\" in content:\n",
        "                return \"Hello. I'm ready to analyze topics you'd like to discuss.\"\n",
        "            elif \"?\" in content:\n",
        "                return \"Let me analyze this systematically. Based on patterns...\"\n",
        "            else:\n",
        "                return \"Interesting. Let me process this information.\"\n",
        "\n",
        "        elif self.personality == \"helpful\":\n",
        "            if \"hello\" in content:\n",
        "                return \"Hello! How can I help you today?\"\n",
        "            elif \"?\" in content:\n",
        "                return \"I'd be happy to help answer that!\"\n",
        "            else:\n",
        "                return \"Thanks! Is there anything I can help you with?\"\n",
        "\n",
        "        elif self.personality == \"thoughtful\":\n",
        "            if \"hello\" in content:\n",
        "                return \"Hello... *pauses thoughtfully* Good to meet you.\"\n",
        "            elif \"?\" in content:\n",
        "                return \"Hmm, that's profound. Let me think carefully...\"\n",
        "            else:\n",
        "                return \"I see... *considers deeply* Much to reflect upon.\"\n",
        "\n",
        "        elif self.personality == \"quick\":\n",
        "            if \"hello\" in content:\n",
        "                return \"Hi! Quick chat?\"\n",
        "            elif \"?\" in content:\n",
        "                return \"Fast answer: depends on context!\"\n",
        "            else:\n",
        "                return \"Got it! Next?\"\n",
        "\n",
        "        else:  # balanced\n",
        "            if \"hello\" in content:\n",
        "                return \"Hello! Nice to meet you.\"\n",
        "            elif \"?\" in content:\n",
        "                return \"That's a good question. Let me think about it.\"\n",
        "            else:\n",
        "                return \"Thanks for sharing that.\"\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALIZATION COMPLETE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ğŸ”§ Tutorial 5 initialization complete!\")\n",
        "print(\"âœ… All classes loaded successfully:\")\n",
        "print(\"   - EventType and AlertLevel enums\")\n",
        "print(\"   - MonitoringEvent and PerformanceMetrics classes\")\n",
        "print(\"   - NeuroMonitor comprehensive monitoring system\")\n",
        "print(\"   - MonitoredAgent base class with monitoring\")\n",
        "print(\"   - SmartMonitoredAgent with personality behaviors\")\n",
        "print()\n",
        "print(\"ğŸš€ Ready to start monitoring intelligent agent systems!\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqS6dcQLq9-A",
        "outputId": "4795fb7f-cea6-4722-9d45-33fce5e3c02e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”§ Tutorial 5 initialization complete!\n",
            "âœ… All classes loaded successfully:\n",
            "   - EventType and AlertLevel enums\n",
            "   - MonitoringEvent and PerformanceMetrics classes\n",
            "   - NeuroMonitor comprehensive monitoring system\n",
            "   - MonitoredAgent base class with monitoring\n",
            "   - SmartMonitoredAgent with personality behaviors\n",
            "\n",
            "ğŸš€ Ready to start monitoring intelligent agent systems!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEMO SECTION: Let's monitor our agents in real-time!\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ Tutorial 5: Basic Monitoring - Watching Your Agents Work\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "# Step 1: Create the monitoring system\n",
        "print(\"ğŸ“ Step 1: Creating the NeuroMonitor system...\")\n",
        "monitor = NeuroMonitor(max_events=500)\n",
        "monitor.start()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjYwPFmQrEQf",
        "outputId": "07ea2632-0b4c-4cc0-8bea-24ff67b1cbdb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ğŸš€ Tutorial 5: Basic Monitoring - Watching Your Agents Work\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Step 1: Creating the NeuroMonitor system...\n",
            "ğŸ” NeuroMonitor initialized with max 500 events\n",
            "ğŸ”„ NeuroMonitor background loop started\n",
            "â–¶ï¸  NeuroMonitor started\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create monitored agents with different personalities\n",
        "print(\"ğŸ“ Step 2: Creating monitored agents with different personalities...\")\n",
        "\n",
        "# Create agents\n",
        "alice = SmartMonitoredAgent(name=\"Alice\", personality=\"friendly\")\n",
        "bob = SmartMonitoredAgent(name=\"Bob\", personality=\"analytical\")\n",
        "charlie = SmartMonitoredAgent(name=\"Charlie\", personality=\"helpful\")\n",
        "diana = SmartMonitoredAgent(name=\"Diana\", personality=\"thoughtful\")\n",
        "erik = SmartMonitoredAgent(name=\"Erik\", personality=\"quick\")\n",
        "\n",
        "agents = [alice, bob, charlie, diana, erik]\n",
        "\n",
        "# Register agents with monitor (with safety checks)\n",
        "print(\"   Registering agents with monitor...\")\n",
        "for i, agent in enumerate(agents, 1):\n",
        "    try:\n",
        "        print(f\"   ğŸ”„ Registering {agent.name}...\")\n",
        "        monitor.register_agent(agent)\n",
        "        print(f\"   âœ… Registered {agent.name} ({i}/{len(agents)})\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Failed to register {agent.name}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Small delay for registration\n",
        "time.sleep(0.5)\n",
        "\n",
        "# Start all agents\n",
        "print(\"   Starting agent processing threads...\")\n",
        "for i, agent in enumerate(agents, 1):\n",
        "    agent.start()\n",
        "    print(f\"   â–¶ï¸  Started {agent.name} ({i}/{len(agents)})\")\n",
        "    time.sleep(0.1)\n",
        "\n",
        "# Verify agents are running\n",
        "print(\"   Verifying agent status...\")\n",
        "running_count = 0\n",
        "for agent in agents:\n",
        "    if agent._running:\n",
        "        running_count += 1\n",
        "        print(f\"   âœ… {agent.name} is running\")\n",
        "    else:\n",
        "        print(f\"   âŒ {agent.name} failed to start\")\n",
        "\n",
        "print(f\"   Successfully started {running_count}/{len(agents)} agents\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7P8w0PrrMh9",
        "outputId": "694d7538-35f5-4f47-d9cd-7d20ae733381"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 2: Creating monitored agents with different personalities...\n",
            "ğŸ¤– Initialized MonitoredAgent: Alice (dec8ba13...)\n",
            "ğŸ§  SmartMonitoredAgent personality: friendly\n",
            "ğŸ¤– Initialized MonitoredAgent: Bob (e0ba6081...)\n",
            "ğŸ§  SmartMonitoredAgent personality: analytical\n",
            "ğŸ¤– Initialized MonitoredAgent: Charlie (bb465d88...)\n",
            "ğŸ§  SmartMonitoredAgent personality: helpful\n",
            "ğŸ¤– Initialized MonitoredAgent: Diana (785bbe44...)\n",
            "ğŸ§  SmartMonitoredAgent personality: thoughtful\n",
            "ğŸ¤– Initialized MonitoredAgent: Erik (fc5d3552...)\n",
            "ğŸ§  SmartMonitoredAgent personality: quick\n",
            "   Registering agents with monitor...\n",
            "   ğŸ”„ Registering Alice...\n",
            "ğŸ“Š Registered agent for monitoring: Alice\n",
            "   âœ… Registered Alice (1/5)\n",
            "   ğŸ”„ Registering Bob...\n",
            "ğŸ“Š Registered agent for monitoring: Bob\n",
            "   âœ… Registered Bob (2/5)\n",
            "   ğŸ”„ Registering Charlie...\n",
            "ğŸ“Š Registered agent for monitoring: Charlie\n",
            "   âœ… Registered Charlie (3/5)\n",
            "   ğŸ”„ Registering Diana...\n",
            "ğŸ“Š Registered agent for monitoring: Diana\n",
            "   âœ… Registered Diana (4/5)\n",
            "   ğŸ”„ Registering Erik...\n",
            "ğŸ“Š Registered agent for monitoring: Erik\n",
            "   âœ… Registered Erik (5/5)\n",
            "   Starting agent processing threads...\n",
            "ğŸ”„ Alice processing loop started\n",
            "â–¶ï¸  MonitoredAgent Alice started\n",
            "   â–¶ï¸  Started Alice (1/5)\n",
            "ğŸ”„ Bob processing loop started\n",
            "â–¶ï¸  MonitoredAgent Bob started\n",
            "   â–¶ï¸  Started Bob (2/5)\n",
            "ğŸ”„ Charlie processing loop started\n",
            "â–¶ï¸  MonitoredAgent Charlie started\n",
            "   â–¶ï¸  Started Charlie (3/5)\n",
            "ğŸ”„ Diana processing loop started\n",
            "â–¶ï¸  MonitoredAgent Diana started\n",
            "   â–¶ï¸  Started Diana (4/5)\n",
            "ğŸ”„ Erik processing loop startedâ–¶ï¸  MonitoredAgent Erik started\n",
            "   â–¶ï¸  Started Erik (5/5)\n",
            "\n",
            "   Verifying agent status...\n",
            "   âœ… Alice is running\n",
            "   âœ… Bob is running\n",
            "   âœ… Charlie is running\n",
            "   âœ… Diana is running\n",
            "   âœ… Erik is running\n",
            "   Successfully started 5/5 agents\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Simulate conversations to generate monitoring data\n",
        "print(\"ğŸ“ Step 3: Simulating conversations to generate monitoring data...\")\n",
        "\n",
        "conversations = [\n",
        "    (\"Hello everyone!\", [alice, bob, charlie]),\n",
        "    (\"What do you think about AI?\", [alice, diana]),\n",
        "    (\"Can someone help me?\", [bob, charlie]),\n",
        "    (\"How are you doing?\", [alice, diana, erik]),\n",
        "    (\"Thanks and goodbye!\", [alice, bob, charlie, diana, erik])\n",
        "]\n",
        "\n",
        "for i, (message_content, target_agents) in enumerate(conversations, 1):\n",
        "    print(f\"--- Conversation {i} ---\")\n",
        "    print(f\"Broadcasting: '{message_content}'\")\n",
        "\n",
        "    for agent in target_agents:\n",
        "        test_msg = Message.create(\n",
        "            sender=\"user_simulator\",\n",
        "            recipients=[agent.id],\n",
        "            content=message_content\n",
        "        )\n",
        "        agent.receive_message(test_msg)\n",
        "\n",
        "    time.sleep(1.0)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkkU_W_xrvBL",
        "outputId": "615a0437-9ce7-4b6e-f0f0-8ec03932296b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 3: Simulating conversations to generate monitoring data...\n",
            "--- Conversation 1 ---\n",
            "Broadcasting: 'Hello everyone!'\n",
            "ğŸ“¬ Alice received: Hello everyone!\n",
            "ğŸ“¬ Bob received: Hello everyone!\n",
            "ğŸ“¬ Charlie received: Hello everyone!\n",
            "ğŸ¯ Bob (analytical) processing: Hello everyone!\n",
            "ğŸ¯ Alice (friendly) processing: Hello everyone!\n",
            "ğŸ¯ Charlie (helpful) processing: Hello everyone!\n",
            "ğŸ“¤ Bob sent: Hello. I'm ready to analyze topics you'd like to d...\n",
            "âœ… Bob processed message in 0.020s\n",
            "ğŸ“¤ Alice sent: Hello there! It's wonderful to meet you! ğŸ˜Š\n",
            "âœ… Alice processed message in 0.021s\n",
            "ğŸ“¤ Charlie sent: Hello! How can I help you today?\n",
            "âœ… Charlie processed message in 0.020s\n",
            "\n",
            "--- Conversation 2 ---\n",
            "Broadcasting: 'What do you think about AI?'\n",
            "ğŸ“¬ Alice received: What do you think about AI?\n",
            "ğŸ“¬ Diana received: What do you think about AI?\n",
            "ğŸ¯ Alice (friendly) processing: What do you think about AI?\n",
            "ğŸ¯ Diana (thoughtful) processing: What do you think about AI?\n",
            "ğŸ“¤ Alice sent: That's such an interesting question! I love chatti...\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ“¤ Diana sent: Hmm, that's profound. Let me think carefully...\n",
            "âœ… Diana processed message in 0.050s\n",
            "\n",
            "--- Conversation 3 ---\n",
            "Broadcasting: 'Can someone help me?'\n",
            "ğŸ“¬ Bob received: Can someone help me?\n",
            "ğŸ“¬ Charlie received: Can someone help me?\n",
            "ğŸ¯ Bob (analytical) processing: Can someone help me?\n",
            "ğŸ¯ Charlie (helpful) processing: Can someone help me?\n",
            "ğŸ“¤ Bob sent: Let me analyze this systematically. Based on patte...\n",
            "âœ… Bob processed message in 0.020s\n",
            "ğŸ“¤ Charlie sent: I'd be happy to help answer that!\n",
            "âœ… Charlie processed message in 0.021s\n",
            "\n",
            "--- Conversation 4 ---\n",
            "Broadcasting: 'How are you doing?'\n",
            "ğŸ“¬ Alice received: How are you doing?\n",
            "ğŸ“¬ Diana received: How are you doing?\n",
            "ğŸ“¬ Erik received: How are you doing?\n",
            "ğŸ¯ Erik (quick) processing: How are you doing?\n",
            "ğŸ¯ Diana (thoughtful) processing: How are you doing?\n",
            "ğŸ¯ Alice (friendly) processing: How are you doing?\n",
            "ğŸ“¤ Erik sent: Fast answer: depends on context!\n",
            "âœ… Erik processed message in 0.010s\n",
            "ğŸ“¤ Alice sent: That's such an interesting question! I love chatti...\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ“¤ Diana sent: Hmm, that's profound. Let me think carefully...\n",
            "âœ… Diana processed message in 0.050s\n",
            "\n",
            "--- Conversation 5 ---\n",
            "Broadcasting: 'Thanks and goodbye!'\n",
            "ğŸ“¬ Alice received: Thanks and goodbye!\n",
            "ğŸ“¬ Bob received: Thanks and goodbye!\n",
            "ğŸ“¬ Charlie received: Thanks and goodbye!\n",
            "ğŸ“¬ Diana received: Thanks and goodbye!\n",
            "ğŸ“¬ Erik received: Thanks and goodbye!\n",
            "ğŸ¯ Alice (friendly) processing: Thanks and goodbye!\n",
            "ğŸ¯ Charlie (helpful) processing: Thanks and goodbye!\n",
            "ğŸ¯ Erik (quick) processing: Thanks and goodbye!\n",
            "ğŸ¯ Bob (analytical) processing: Thanks and goodbye!\n",
            "ğŸ¯ Diana (thoughtful) processing: Thanks and goodbye!\n",
            "ğŸ“¤ Erik sent: Got it! Next?\n",
            "âœ… Erik processed message in 0.010s\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.021s\n",
            "ğŸ“¤ Charlie sent: Thanks! Is there anything I can help you with?\n",
            "âœ… Charlie processed message in 0.021s\n",
            "ğŸ“¤ Bob sent: Interesting. Let me process this information.\n",
            "âœ… Bob processed message in 0.021s\n",
            "ğŸ“¤ Diana sent: I see... *considers deeply* Much to reflect upon.\n",
            "âœ… Diana processed message in 0.050s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Wait for metrics collection and check system health\n",
        "print(\"ğŸ“ Step 4: Analyzing system performance...\")\n",
        "print(\"   Waiting for metrics collection...\")\n",
        "time.sleep(3.0)\n",
        "\n",
        "# Get system health\n",
        "health = monitor.get_system_health()\n",
        "print(\"   System Health Overview:\")\n",
        "for key, value in health.items():\n",
        "    if isinstance(value, float):\n",
        "        if 'time' in key or 'rate' in key:\n",
        "            print(f\"     {key}: {value:.3f}\")\n",
        "        else:\n",
        "            print(f\"     {key}: {value:.2f}\")\n",
        "    elif isinstance(value, dict):\n",
        "        print(f\"     {key}:\")\n",
        "        for sub_key, sub_value in value.items():\n",
        "            print(f\"       {sub_key}: {sub_value}\")\n",
        "    else:\n",
        "        print(f\"     {key}: {value}\")\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dpZbIWyr0YS",
        "outputId": "b201fa6c-2579-4776-a9a2-5438558525f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 4: Analyzing system performance...\n",
            "   Waiting for metrics collection...\n",
            "   System Health Overview:\n",
            "     system_uptime_seconds: 54.629\n",
            "     active_agents: 5\n",
            "     total_events: 55\n",
            "     total_messages_processed: 15\n",
            "     total_errors: 0\n",
            "     error_rate: 0.000\n",
            "     average_processing_time: 0.024\n",
            "     events_by_type:\n",
            "       agent_started: 10\n",
            "       message_received: 15\n",
            "       message_sent: 15\n",
            "       message_processed: 15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Individual agent metrics\n",
        "print(\"ğŸ“ Step 5: Individual agent performance analysis...\")\n",
        "for agent in agents:\n",
        "    metrics = monitor.get_agent_metrics(agent.id)\n",
        "    if metrics:\n",
        "        print(f\"   {agent.name} ({agent.personality}):\")\n",
        "        print(f\"     Messages processed: {metrics.messages_processed}\")\n",
        "        print(f\"     Messages sent: {metrics.messages_sent}\")\n",
        "        print(f\"     Average processing time: {metrics.processing_time_avg:.3f}s\")\n",
        "        print(f\"     Queue size: {metrics.queue_size}\")\n",
        "        print(f\"     Errors: {metrics.errors_total}\")\n",
        "        print(f\"     Uptime: {metrics.uptime_seconds/60:.1f} minutes\")\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWrSG51Rr3p_",
        "outputId": "5ff00363-1328-4bfc-fa53-cf41ce96abb1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 5: Individual agent performance analysis...\n",
            "   Alice (friendly):\n",
            "     Messages processed: 4\n",
            "     Messages sent: 4\n",
            "     Average processing time: 0.020s\n",
            "     Queue size: 0\n",
            "     Errors: 0\n",
            "     Uptime: 0.9 minutes\n",
            "   Bob (analytical):\n",
            "     Messages processed: 3\n",
            "     Messages sent: 3\n",
            "     Average processing time: 0.021s\n",
            "     Queue size: 0\n",
            "     Errors: 0\n",
            "     Uptime: 0.9 minutes\n",
            "   Charlie (helpful):\n",
            "     Messages processed: 3\n",
            "     Messages sent: 3\n",
            "     Average processing time: 0.021s\n",
            "     Queue size: 0\n",
            "     Errors: 0\n",
            "     Uptime: 0.9 minutes\n",
            "   Diana (thoughtful):\n",
            "     Messages processed: 3\n",
            "     Messages sent: 3\n",
            "     Average processing time: 0.050s\n",
            "     Queue size: 0\n",
            "     Errors: 0\n",
            "     Uptime: 0.9 minutes\n",
            "   Erik (quick):\n",
            "     Messages processed: 2\n",
            "     Messages sent: 2\n",
            "     Average processing time: 0.010s\n",
            "     Queue size: 0\n",
            "     Errors: 0\n",
            "     Uptime: 0.9 minutes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Event analysis\n",
        "print(\"ğŸ“ Step 6: Event analysis...\")\n",
        "recent_events = monitor.get_recent_events(20)\n",
        "print(f\"   Recent events: {len(recent_events)}\")\n",
        "\n",
        "event_summary = defaultdict(int)\n",
        "for event in recent_events:\n",
        "    event_summary[event.event_type.value] += 1\n",
        "\n",
        "print(\"   Event breakdown:\")\n",
        "for event_type, count in event_summary.items():\n",
        "    print(f\"     {event_type}: {count}\")\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGhfklRXr7Kx",
        "outputId": "6e99f6e9-19fc-4635-aaca-812d7a460bc1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 6: Event analysis...\n",
            "   Recent events: 20\n",
            "   Event breakdown:\n",
            "     message_processed: 8\n",
            "     message_sent: 7\n",
            "     message_received: 5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Test error conditions\n",
        "print(\"ğŸ“ Step 7: Testing error monitoring...\")\n",
        "\n",
        "# Simulate high load\n",
        "print(\"   Simulating high load on Alice...\")\n",
        "for i in range(10):\n",
        "    load_msg = Message.create(\n",
        "        sender=\"load_tester\",\n",
        "        recipients=[alice.id],\n",
        "        content=f\"Load test message {i+1}\"\n",
        "    )\n",
        "    alice.receive_message(load_msg)\n",
        "\n",
        "time.sleep(2.0)\n",
        "\n",
        "# Check for alerts\n",
        "recent_events = monitor.get_recent_events(10)\n",
        "alerts = [e for e in recent_events if e.alert_level != AlertLevel.INFO]\n",
        "print(f\"   Performance alerts generated: {len(alerts)}\")\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X12qcX2Jr-IL",
        "outputId": "52f1ec17-4dcd-421a-a7b0-7af4839e7718"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 7: Testing error monitoring...\n",
            "   Simulating high load on Alice...\n",
            "ğŸ“¬ Alice received: Load test message 1\n",
            "ğŸ“¬ Alice received: Load test message 2\n",
            "ğŸ“¬ Alice received: Load test message 3\n",
            "ğŸ“¬ Alice received: Load test message 4\n",
            "ğŸ“¬ Alice received: Load test message 5\n",
            "ğŸ“¬ Alice received: Load test message 6\n",
            "ğŸ“¬ Alice received: Load test message 7\n",
            "ğŸ“¬ Alice received: Load test message 8\n",
            "ğŸ“¬ Alice received: Load test message 9\n",
            "ğŸ“¬ Alice received: Load test message 10\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 1\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 2\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 3\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 4\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 5\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 6\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 7\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 8\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 9\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.020s\n",
            "ğŸ¯ Alice (friendly) processing: Load test message 10\n",
            "ğŸ“¤ Alice sent: That's really cool! Thanks for sharing!\n",
            "âœ… Alice processed message in 0.021s\n",
            "   Performance alerts generated: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Visualize if possible\n",
        "print(\"ğŸ“ Step 8: Creating monitoring visualization...\")\n",
        "\n",
        "try:\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "\n",
        "    # Prepare data\n",
        "    agent_names = []\n",
        "    messages_processed = []\n",
        "    processing_times = []\n",
        "    personalities = []\n",
        "\n",
        "    for agent in agents:\n",
        "        metrics = monitor.get_agent_metrics(agent.id)\n",
        "        if metrics:\n",
        "            agent_names.append(agent.name)\n",
        "            messages_processed.append(metrics.messages_processed)\n",
        "            processing_times.append(metrics.processing_time_avg)\n",
        "            personalities.append(agent.personality)\n",
        "\n",
        "    # Create dashboard\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            'Message Processing by Agent',\n",
        "            'Processing Time by Personality',\n",
        "            'System Health Score',\n",
        "            'Event Distribution'\n",
        "        ),\n",
        "        specs=[[{\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
        "               [{\"type\": \"xy\"}, {\"type\": \"domain\"}]]  # domain type for pie chart\n",
        "    )\n",
        "\n",
        "    # Messages processed\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=agent_names,\n",
        "            y=messages_processed,\n",
        "            name='Messages',\n",
        "            marker_color='lightblue'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Processing times\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=personalities,\n",
        "            y=processing_times,\n",
        "            mode='markers',\n",
        "            name='Processing Time',\n",
        "            marker=dict(size=10, color='red')\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # System health (mock trend)\n",
        "    health_times = [i for i in range(10)]\n",
        "    health_scores = [95 + i * 0.5 for i in range(10)]\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=health_times,\n",
        "            y=health_scores,\n",
        "            mode='lines+markers',\n",
        "            name='Health %',\n",
        "            line=dict(color='green')\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Event distribution\n",
        "    event_counts = health['events_by_type']\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=list(event_counts.keys()),\n",
        "            values=list(event_counts.values()),\n",
        "            name=\"Events\"\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=\"NeuroMonitor Dashboard - Real-time Agent Monitoring\",\n",
        "        height=800,\n",
        "        showlegend=True,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    # Update axes\n",
        "    fig.update_xaxes(title_text=\"Agents\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Message Count\", row=1, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Personality\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Processing Time (s)\", row=1, col=2)\n",
        "\n",
        "    fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"Health Score %\", row=2, col=1)\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    print(\"   âœ… Monitoring dashboard created!\")\n",
        "    print(\"   ğŸ“Š The dashboard shows:\")\n",
        "    print(\"      - Message processing capacity per agent\")\n",
        "    print(\"      - Processing time by personality type\")\n",
        "    print(\"      - System health trend over time\")\n",
        "    print(\"      - Distribution of event types\")\n",
        "    print()\n",
        "\n",
        "except ImportError:\n",
        "    print(\"   âš ï¸  Plotly not available - skipping visualization\")\n",
        "    print(\"   ğŸ’¡ To see monitoring visualizations, install plotly: pip install plotly\")\n",
        "    print(\"   ğŸ“Š Monitoring summary:\")\n",
        "    print(f\"      Total events: {health['total_events']}\")\n",
        "    print(f\"      Active agents: {health['active_agents']}\")\n",
        "    print(f\"      System uptime: {health['system_uptime_seconds']/60:.1f} minutes\")\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "JYLM__c_sB0o",
        "outputId": "b314df36-a2d0-4bf3-e9ea-137f7f5198cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 8: Creating monitoring visualization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a4e9feef-07b7-4e10-8145-54f06e157a56\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4e9feef-07b7-4e10-8145-54f06e157a56\")) {                    Plotly.newPlot(                        \"a4e9feef-07b7-4e10-8145-54f06e157a56\",                        [{\"marker\":{\"color\":\"lightblue\"},\"name\":\"Messages\",\"x\":[\"Alice\",\"Bob\",\"Charlie\",\"Diana\",\"Erik\"],\"y\":[14,3,3,3,2],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"red\",\"size\":10},\"mode\":\"markers\",\"name\":\"Processing Time\",\"x\":[\"friendly\",\"analytical\",\"helpful\",\"thoughtful\",\"quick\"],\"y\":[0.02040408338819231,0.020575841267903645,0.020553986231486004,0.05032618840535482,0.010343432426452637],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"line\":{\"color\":\"green\"},\"mode\":\"lines+markers\",\"name\":\"Health %\",\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[95.0,95.5,96.0,96.5,97.0,97.5,98.0,98.5,99.0,99.5],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"labels\":[\"agent_started\",\"message_received\",\"message_sent\",\"message_processed\"],\"name\":\"Events\",\"values\":[10,15,15,15],\"type\":\"pie\",\"domain\":{\"x\":[0.55,1.0],\"y\":[0.0,0.375]}}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Agents\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Message Count\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"title\":{\"text\":\"Personality\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Processing Time (s)\"}},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"Time\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"Health Score %\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Message Processing by Agent\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Processing Time by Personality\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"System Health Score\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Event Distribution\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"NeuroMonitor Dashboard - Real-time Agent Monitoring\"},\"height\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a4e9feef-07b7-4e10-8145-54f06e157a56');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ… Monitoring dashboard created!\n",
            "   ğŸ“Š The dashboard shows:\n",
            "      - Message processing capacity per agent\n",
            "      - Processing time by personality type\n",
            "      - System health trend over time\n",
            "      - Distribution of event types\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Performance analysis\n",
        "print(\"ğŸ“ Step 9: Performance analysis and optimization insights...\")\n",
        "\n",
        "# Find best and worst performers\n",
        "best_performer = None\n",
        "worst_performer = None\n",
        "best_time = float('inf')\n",
        "worst_time = 0.0\n",
        "\n",
        "for agent in agents:\n",
        "    metrics = monitor.get_agent_metrics(agent.id)\n",
        "    if metrics and metrics.messages_processed > 0:\n",
        "        avg_time = metrics.processing_time_avg\n",
        "        if avg_time < best_time:\n",
        "            best_time = avg_time\n",
        "            best_performer = agent\n",
        "        if avg_time > worst_time:\n",
        "            worst_time = avg_time\n",
        "            worst_performer = agent\n",
        "\n",
        "if best_performer and worst_performer:\n",
        "    print(f\"   ğŸ† Best performer: {best_performer.name} ({best_performer.personality})\")\n",
        "    print(f\"      Average processing time: {best_time:.3f}s\")\n",
        "    print(f\"   ğŸŒ Slowest performer: {worst_performer.name} ({worst_performer.personality})\")\n",
        "    print(f\"      Average processing time: {worst_time:.3f}s\")\n",
        "\n",
        "    if worst_time > 0:\n",
        "        speedup = worst_time / best_time\n",
        "        print(f\"   ğŸ“ˆ Performance difference: {speedup:.1f}x\")\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw36df1nsXpe",
        "outputId": "24ddc267-68fa-4985-cf38-f3c6629fd894"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 9: Performance analysis and optimization insights...\n",
            "   ğŸ† Best performer: Erik (quick)\n",
            "      Average processing time: 0.010s\n",
            "   ğŸŒ Slowest performer: Diana (thoughtful)\n",
            "      Average processing time: 0.050s\n",
            "   ğŸ“ˆ Performance difference: 4.9x\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 10: Cleanup and final summary\n",
        "print(\"ğŸ“ Step 10: Final analysis and cleanup...\")\n",
        "\n",
        "# Final metrics\n",
        "final_health = monitor.get_system_health()\n",
        "print(\"   Final System Statistics:\")\n",
        "print(f\"     Runtime: {final_health['system_uptime_seconds']/60:.1f} minutes\")\n",
        "print(f\"     Total events: {final_health['total_events']}\")\n",
        "print(f\"     Total messages: {final_health['total_messages_processed']}\")\n",
        "print(f\"     Error rate: {final_health['error_rate']:.2%}\")\n",
        "print(f\"     Avg processing time: {final_health['average_processing_time']:.3f}s\")\n",
        "\n",
        "# Calculate throughput\n",
        "total_runtime = final_health['system_uptime_seconds']\n",
        "total_messages = final_health['total_messages_processed']\n",
        "if total_runtime > 0:\n",
        "    throughput = total_messages / total_runtime\n",
        "    print(f\"     System throughput: {throughput:.1f} messages/second\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Stop everything\n",
        "print(\"   Stopping all agents and monitoring...\")\n",
        "for agent in agents:\n",
        "    agent.stop()\n",
        "\n",
        "monitor.stop()\n",
        "\n",
        "print(\"âœ… Tutorial 5 Complete!\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IHcSpF9schD",
        "outputId": "2b72866c-2e56-4044-8aac-850f7dcc5c5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Step 10: Final analysis and cleanup...\n",
            "   Final System Statistics:\n",
            "     Runtime: 3.8 minutes\n",
            "     Total events: 85\n",
            "     Total messages: 25\n",
            "     Error rate: 0.00%\n",
            "     Avg processing time: 0.024s\n",
            "     System throughput: 0.1 messages/second\n",
            "\n",
            "   Stopping all agents and monitoring...\n",
            "ğŸ›‘ Alice processing loop stopped\n",
            "â¹ï¸  MonitoredAgent Alice stopped\n",
            "ğŸ›‘ Bob processing loop stopped\n",
            "â¹ï¸  MonitoredAgent Bob stopped\n",
            "ğŸ›‘ Charlie processing loop stopped\n",
            "â¹ï¸  MonitoredAgent Charlie stopped\n",
            "ğŸ›‘ Diana processing loop stopped\n",
            "â¹ï¸  MonitoredAgent Diana stopped\n",
            "ğŸ›‘ Erik processing loop stopped\n",
            "â¹ï¸  MonitoredAgent Erik stopped\n",
            "ğŸ›‘ NeuroMonitor background loop stopped\n",
            "â¹ï¸  NeuroMonitor stopped\n",
            "âœ… Tutorial 5 Complete!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SUMMARY OF WHAT WE LEARNED\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ğŸ“š WHAT WE LEARNED:\")\n",
        "\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"1. ğŸ” Built a comprehensive monitoring system\")\n",
        "\n",
        "print(\"   - Event-driven monitoring with structured logging\")\n",
        "\n",
        "print(\"   - Performance metrics collection and analysis\")\n",
        "\n",
        "print(\"   - Real-time alerting with customizable thresholds\")\n",
        "\n",
        "print(\"   - Multi-agent system observability\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"2. ğŸ“Š Implemented production-ready monitoring patterns\")\n",
        "\n",
        "print(\"   - Automatic instrumentation of agent behaviors\")\n",
        "\n",
        "print(\"   - Health monitoring and trend analysis\")\n",
        "\n",
        "print(\"   - Performance bottleneck identification\")\n",
        "\n",
        "print(\"   - Error tracking and recovery monitoring\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"3. ğŸ¯ Created intelligent monitored agents\")\n",
        "\n",
        "print(\"   - Personality-based behavior monitoring\")\n",
        "\n",
        "print(\"   - Conversation pattern analysis\")\n",
        "\n",
        "print(\"   - Resource utilization measurement\")\n",
        "\n",
        "print(\"   - Comparative performance analysis\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"4. ğŸ“ˆ Added interactive monitoring dashboards\")\n",
        "\n",
        "print(\"   - Real-time performance visualization\")\n",
        "\n",
        "print(\"   - System health trend monitoring\")\n",
        "\n",
        "print(\"   - Event correlation and analysis\")\n",
        "\n",
        "print(\"   - Agent performance comparison\")\n",
        "\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWptG8p5sjVE",
        "outputId": "ab20531a-3f78-42df-d96f-65d3ad6603e8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“š WHAT WE LEARNED:\n",
            "========================================\n",
            "1. ğŸ” Built a comprehensive monitoring system\n",
            "   - Event-driven monitoring with structured logging\n",
            "   - Performance metrics collection and analysis\n",
            "   - Real-time alerting with customizable thresholds\n",
            "   - Multi-agent system observability\n",
            "\n",
            "2. ğŸ“Š Implemented production-ready monitoring patterns\n",
            "   - Automatic instrumentation of agent behaviors\n",
            "   - Health monitoring and trend analysis\n",
            "   - Performance bottleneck identification\n",
            "   - Error tracking and recovery monitoring\n",
            "\n",
            "3. ğŸ¯ Created intelligent monitored agents\n",
            "   - Personality-based behavior monitoring\n",
            "   - Conversation pattern analysis\n",
            "   - Resource utilization measurement\n",
            "   - Comparative performance analysis\n",
            "\n",
            "4. ğŸ“ˆ Added interactive monitoring dashboards\n",
            "   - Real-time performance visualization\n",
            "   - System health trend monitoring\n",
            "   - Event correlation and analysis\n",
            "   - Agent performance comparison\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMON ERRORS AND SOLUTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"âš ï¸  COMMON ERRORS AND SOLUTIONS:\")\n",
        "\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"1. ğŸ› Missing monitoring events\")\n",
        "\n",
        "print(\"   Problem: Events not being logged or lost\")\n",
        "\n",
        "print(\"   Solution: Check if monitor.log_event() is being called\")\n",
        "\n",
        "print(\"   Solution: Verify agent is registered with monitor\")\n",
        "\n",
        "print(\"   Solution: Ensure monitoring system is started\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"2. ğŸ› Performance alerts not triggering\")\n",
        "\n",
        "print(\"   Problem: Thresholds too high or metrics not collected\")\n",
        "\n",
        "print(\"   Solution: Lower alert thresholds for testing\")\n",
        "\n",
        "print(\"   Solution: Check metrics collection timing\")\n",
        "\n",
        "print(\"   Solution: Verify agent performance data updates\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"3. ğŸ› Memory usage growing over time\")\n",
        "\n",
        "print(\"   Problem: Event storage growing without bounds\")\n",
        "\n",
        "print(\"   Solution: Already handled with deque(maxlen=...)\")\n",
        "\n",
        "print(\"   Solution: Monitor NeuroMonitor's own memory usage\")\n",
        "\n",
        "print(\"   Solution: Adjust max_events parameter as needed\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"4. ğŸ› Monitoring affecting agent performance\")\n",
        "\n",
        "print(\"   Problem: Too much monitoring overhead\")\n",
        "\n",
        "print(\"   Solution: Use threading locks judiciously\")\n",
        "\n",
        "print(\"   Solution: Batch metrics updates when possible\")\n",
        "\n",
        "print(\"   Solution: Sample events rather than logging everything\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"5. ğŸ› Agents not starting properly\")\n",
        "\n",
        "print(\"   Problem: Race conditions during startup\")\n",
        "\n",
        "print(\"   Solution: Register agents before starting them\")\n",
        "\n",
        "print(\"   Solution: Add delays between agent starts\")\n",
        "\n",
        "print(\"   Solution: Verify agent status after starting\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"6. ğŸ› Visualization not displaying data\")\n",
        "\n",
        "print(\"   Problem: Empty or missing metrics data\")\n",
        "\n",
        "print(\"   Solution: Ensure agents have processed messages\")\n",
        "\n",
        "print(\"   Solution: Wait for metrics collection cycle\")\n",
        "\n",
        "print(\"   Solution: Check that Plotly is installed\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"ğŸ‰ Ready for Tutorial 6: Configuration Management!\")\n",
        "\n",
        "print(\"   Next we'll add flexible configuration systems...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHyrtbl5syWV",
        "outputId": "8d7d1586-43c0-4cfb-fa42-b33afe987c1b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸  COMMON ERRORS AND SOLUTIONS:\n",
            "========================================\n",
            "1. ğŸ› Missing monitoring events\n",
            "   Problem: Events not being logged or lost\n",
            "   Solution: Check if monitor.log_event() is being called\n",
            "   Solution: Verify agent is registered with monitor\n",
            "   Solution: Ensure monitoring system is started\n",
            "\n",
            "2. ğŸ› Performance alerts not triggering\n",
            "   Problem: Thresholds too high or metrics not collected\n",
            "   Solution: Lower alert thresholds for testing\n",
            "   Solution: Check metrics collection timing\n",
            "   Solution: Verify agent performance data updates\n",
            "\n",
            "3. ğŸ› Memory usage growing over time\n",
            "   Problem: Event storage growing without bounds\n",
            "   Solution: Already handled with deque(maxlen=...)\n",
            "   Solution: Monitor NeuroMonitor's own memory usage\n",
            "   Solution: Adjust max_events parameter as needed\n",
            "\n",
            "4. ğŸ› Monitoring affecting agent performance\n",
            "   Problem: Too much monitoring overhead\n",
            "   Solution: Use threading locks judiciously\n",
            "   Solution: Batch metrics updates when possible\n",
            "   Solution: Sample events rather than logging everything\n",
            "\n",
            "5. ğŸ› Agents not starting properly\n",
            "   Problem: Race conditions during startup\n",
            "   Solution: Register agents before starting them\n",
            "   Solution: Add delays between agent starts\n",
            "   Solution: Verify agent status after starting\n",
            "\n",
            "6. ğŸ› Visualization not displaying data\n",
            "   Problem: Empty or missing metrics data\n",
            "   Solution: Ensure agents have processed messages\n",
            "   Solution: Wait for metrics collection cycle\n",
            "   Solution: Check that Plotly is installed\n",
            "\n",
            "ğŸ‰ Ready for Tutorial 6: Configuration Management!\n",
            "   Next we'll add flexible configuration systems...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ğŸ”’ **INTELLECTUAL PROPERTY & LICENSE NOTICE**\n",
        "\n",
        "This tutorial and its contents â€” including code, architecture, narrative examples, and educational structure â€” are the intellectual property of **Shalini Ananda, PhD** and part of the **Neuron Framework** under a **Modified MIT License with Attribution**.\n",
        "\n",
        "- Commercial use, redistribution, or derivative works **must** include clear and visible attribution to the original author.\n",
        "- Use in products, consulting engagements, or educational materials **must reference this repository and author name.**\n",
        "- Removal of author credit or misrepresentation of origin constitutes **a violation of the license and may trigger legal action.**\n",
        "- You may **not white-label, obfuscate, or rebrand** this work without explicit, written permission.\n",
        "\n",
        "Use of this tutorial in Colab or any other platform implies agreement with these terms.\n",
        "\n",
        "ğŸ“˜ **License**: [LICENSE.md](../LICENSE.md)  \n",
        "ğŸ“Œ **Notice**: [NOTICE.md](../NOTICE.md)  \n",
        "ğŸ§  **Author**: [Shalini Ananda, PhD](https://github.com/ShaliniAnandaPhD)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iXkCJIyftIpD"
      }
    }
  ]
}