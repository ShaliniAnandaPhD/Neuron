{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlseplZyghrYbCZmv3YBW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/Neuron/blob/main/Tutorial_12_Learning_from_Experience_Adaptive_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Tutorial 11, you built sophisticated deliberative reasoning systems.\n",
        "Now we're adding comprehensive learning capabilities - agents that improve  their performance through experience, adapt to new situations, and develop expertise over time.\n",
        "\n",
        " What you'll learn:\n",
        "\n",
        " • Experience-based learning and adaptation mechanisms\n",
        "\n",
        " • Pattern recognition and knowledge extraction from interactions\n",
        "\n",
        " • Multi-modal learning (supervised, unsupervised, reinforcement)\n",
        "\n",
        " • Expertise development and specialization\n",
        "\n",
        " • Knowledge transfer between agents\n",
        "\n",
        " • Continuous improvement and performance optimization\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "True intelligence emerges from the ability to learn and adapt. Agents that\n",
        "can improve from experience become increasingly valuable over time, developing expertise that static systems cannot match. This enables them to handle novel situations and continuously optimize their performance."
      ],
      "metadata": {
        "id": "dtyAvmNz7jSn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM9Fx10z7Wvc",
        "outputId": "bd1aebb2-7b77-4bbb-835e-9dbcaa96bb07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12: Learning from Experience - Adaptive Agents\n",
            "=======================================================\n",
            "\n",
            "Building agents that learn, adapt, and improve over time...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Tutorial 12: Learning from Experience - Adaptive Agents\")\n",
        "print(\"=\" * 55)\n",
        "print()\n",
        "print(\"Building agents that learn, adapt, and improve over time...\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essential imports\n",
        "import uuid\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import json\n",
        "import threading\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple, Callable, Union\n",
        "from enum import Enum\n",
        "from collections import defaultdict, deque\n",
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "GvTZNaMh76Ki"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CORE LEARNING TYPES AND CONCEPTS\n",
        "# =============================================================================\n",
        "\n",
        "class LearningType(Enum):\n",
        "    \"\"\"Types of learning experiences\"\"\"\n",
        "    SUPERVISED = \"supervised\"           # Learning from labeled examples\n",
        "    UNSUPERVISED = \"unsupervised\"      # Finding patterns in unlabeled data\n",
        "    REINFORCEMENT = \"reinforcement\"    # Learning from rewards/penalties\n",
        "    IMITATION = \"imitation\"            # Learning by observing others\n",
        "    TRANSFER = \"transfer\"              # Applying knowledge from other domains\n",
        "\n",
        "class ExperienceType(Enum):\n",
        "    \"\"\"Categories of experiences for learning\"\"\"\n",
        "    SUCCESS = \"success\"                # Successful task completion\n",
        "    FAILURE = \"failure\"                # Failed attempts\n",
        "    FEEDBACK = \"feedback\"              # External feedback/correction\n",
        "    OBSERVATION = \"observation\"        # Observing other agents\n",
        "    EXPLORATION = \"exploration\"        # Trying new approaches\n",
        "\n",
        "class LearningObjective(Enum):\n",
        "    \"\"\"What the agent is trying to optimize\"\"\"\n",
        "    ACCURACY = \"accuracy\"              # Correctness of responses\n",
        "    EFFICIENCY = \"efficiency\"          # Speed of task completion\n",
        "    QUALITY = \"quality\"                # Quality of outputs\n",
        "    ADAPTABILITY = \"adaptability\"      # Ability to handle new situations\n",
        "    ROBUSTNESS = \"robustness\"          # Consistency across conditions\n",
        "\n",
        "@dataclass\n",
        "class LearningExperience:\n",
        "    \"\"\"\n",
        "    A single learning experience with context and outcomes\n",
        "\n",
        "    This represents one instance of learning - what happened,\n",
        "    what was learned, and how it can be applied in the future.\n",
        "    \"\"\"\n",
        "    id: str\n",
        "    experience_type: ExperienceType\n",
        "    learning_type: LearningType\n",
        "\n",
        "    # Context of the experience\n",
        "    context: Dict[str, Any] = field(default_factory=dict)\n",
        "    task_description: str = \"\"\n",
        "    input_data: Any = None\n",
        "\n",
        "    # Actions and outcomes\n",
        "    action_taken: str = \"\"\n",
        "    outcome: Any = None\n",
        "    success: bool = False\n",
        "    performance_metrics: Dict[str, float] = field(default_factory=dict)\n",
        "\n",
        "    # Learning content\n",
        "    lesson_learned: str = \"\"\n",
        "    patterns_identified: List[str] = field(default_factory=list)\n",
        "    knowledge_gained: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    # Metadata\n",
        "    timestamp: float = field(default_factory=time.time)\n",
        "    confidence: float = 0.5\n",
        "    importance: float = 0.5\n",
        "    source_agent: str = \"\"\n",
        "\n",
        "    def get_age(self) -> float:\n",
        "        \"\"\"Get experience age in days\"\"\"\n",
        "        return (time.time() - self.timestamp) / (24 * 3600)\n",
        "\n",
        "    def calculate_relevance(self, current_context: Dict[str, Any]) -> float:\n",
        "        \"\"\"Calculate how relevant this experience is to current context\"\"\"\n",
        "        if not current_context or not self.context:\n",
        "            return 0.0\n",
        "\n",
        "        # Simple context matching\n",
        "        common_keys = set(current_context.keys()) & set(self.context.keys())\n",
        "        if not common_keys:\n",
        "            return 0.0\n",
        "\n",
        "        relevance = 0.0\n",
        "        for key in common_keys:\n",
        "            if current_context[key] == self.context[key]:\n",
        "                relevance += 1.0\n",
        "\n",
        "        return relevance / len(self.context)\n",
        "\n",
        "@dataclass\n",
        "class LearningPattern:\n",
        "    \"\"\"\n",
        "    A learned pattern that can be applied to new situations\n",
        "\n",
        "    This represents extracted knowledge that generalizes\n",
        "    beyond specific experiences.\n",
        "    \"\"\"\n",
        "    id: str\n",
        "    pattern_type: str\n",
        "    description: str\n",
        "\n",
        "    # Pattern definition\n",
        "    conditions: Dict[str, Any] = field(default_factory=dict)\n",
        "    actions: List[str] = field(default_factory=list)\n",
        "    expected_outcomes: Dict[str, float] = field(default_factory=dict)\n",
        "\n",
        "    # Pattern statistics\n",
        "    times_observed: int = 0\n",
        "    times_applied: int = 0\n",
        "    success_rate: float = 0.0\n",
        "    confidence: float = 0.0\n",
        "\n",
        "    # Supporting evidence\n",
        "    supporting_experiences: List[str] = field(default_factory=list)\n",
        "    last_updated: float = field(default_factory=time.time)\n",
        "\n",
        "    def update_from_experience(self, experience: LearningExperience, outcome_success: bool):\n",
        "        \"\"\"Update pattern based on new experience\"\"\"\n",
        "        self.times_observed += 1\n",
        "        if outcome_success:\n",
        "            self.times_applied += 1\n",
        "\n",
        "        # Update success rate\n",
        "        if self.times_observed > 0:\n",
        "            self.success_rate = self.times_applied / self.times_observed\n",
        "\n",
        "        # Update confidence based on number of observations\n",
        "        self.confidence = min(1.0, self.times_observed / 10.0)\n",
        "\n",
        "        # Add to supporting evidence\n",
        "        self.supporting_experiences.append(experience.id)\n",
        "        if len(self.supporting_experiences) > 20:  # Keep only recent evidence\n",
        "            self.supporting_experiences = self.supporting_experiences[-20:]\n",
        "\n",
        "        self.last_updated = time.time()\n",
        "\n",
        "# =============================================================================\n",
        "# TEST THE FOUNDATION CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing foundation classes...\")\n",
        "\n",
        "# Create a sample learning experience\n",
        "sample_experience = LearningExperience(\n",
        "    id=\"exp_001\",\n",
        "    experience_type=ExperienceType.SUCCESS,\n",
        "    learning_type=LearningType.SUPERVISED,\n",
        "    context={'domain': 'customer_service', 'urgency': 'high'},\n",
        "    task_description=\"Handle urgent customer complaint\",\n",
        "    action_taken=\"escalate_to_manager\",\n",
        "    success=True,\n",
        "    performance_metrics={'satisfaction': 0.9, 'resolution_time': 0.8},\n",
        "    lesson_learned=\"Escalation works well for urgent complaints\",\n",
        "    source_agent=\"service_bot\"\n",
        ")\n",
        "\n",
        "print(f\"✅ Created sample experience: {sample_experience.task_description}\")\n",
        "print(f\"   Age: {sample_experience.get_age():.4f} days\")\n",
        "print(f\"   Success: {sample_experience.success}\")\n",
        "\n",
        "# Create a sample learning pattern\n",
        "sample_pattern = LearningPattern(\n",
        "    id=\"pattern_001\",\n",
        "    pattern_type=\"success_pattern\",\n",
        "    description=\"Escalation pattern for urgent issues\",\n",
        "    conditions={'domain': 'customer_service', 'urgency': 'high'},\n",
        "    actions=['escalate_to_manager'],\n",
        "    times_observed=5,\n",
        "    times_applied=4,\n",
        "    confidence=0.8\n",
        ")\n",
        "\n",
        "print(f\"✅ Created sample pattern: {sample_pattern.description}\")\n",
        "print(f\"   Success rate: {sample_pattern.success_rate:.1%}\")\n",
        "print(f\"   Confidence: {sample_pattern.confidence:.1f}\")\n",
        "\n",
        "# Test relevance calculation\n",
        "test_context = {'domain': 'customer_service', 'urgency': 'high', 'customer_type': 'premium'}\n",
        "relevance = sample_experience.calculate_relevance(test_context)\n",
        "print(f\"✅ Relevance to test context: {relevance:.2f}\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Foundation classes working correctly!\")\n",
        "print(\"   Ready for Part 2: Experience Memory System\")\n",
        "print()\n",
        "print(\"📋 Summary of what we built:\")\n",
        "print(\"   • LearningExperience - Individual learning moments\")\n",
        "print(\"   • LearningPattern - Extracted knowledge patterns\")\n",
        "print(\"   • Learning types (supervised, reinforcement, etc.)\")\n",
        "print(\"   • Experience types (success, failure, feedback, etc.)\")\n",
        "print(\"   • Learning objectives (accuracy, efficiency, etc.)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooN5_ge07-Y0",
        "outputId": "4ca6309d-1424-4a18-fe65-b4a92fcdc570"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Testing foundation classes...\n",
            "✅ Created sample experience: Handle urgent customer complaint\n",
            "   Age: 0.0000 days\n",
            "   Success: True\n",
            "✅ Created sample pattern: Escalation pattern for urgent issues\n",
            "   Success rate: 0.0%\n",
            "   Confidence: 0.8\n",
            "✅ Relevance to test context: 1.00\n",
            "\n",
            "🎉 Foundation classes working correctly!\n",
            "   Ready for Part 2: Experience Memory System\n",
            "\n",
            "📋 Summary of what we built:\n",
            "   • LearningExperience - Individual learning moments\n",
            "   • LearningPattern - Extracted knowledge patterns\n",
            "   • Learning types (supervised, reinforcement, etc.)\n",
            "   • Experience types (success, failure, feedback, etc.)\n",
            "   • Learning objectives (accuracy, efficiency, etc.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tutorial 12 Part 2: Experience Memory System\")\n",
        "print(\"=\" * 45)\n",
        "print(\"Building sophisticated memory for learning experiences...\")\n",
        "print()\n",
        "\n",
        "# Make sure you've run Part 1 first!\n",
        "# This part builds on the classes from Part 1\n",
        "\n",
        "class ExperienceMemory:\n",
        "    \"\"\"\n",
        "    Specialized memory system for learning experiences\n",
        "\n",
        "    This manages the storage, retrieval, and organization\n",
        "    of learning experiences for effective knowledge extraction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, capacity: int = 1000):\n",
        "        self.capacity = capacity\n",
        "        self.experiences: Dict[str, LearningExperience] = {}\n",
        "        self.patterns: Dict[str, LearningPattern] = {}\n",
        "\n",
        "        # Indices for efficient retrieval\n",
        "        self.type_index: Dict[ExperienceType, List[str]] = defaultdict(list)\n",
        "        self.context_index: Dict[str, List[str]] = defaultdict(list)\n",
        "        self.success_index: Dict[bool, List[str]] = defaultdict(list)\n",
        "        self.temporal_index: List[Tuple[float, str]] = []  # (timestamp, experience_id)\n",
        "\n",
        "        print(f\"🧠 Experience memory initialized (capacity: {capacity})\")\n",
        "\n",
        "    def add_experience(self, experience: LearningExperience) -> str:\n",
        "        \"\"\"Add a new learning experience\"\"\"\n",
        "\n",
        "        # Add to main storage\n",
        "        self.experiences[experience.id] = experience\n",
        "\n",
        "        # Update indices\n",
        "        self.type_index[experience.experience_type].append(experience.id)\n",
        "        self.success_index[experience.success].append(experience.id)\n",
        "        self.temporal_index.append((experience.timestamp, experience.id))\n",
        "\n",
        "        # Context indexing\n",
        "        for key, value in experience.context.items():\n",
        "            context_key = f\"{key}:{value}\"\n",
        "            self.context_index[context_key].append(experience.id)\n",
        "\n",
        "        # Maintain capacity\n",
        "        if len(self.experiences) > self.capacity:\n",
        "            self._evict_old_experiences()\n",
        "\n",
        "        print(f\"   📝 Stored experience: {experience.task_description[:50]}...\")\n",
        "        return experience.id\n",
        "\n",
        "    def _evict_old_experiences(self):\n",
        "        \"\"\"Remove oldest experiences when at capacity\"\"\"\n",
        "        # Sort by timestamp and remove oldest\n",
        "        self.temporal_index.sort()\n",
        "        to_remove = self.temporal_index[:len(self.temporal_index) - self.capacity + 100]\n",
        "\n",
        "        for _, exp_id in to_remove:\n",
        "            if exp_id in self.experiences:\n",
        "                self._remove_from_indices(exp_id)\n",
        "                del self.experiences[exp_id]\n",
        "\n",
        "        # Update temporal index\n",
        "        self.temporal_index = self.temporal_index[len(to_remove):]\n",
        "\n",
        "    def _remove_from_indices(self, experience_id: str):\n",
        "        \"\"\"Remove experience from all indices\"\"\"\n",
        "        experience = self.experiences.get(experience_id)\n",
        "        if not experience:\n",
        "            return\n",
        "\n",
        "        # Remove from type index\n",
        "        if experience_id in self.type_index[experience.experience_type]:\n",
        "            self.type_index[experience.experience_type].remove(experience_id)\n",
        "\n",
        "        # Remove from success index\n",
        "        if experience_id in self.success_index[experience.success]:\n",
        "            self.success_index[experience.success].remove(experience_id)\n",
        "\n",
        "        # Remove from context index\n",
        "        for key, value in experience.context.items():\n",
        "            context_key = f\"{key}:{value}\"\n",
        "            if experience_id in self.context_index[context_key]:\n",
        "                self.context_index[context_key].remove(experience_id)\n",
        "\n",
        "    def find_similar_experiences(self, context: Dict[str, Any],\n",
        "                                experience_type: ExperienceType = None,\n",
        "                                limit: int = 10) -> List[LearningExperience]:\n",
        "        \"\"\"Find experiences similar to given context\"\"\"\n",
        "\n",
        "        candidate_ids = set()\n",
        "\n",
        "        # Filter by experience type if specified\n",
        "        if experience_type:\n",
        "            candidate_ids = set(self.type_index[experience_type])\n",
        "        else:\n",
        "            candidate_ids = set(self.experiences.keys())\n",
        "\n",
        "        # Filter by context similarity\n",
        "        context_candidates = set()\n",
        "        for key, value in context.items():\n",
        "            context_key = f\"{key}:{value}\"\n",
        "            context_candidates.update(self.context_index[context_key])\n",
        "\n",
        "        if context_candidates:\n",
        "            candidate_ids &= context_candidates\n",
        "\n",
        "        # Score and rank by relevance\n",
        "        scored_experiences = []\n",
        "        for exp_id in candidate_ids:\n",
        "            if exp_id in self.experiences:\n",
        "                experience = self.experiences[exp_id]\n",
        "                relevance = experience.calculate_relevance(context)\n",
        "                scored_experiences.append((relevance, experience))\n",
        "\n",
        "        # Sort by relevance and return top results\n",
        "        scored_experiences.sort(key=lambda x: x[0], reverse=True)\n",
        "        return [exp for _, exp in scored_experiences[:limit]]\n",
        "\n",
        "    def get_success_patterns(self, min_observations: int = 3) -> List[LearningPattern]:\n",
        "        \"\"\"Extract success patterns from successful experiences\"\"\"\n",
        "\n",
        "        successful_experiences = [\n",
        "            self.experiences[exp_id]\n",
        "            for exp_id in self.success_index[True]\n",
        "            if exp_id in self.experiences\n",
        "        ]\n",
        "\n",
        "        if len(successful_experiences) < min_observations:\n",
        "            return []\n",
        "\n",
        "        # Group by similar contexts\n",
        "        context_groups = defaultdict(list)\n",
        "        for exp in successful_experiences:\n",
        "            # Create a simplified context signature\n",
        "            context_sig = tuple(sorted(exp.context.items()))\n",
        "            context_groups[context_sig].append(exp)\n",
        "\n",
        "        patterns = []\n",
        "        for context_sig, group_experiences in context_groups.items():\n",
        "            if len(group_experiences) >= min_observations:\n",
        "                # Create pattern from this group\n",
        "                pattern_id = f\"pattern_{len(self.patterns)}\"\n",
        "\n",
        "                # Extract common elements\n",
        "                common_actions = []\n",
        "                action_counts = defaultdict(int)\n",
        "\n",
        "                for exp in group_experiences:\n",
        "                    if exp.action_taken:\n",
        "                        action_counts[exp.action_taken] += 1\n",
        "\n",
        "                # Actions that appear in most experiences\n",
        "                for action, count in action_counts.items():\n",
        "                    if count >= len(group_experiences) * 0.6:  # 60% threshold\n",
        "                        common_actions.append(action)\n",
        "\n",
        "                if common_actions:\n",
        "                    pattern = LearningPattern(\n",
        "                        id=pattern_id,\n",
        "                        pattern_type=\"success_pattern\",\n",
        "                        description=f\"Successful pattern with {len(group_experiences)} observations\",\n",
        "                        conditions=dict(context_sig),\n",
        "                        actions=common_actions,\n",
        "                        times_observed=len(group_experiences),\n",
        "                        times_applied=len(group_experiences),\n",
        "                        success_rate=1.0,\n",
        "                        confidence=min(1.0, len(group_experiences) / 10.0),\n",
        "                        supporting_experiences=[exp.id for exp in group_experiences]\n",
        "                    )\n",
        "                    patterns.append(pattern)\n",
        "                    self.patterns[pattern_id] = pattern\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def get_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get memory statistics\"\"\"\n",
        "        total_experiences = len(self.experiences)\n",
        "        if total_experiences == 0:\n",
        "            return {'total_experiences': 0}\n",
        "\n",
        "        # Type distribution\n",
        "        type_dist = {}\n",
        "        for exp_type, exp_list in self.type_index.items():\n",
        "            type_dist[exp_type.value] = len(exp_list)\n",
        "\n",
        "        # Success rate\n",
        "        successful = len(self.success_index[True])\n",
        "        success_rate = successful / total_experiences if total_experiences > 0 else 0.0\n",
        "\n",
        "        # Age distribution\n",
        "        current_time = time.time()\n",
        "        ages = [(current_time - exp.timestamp) / (24 * 3600) for exp in self.experiences.values()]\n",
        "        avg_age = sum(ages) / len(ages) if ages else 0.0\n",
        "\n",
        "        return {\n",
        "            'total_experiences': total_experiences,\n",
        "            'success_rate': success_rate,\n",
        "            'type_distribution': type_dist,\n",
        "            'patterns_discovered': len(self.patterns),\n",
        "            'average_age_days': avg_age,\n",
        "            'capacity_utilization': total_experiences / self.capacity\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# TEST THE EXPERIENCE MEMORY SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing Experience Memory System...\")\n",
        "\n",
        "# Create memory system\n",
        "memory = ExperienceMemory(capacity=50)\n",
        "\n",
        "# Create diverse sample experiences\n",
        "sample_experiences = [\n",
        "    LearningExperience(\n",
        "        id=\"exp_001\",\n",
        "        experience_type=ExperienceType.SUCCESS,\n",
        "        learning_type=LearningType.SUPERVISED,\n",
        "        context={'domain': 'customer_service', 'urgency': 'high'},\n",
        "        task_description=\"Handle urgent customer complaint\",\n",
        "        action_taken=\"escalate_to_manager\",\n",
        "        success=True,\n",
        "        performance_metrics={'satisfaction': 0.9, 'resolution_time': 0.8}\n",
        "    ),\n",
        "    LearningExperience(\n",
        "        id=\"exp_002\",\n",
        "        experience_type=ExperienceType.FAILURE,\n",
        "        learning_type=LearningType.REINFORCEMENT,\n",
        "        context={'domain': 'customer_service', 'urgency': 'low'},\n",
        "        task_description=\"Handle routine customer inquiry\",\n",
        "        action_taken=\"provide_standard_response\",\n",
        "        success=False,\n",
        "        performance_metrics={'satisfaction': 0.3, 'resolution_time': 0.6}\n",
        "    ),\n",
        "    LearningExperience(\n",
        "        id=\"exp_003\",\n",
        "        experience_type=ExperienceType.SUCCESS,\n",
        "        learning_type=LearningType.SUPERVISED,\n",
        "        context={'domain': 'customer_service', 'urgency': 'medium'},\n",
        "        task_description=\"Process customer refund request\",\n",
        "        action_taken=\"verify_and_approve\",\n",
        "        success=True,\n",
        "        performance_metrics={'satisfaction': 0.85, 'resolution_time': 0.9}\n",
        "    ),\n",
        "    LearningExperience(\n",
        "        id=\"exp_004\",\n",
        "        experience_type=ExperienceType.SUCCESS,\n",
        "        learning_type=LearningType.SUPERVISED,\n",
        "        context={'domain': 'customer_service', 'urgency': 'high'},\n",
        "        task_description=\"Handle urgent billing issue\",\n",
        "        action_taken=\"escalate_to_manager\",\n",
        "        success=True,\n",
        "        performance_metrics={'satisfaction': 0.8, 'resolution_time': 0.7}\n",
        "    ),\n",
        "    LearningExperience(\n",
        "        id=\"exp_005\",\n",
        "        experience_type=ExperienceType.OBSERVATION,\n",
        "        learning_type=LearningType.IMITATION,\n",
        "        context={'domain': 'technical_support', 'complexity': 'high'},\n",
        "        task_description=\"Debug complex technical issue\",\n",
        "        action_taken=\"systematic_diagnosis\",\n",
        "        success=True,\n",
        "        performance_metrics={'problem_solved': 1.0, 'time_taken': 0.6}\n",
        "    )\n",
        "]\n",
        "\n",
        "# Add experiences to memory\n",
        "print(\"\\n📝 Adding experiences to memory:\")\n",
        "for exp in sample_experiences:\n",
        "    memory.add_experience(exp)\n",
        "\n",
        "# Test memory retrieval\n",
        "print(\"\\n🔍 Testing memory retrieval:\")\n",
        "\n",
        "# Find similar experiences\n",
        "similar_context = {'domain': 'customer_service', 'urgency': 'high'}\n",
        "similar_experiences = memory.find_similar_experiences(similar_context, limit=5)\n",
        "print(f\"   Found {len(similar_experiences)} experiences for context: {similar_context}\")\n",
        "\n",
        "for exp in similar_experiences:\n",
        "    print(f\"     - {exp.task_description} (action: {exp.action_taken})\")\n",
        "\n",
        "# Find successful experiences\n",
        "successful_experiences = memory.find_similar_experiences(\n",
        "    context={'domain': 'customer_service'},\n",
        "    experience_type=ExperienceType.SUCCESS,\n",
        "    limit=3\n",
        ")\n",
        "print(f\"\\n   Found {len(successful_experiences)} successful customer service experiences\")\n",
        "\n",
        "# Test pattern discovery\n",
        "print(\"\\n🔍 Testing pattern discovery:\")\n",
        "patterns = memory.get_success_patterns(min_observations=2)\n",
        "print(f\"   Discovered {len(patterns)} success patterns\")\n",
        "\n",
        "for pattern in patterns:\n",
        "    print(f\"     - {pattern.description}\")\n",
        "    print(f\"       Conditions: {pattern.conditions}\")\n",
        "    print(f\"       Actions: {pattern.actions}\")\n",
        "    print(f\"       Confidence: {pattern.confidence:.2f}\")\n",
        "\n",
        "# Get memory statistics\n",
        "print(\"\\n📊 Memory Statistics:\")\n",
        "stats = memory.get_statistics()\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"   {key}:\")\n",
        "        for subkey, subvalue in value.items():\n",
        "            print(f\"     {subkey}: {subvalue}\")\n",
        "    else:\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key}: {value:.3f}\")\n",
        "        else:\n",
        "            print(f\"   {key}: {value}\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Experience Memory System working correctly!\")\n",
        "print(\"   Ready for Part 3: Learning Engine\")\n",
        "print()\n",
        "print(\"📋 Summary of what we built:\")\n",
        "print(\"   • ExperienceMemory - Efficient storage and retrieval\")\n",
        "print(\"   • Smart indexing by type, context, and success\")\n",
        "print(\"   • Pattern discovery from successful experiences\")\n",
        "print(\"   • Memory capacity management with eviction\")\n",
        "print(\"   • Similarity search and relevance scoring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvNaECdc8REE",
        "outputId": "ecac6423-5431-42d0-ed5c-0f66a7bba278"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12 Part 2: Experience Memory System\n",
            "=============================================\n",
            "Building sophisticated memory for learning experiences...\n",
            "\n",
            "🧪 Testing Experience Memory System...\n",
            "🧠 Experience memory initialized (capacity: 50)\n",
            "\n",
            "📝 Adding experiences to memory:\n",
            "   📝 Stored experience: Handle urgent customer complaint...\n",
            "   📝 Stored experience: Handle routine customer inquiry...\n",
            "   📝 Stored experience: Process customer refund request...\n",
            "   📝 Stored experience: Handle urgent billing issue...\n",
            "   📝 Stored experience: Debug complex technical issue...\n",
            "\n",
            "🔍 Testing memory retrieval:\n",
            "   Found 4 experiences for context: {'domain': 'customer_service', 'urgency': 'high'}\n",
            "     - Handle urgent customer complaint (action: escalate_to_manager)\n",
            "     - Handle urgent billing issue (action: escalate_to_manager)\n",
            "     - Handle routine customer inquiry (action: provide_standard_response)\n",
            "     - Process customer refund request (action: verify_and_approve)\n",
            "\n",
            "   Found 3 successful customer service experiences\n",
            "\n",
            "🔍 Testing pattern discovery:\n",
            "   Discovered 1 success patterns\n",
            "     - Successful pattern with 2 observations\n",
            "       Conditions: {'domain': 'customer_service', 'urgency': 'high'}\n",
            "       Actions: ['escalate_to_manager']\n",
            "       Confidence: 0.20\n",
            "\n",
            "📊 Memory Statistics:\n",
            "   total_experiences: 5\n",
            "   success_rate: 0.800\n",
            "   type_distribution:\n",
            "     success: 3\n",
            "     failure: 1\n",
            "     observation: 1\n",
            "   patterns_discovered: 1\n",
            "   average_age_days: 0.000\n",
            "   capacity_utilization: 0.100\n",
            "\n",
            "🎉 Experience Memory System working correctly!\n",
            "   Ready for Part 3: Learning Engine\n",
            "\n",
            "📋 Summary of what we built:\n",
            "   • ExperienceMemory - Efficient storage and retrieval\n",
            "   • Smart indexing by type, context, and success\n",
            "   • Pattern discovery from successful experiences\n",
            "   • Memory capacity management with eviction\n",
            "   • Similarity search and relevance scoring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this after Parts 1 and 2 to build the core learning processing system\n",
        "\n",
        "print(\"Tutorial 12 Part 3: Learning Engine\")\n",
        "print(\"=\" * 35)\n",
        "print(\"Building the core learning processing system...\")\n",
        "print()\n",
        "\n",
        "# Make sure you've run Parts 1 and 2 first!\n",
        "\n",
        "class LearningEngine:\n",
        "    \"\"\"\n",
        "    Core learning engine that processes experiences and extracts knowledge\n",
        "\n",
        "    This is the heart of the learning system - it takes raw experiences\n",
        "    and transforms them into actionable knowledge and patterns.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_objectives: List[LearningObjective] = None):\n",
        "        self.learning_objectives = learning_objectives or [LearningObjective.ACCURACY]\n",
        "        self.experience_memory = ExperienceMemory()\n",
        "        self.learning_algorithms = {}\n",
        "        self.performance_baselines = {}\n",
        "\n",
        "        # Learning statistics\n",
        "        self.learning_sessions = 0\n",
        "        self.patterns_discovered = 0\n",
        "        self.knowledge_items = 0\n",
        "\n",
        "        self._initialize_algorithms()\n",
        "        print(f\"🎓 Learning engine initialized with {len(self.learning_objectives)} objectives\")\n",
        "\n",
        "    def _initialize_algorithms(self):\n",
        "        \"\"\"Initialize learning algorithms for different learning types\"\"\"\n",
        "        self.learning_algorithms = {\n",
        "            LearningType.SUPERVISED: self._supervised_learning,\n",
        "            LearningType.UNSUPERVISED: self._unsupervised_learning,\n",
        "            LearningType.REINFORCEMENT: self._reinforcement_learning,\n",
        "            LearningType.IMITATION: self._imitation_learning,\n",
        "            LearningType.TRANSFER: self._transfer_learning\n",
        "        }\n",
        "\n",
        "    def process_experience(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process a single learning experience\"\"\"\n",
        "\n",
        "        # Store the experience\n",
        "        exp_id = self.experience_memory.add_experience(experience)\n",
        "\n",
        "        # Apply appropriate learning algorithm\n",
        "        learning_result = None\n",
        "        if experience.learning_type in self.learning_algorithms:\n",
        "            algorithm = self.learning_algorithms[experience.learning_type]\n",
        "            learning_result = algorithm(experience)\n",
        "\n",
        "        # Update performance tracking\n",
        "        self._update_performance_tracking(experience)\n",
        "\n",
        "        # Trigger pattern discovery if enough new experiences\n",
        "        if len(self.experience_memory.experiences) % 10 == 0:\n",
        "            self._discover_patterns()\n",
        "\n",
        "        return {\n",
        "            'experience_id': exp_id,\n",
        "            'learning_result': learning_result,\n",
        "            'patterns_updated': self.patterns_discovered,\n",
        "            'learning_type': experience.learning_type.value\n",
        "        }\n",
        "\n",
        "    def _supervised_learning(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process supervised learning experience\"\"\"\n",
        "\n",
        "        if not experience.outcome or experience.input_data is None:\n",
        "            return {'error': 'Insufficient data for supervised learning'}\n",
        "\n",
        "        # Extract features from input and label from outcome\n",
        "        features = self._extract_features(experience.input_data, experience.context)\n",
        "        label = self._extract_label(experience.outcome)\n",
        "\n",
        "        # Simple pattern-based supervised learning\n",
        "        pattern_key = f\"supervised_{hash(str(features))}\"\n",
        "\n",
        "        if pattern_key not in self.experience_memory.patterns:\n",
        "            # Create new pattern\n",
        "            pattern = LearningPattern(\n",
        "                id=pattern_key,\n",
        "                pattern_type=\"supervised_mapping\",\n",
        "                description=f\"Input-output mapping from supervised learning\",\n",
        "                conditions=features,\n",
        "                expected_outcomes={'predicted_label': label},\n",
        "                times_observed=1,\n",
        "                confidence=0.1\n",
        "            )\n",
        "            self.experience_memory.patterns[pattern_key] = pattern\n",
        "        else:\n",
        "            # Update existing pattern\n",
        "            pattern = self.experience_memory.patterns[pattern_key]\n",
        "            pattern.update_from_experience(experience, experience.success)\n",
        "\n",
        "        return {\n",
        "            'pattern_id': pattern_key,\n",
        "            'features_extracted': len(features),\n",
        "            'confidence': pattern.confidence\n",
        "        }\n",
        "\n",
        "    def _unsupervised_learning(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process unsupervised learning experience\"\"\"\n",
        "\n",
        "        # Look for patterns in similar experiences\n",
        "        similar_experiences = self.experience_memory.find_similar_experiences(\n",
        "            experience.context,\n",
        "            experience_type=experience.experience_type,\n",
        "            limit=20\n",
        "        )\n",
        "\n",
        "        if len(similar_experiences) < 3:\n",
        "            return {'message': 'Insufficient data for pattern discovery'}\n",
        "\n",
        "        # Cluster similar experiences\n",
        "        clusters = self._cluster_experiences(similar_experiences)\n",
        "\n",
        "        # Create patterns from clusters\n",
        "        patterns_created = 0\n",
        "        for cluster_id, cluster_experiences in clusters.items():\n",
        "            if len(cluster_experiences) >= 3:\n",
        "                pattern_id = f\"unsupervised_cluster_{cluster_id}\"\n",
        "\n",
        "                # Extract common characteristics\n",
        "                common_context = self._extract_common_context(cluster_experiences)\n",
        "                common_actions = self._extract_common_actions(cluster_experiences)\n",
        "\n",
        "                if common_context and common_actions:\n",
        "                    pattern = LearningPattern(\n",
        "                        id=pattern_id,\n",
        "                        pattern_type=\"unsupervised_cluster\",\n",
        "                        description=f\"Discovered pattern from {len(cluster_experiences)} similar experiences\",\n",
        "                        conditions=common_context,\n",
        "                        actions=common_actions,\n",
        "                        times_observed=len(cluster_experiences)\n",
        "                    )\n",
        "                    self.experience_memory.patterns[pattern_id] = pattern\n",
        "                    patterns_created += 1\n",
        "\n",
        "        return {\n",
        "            'clusters_found': len(clusters),\n",
        "            'patterns_created': patterns_created,\n",
        "            'total_experiences_analyzed': len(similar_experiences)\n",
        "        }\n",
        "\n",
        "    def _reinforcement_learning(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process reinforcement learning experience\"\"\"\n",
        "\n",
        "        # Extract reward signal\n",
        "        reward = self._calculate_reward(experience)\n",
        "\n",
        "        # Update action-value estimates\n",
        "        state_action_key = f\"rl_{hash(str(experience.context))}_{experience.action_taken}\"\n",
        "\n",
        "        # Simple Q-learning update\n",
        "        alpha = 0.1  # Learning rate\n",
        "        current_q = self._get_q_value(state_action_key)\n",
        "        new_q = current_q + alpha * (reward - current_q)\n",
        "\n",
        "        # Store updated Q-value as a pattern\n",
        "        pattern = LearningPattern(\n",
        "            id=state_action_key,\n",
        "            pattern_type=\"q_value\",\n",
        "            description=f\"Action value for state-action pair\",\n",
        "            conditions=experience.context,\n",
        "            actions=[experience.action_taken],\n",
        "            expected_outcomes={'q_value': new_q, 'reward': reward},\n",
        "            times_observed=1 if state_action_key not in self.experience_memory.patterns else self.experience_memory.patterns[state_action_key].times_observed + 1\n",
        "        )\n",
        "\n",
        "        self.experience_memory.patterns[state_action_key] = pattern\n",
        "\n",
        "        return {\n",
        "            'reward': reward,\n",
        "            'q_value_updated': new_q,\n",
        "            'action': experience.action_taken,\n",
        "            'learning_rate': alpha\n",
        "        }\n",
        "\n",
        "    def _imitation_learning(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process imitation learning experience\"\"\"\n",
        "\n",
        "        if experience.experience_type != ExperienceType.OBSERVATION:\n",
        "            return {'error': 'Imitation learning requires observation experiences'}\n",
        "\n",
        "        # Extract behavior patterns from observed actions\n",
        "        observed_action = experience.action_taken\n",
        "        context = experience.context\n",
        "\n",
        "        # Create imitation pattern\n",
        "        pattern_id = f\"imitation_{hash(str(context))}\"\n",
        "\n",
        "        if pattern_id in self.experience_memory.patterns:\n",
        "            pattern = self.experience_memory.patterns[pattern_id]\n",
        "            pattern.update_from_experience(experience, experience.success)\n",
        "        else:\n",
        "            pattern = LearningPattern(\n",
        "                id=pattern_id,\n",
        "                pattern_type=\"imitation_behavior\",\n",
        "                description=f\"Behavior pattern learned through imitation\",\n",
        "                conditions=context,\n",
        "                actions=[observed_action],\n",
        "                times_observed=1,\n",
        "                confidence=0.3  # Lower initial confidence for imitation\n",
        "            )\n",
        "            self.experience_memory.patterns[pattern_id] = pattern\n",
        "\n",
        "        return {\n",
        "            'pattern_id': pattern_id,\n",
        "            'observed_action': observed_action,\n",
        "            'context_complexity': len(context),\n",
        "            'pattern_confidence': pattern.confidence\n",
        "        }\n",
        "\n",
        "    def _transfer_learning(self, experience: LearningExperience) -> Dict[str, Any]:\n",
        "        \"\"\"Process transfer learning experience\"\"\"\n",
        "\n",
        "        source_domain = experience.context.get('source_domain')\n",
        "        target_domain = experience.context.get('target_domain')\n",
        "\n",
        "        if not source_domain or not target_domain:\n",
        "            return {'error': 'Transfer learning requires source and target domains'}\n",
        "\n",
        "        # Find patterns from source domain\n",
        "        source_patterns = [\n",
        "            pattern for pattern in self.experience_memory.patterns.values()\n",
        "            if source_domain in str(pattern.conditions)\n",
        "        ]\n",
        "\n",
        "        # Adapt patterns to target domain\n",
        "        adapted_patterns = 0\n",
        "        for source_pattern in source_patterns:\n",
        "            if source_pattern.success_rate > 0.6:  # Only transfer successful patterns\n",
        "\n",
        "                # Create adapted pattern for target domain\n",
        "                adapted_id = f\"transfer_{source_pattern.id}_{target_domain}\"\n",
        "                adapted_conditions = dict(source_pattern.conditions)\n",
        "                adapted_conditions['domain'] = target_domain\n",
        "\n",
        "                adapted_pattern = LearningPattern(\n",
        "                    id=adapted_id,\n",
        "                    pattern_type=\"transfer_adapted\",\n",
        "                    description=f\"Pattern transferred from {source_domain} to {target_domain}\",\n",
        "                    conditions=adapted_conditions,\n",
        "                    actions=source_pattern.actions.copy(),\n",
        "                    expected_outcomes=source_pattern.expected_outcomes.copy(),\n",
        "                    confidence=source_pattern.confidence * 0.7  # Reduced confidence for transfer\n",
        "                )\n",
        "\n",
        "                self.experience_memory.patterns[adapted_id] = adapted_pattern\n",
        "                adapted_patterns += 1\n",
        "\n",
        "        return {\n",
        "            'source_patterns_found': len(source_patterns),\n",
        "            'patterns_adapted': adapted_patterns,\n",
        "            'source_domain': source_domain,\n",
        "            'target_domain': target_domain\n",
        "        }\n",
        "\n",
        "    def _extract_features(self, input_data: Any, context: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract features from input data and context\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Basic feature extraction\n",
        "        if isinstance(input_data, str):\n",
        "            features['input_type'] = 'string'\n",
        "            features['input_length'] = len(input_data)\n",
        "            features['input_words'] = len(input_data.split())\n",
        "        elif isinstance(input_data, (int, float)):\n",
        "            features['input_type'] = 'number'\n",
        "            features['input_value'] = input_data\n",
        "        elif isinstance(input_data, dict):\n",
        "            features['input_type'] = 'dict'\n",
        "            features['input_keys'] = len(input_data)\n",
        "\n",
        "        # Add context features\n",
        "        for key, value in context.items():\n",
        "            features[f\"context_{key}\"] = value\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_label(self, outcome: Any) -> Any:\n",
        "        \"\"\"Extract label from outcome\"\"\"\n",
        "        if isinstance(outcome, dict) and 'label' in outcome:\n",
        "            return outcome['label']\n",
        "        elif isinstance(outcome, bool):\n",
        "            return 'success' if outcome else 'failure'\n",
        "        else:\n",
        "            return str(outcome)\n",
        "\n",
        "    def _cluster_experiences(self, experiences: List[LearningExperience]) -> Dict[int, List[LearningExperience]]:\n",
        "        \"\"\"Simple clustering of experiences based on context similarity\"\"\"\n",
        "        clusters = defaultdict(list)\n",
        "\n",
        "        for experience in experiences:\n",
        "            # Simple clustering based on context hash\n",
        "            context_signature = hash(str(sorted(experience.context.items())))\n",
        "            cluster_id = abs(context_signature) % 5  # Create up to 5 clusters\n",
        "            clusters[cluster_id].append(experience)\n",
        "\n",
        "        return dict(clusters)\n",
        "\n",
        "    def _extract_common_context(self, experiences: List[LearningExperience]) -> Dict[str, Any]:\n",
        "        \"\"\"Extract common context elements from a group of experiences\"\"\"\n",
        "        if not experiences:\n",
        "            return {}\n",
        "\n",
        "        # Find keys that appear in all experiences\n",
        "        common_keys = set(experiences[0].context.keys())\n",
        "        for exp in experiences[1:]:\n",
        "            common_keys &= set(exp.context.keys())\n",
        "\n",
        "        # Extract values that are the same across all experiences\n",
        "        common_context = {}\n",
        "        for key in common_keys:\n",
        "            values = [exp.context[key] for exp in experiences]\n",
        "            if len(set(values)) == 1:  # All have the same value\n",
        "                common_context[key] = values[0]\n",
        "\n",
        "        return common_context\n",
        "\n",
        "    def _extract_common_actions(self, experiences: List[LearningExperience]) -> List[str]:\n",
        "        \"\"\"Extract common actions from a group of experiences\"\"\"\n",
        "        action_counts = defaultdict(int)\n",
        "\n",
        "        for exp in experiences:\n",
        "            if exp.action_taken:\n",
        "                action_counts[exp.action_taken] += 1\n",
        "\n",
        "        # Return actions that appear in at least 50% of experiences\n",
        "        threshold = len(experiences) * 0.5\n",
        "        return [action for action, count in action_counts.items() if count >= threshold]\n",
        "\n",
        "    def _calculate_reward(self, experience: LearningExperience) -> float:\n",
        "        \"\"\"Calculate reward signal from experience\"\"\"\n",
        "        if experience.success:\n",
        "            base_reward = 1.0\n",
        "        else:\n",
        "            base_reward = -1.0\n",
        "\n",
        "        # Adjust based on performance metrics\n",
        "        if experience.performance_metrics:\n",
        "            performance_bonus = sum(experience.performance_metrics.values()) / len(experience.performance_metrics)\n",
        "            return base_reward + (performance_bonus - 0.5)  # Normalize around 0.5\n",
        "\n",
        "        return base_reward\n",
        "\n",
        "    def _get_q_value(self, state_action_key: str) -> float:\n",
        "        \"\"\"Get current Q-value for state-action pair\"\"\"\n",
        "        if state_action_key in self.experience_memory.patterns:\n",
        "            pattern = self.experience_memory.patterns[state_action_key]\n",
        "            return pattern.expected_outcomes.get('q_value', 0.0)\n",
        "        return 0.0\n",
        "\n",
        "    def _update_performance_tracking(self, experience: LearningExperience):\n",
        "        \"\"\"Update performance baselines and tracking\"\"\"\n",
        "        for objective in self.learning_objectives:\n",
        "            if objective.value in experience.performance_metrics:\n",
        "                value = experience.performance_metrics[objective.value]\n",
        "\n",
        "                if objective not in self.performance_baselines:\n",
        "                    self.performance_baselines[objective] = {'values': [], 'baseline': 0.0}\n",
        "\n",
        "                self.performance_baselines[objective]['values'].append(value)\n",
        "\n",
        "                # Keep only recent values\n",
        "                if len(self.performance_baselines[objective]['values']) > 100:\n",
        "                    self.performance_baselines[objective]['values'] = self.performance_baselines[objective]['values'][-100:]\n",
        "\n",
        "                # Update baseline\n",
        "                values = self.performance_baselines[objective]['values']\n",
        "                self.performance_baselines[objective]['baseline'] = sum(values) / len(values)\n",
        "\n",
        "    def _discover_patterns(self):\n",
        "        \"\"\"Trigger pattern discovery from accumulated experiences\"\"\"\n",
        "        new_patterns = self.experience_memory.get_success_patterns()\n",
        "        self.patterns_discovered += len(new_patterns)\n",
        "\n",
        "        if new_patterns:\n",
        "            print(f\"   🔍 Discovered {len(new_patterns)} new patterns\")\n",
        "\n",
        "    def get_learning_recommendations(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get learning-based recommendations for given context\"\"\"\n",
        "\n",
        "        recommendations = []\n",
        "\n",
        "        # Find relevant patterns\n",
        "        for pattern in self.experience_memory.patterns.values():\n",
        "            relevance = self._calculate_pattern_relevance(pattern, context)\n",
        "\n",
        "            if relevance > 0.5 and pattern.confidence > 0.3:\n",
        "                recommendation = {\n",
        "                    'pattern_id': pattern.id,\n",
        "                    'suggested_actions': pattern.actions,\n",
        "                    'confidence': pattern.confidence,\n",
        "                    'relevance': relevance,\n",
        "                    'success_rate': pattern.success_rate,\n",
        "                    'description': pattern.description\n",
        "                }\n",
        "                recommendations.append(recommendation)\n",
        "\n",
        "        # Sort by relevance and confidence\n",
        "        recommendations.sort(key=lambda x: x['relevance'] * x['confidence'], reverse=True)\n",
        "\n",
        "        return recommendations[:5]  # Top 5 recommendations\n",
        "\n",
        "    def _calculate_pattern_relevance(self, pattern: LearningPattern, context: Dict[str, Any]) -> float:\n",
        "        \"\"\"Calculate how relevant a pattern is to the current context\"\"\"\n",
        "        if not pattern.conditions or not context:\n",
        "            return 0.0\n",
        "\n",
        "        matching_conditions = 0\n",
        "        total_conditions = len(pattern.conditions)\n",
        "\n",
        "        for key, value in pattern.conditions.items():\n",
        "            if key in context and context[key] == value:\n",
        "                matching_conditions += 1\n",
        "\n",
        "        return matching_conditions / total_conditions if total_conditions > 0 else 0.0\n",
        "\n",
        "    def get_learning_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get comprehensive learning statistics\"\"\"\n",
        "        memory_stats = self.experience_memory.get_statistics()\n",
        "\n",
        "        # Performance trends\n",
        "        performance_trends = {}\n",
        "        for objective, data in self.performance_baselines.items():\n",
        "            if len(data['values']) > 1:\n",
        "                recent_avg = sum(data['values'][-10:]) / min(10, len(data['values']))\n",
        "                overall_avg = data['baseline']\n",
        "                trend = 'improving' if recent_avg > overall_avg else 'declining'\n",
        "                performance_trends[objective.value] = {\n",
        "                    'trend': trend,\n",
        "                    'recent_average': recent_avg,\n",
        "                    'overall_average': overall_avg\n",
        "                }\n",
        "\n",
        "        return {\n",
        "            'learning_sessions': self.learning_sessions,\n",
        "            'patterns_discovered': self.patterns_discovered,\n",
        "            'knowledge_items': self.knowledge_items,\n",
        "            'memory_statistics': memory_stats,\n",
        "            'performance_trends': performance_trends,\n",
        "            'learning_objectives': [obj.value for obj in self.learning_objectives]\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# TEST THE LEARNING ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing Learning Engine...\")\n",
        "\n",
        "# Create learning engine\n",
        "learning_engine = LearningEngine([\n",
        "    LearningObjective.ACCURACY,\n",
        "    LearningObjective.EFFICIENCY,\n",
        "    LearningObjective.QUALITY\n",
        "])\n",
        "\n",
        "# Test different types of learning\n",
        "print(\"\\n🎓 Testing different learning algorithms:\")\n",
        "\n",
        "# Test 1: Supervised Learning\n",
        "print(\"\\n1. Supervised Learning:\")\n",
        "supervised_exp = LearningExperience(\n",
        "    id=\"supervised_001\",\n",
        "    experience_type=ExperienceType.SUCCESS,\n",
        "    learning_type=LearningType.SUPERVISED,\n",
        "    context={'domain': 'classification', 'task_type': 'email_categorization'},\n",
        "    task_description=\"Categorize email as spam or not spam\",\n",
        "    input_data=\"Free money click here now!!!\",\n",
        "    outcome={'label': 'spam'},\n",
        "    action_taken=\"classify_as_spam\",\n",
        "    success=True,\n",
        "    performance_metrics={'accuracy': 0.95, 'confidence': 0.9}\n",
        ")\n",
        "\n",
        "result = learning_engine.process_experience(supervised_exp)\n",
        "print(f\"   Result: {result['learning_result']}\")\n",
        "\n",
        "# Test 2: Reinforcement Learning\n",
        "print(\"\\n2. Reinforcement Learning:\")\n",
        "rl_exp = LearningExperience(\n",
        "    id=\"rl_001\",\n",
        "    experience_type=ExperienceType.SUCCESS,\n",
        "    learning_type=LearningType.REINFORCEMENT,\n",
        "    context={'domain': 'customer_service', 'situation': 'angry_customer'},\n",
        "    task_description=\"Handle angry customer complaint\",\n",
        "    action_taken=\"apologize_and_escalate\",\n",
        "    success=True,\n",
        "    performance_metrics={'customer_satisfaction': 0.8, 'resolution_time': 0.7}\n",
        ")\n",
        "\n",
        "result = learning_engine.process_experience(rl_exp)\n",
        "print(f\"   Result: {result['learning_result']}\")\n",
        "\n",
        "# Test 3: Imitation Learning\n",
        "print(\"\\n3. Imitation Learning:\")\n",
        "imitation_exp = LearningExperience(\n",
        "    id=\"imitation_001\",\n",
        "    experience_type=ExperienceType.OBSERVATION,\n",
        "    learning_type=LearningType.IMITATION,\n",
        "    context={'domain': 'negotiation', 'expert_agent': 'senior_negotiator'},\n",
        "    task_description=\"Observed expert negotiation technique\",\n",
        "    action_taken=\"build_rapport_before_negotiating\",\n",
        "    success=True,\n",
        "    performance_metrics={'effectiveness_observed': 0.9}\n",
        ")\n",
        "\n",
        "result = learning_engine.process_experience(imitation_exp)\n",
        "print(f\"   Result: {result['learning_result']}\")\n",
        "\n",
        "# Test 4: Transfer Learning\n",
        "print(\"\\n4. Transfer Learning:\")\n",
        "transfer_exp = LearningExperience(\n",
        "    id=\"transfer_001\",\n",
        "    experience_type=ExperienceType.EXPLORATION,\n",
        "    learning_type=LearningType.TRANSFER,\n",
        "    context={'source_domain': 'customer_service', 'target_domain': 'technical_support'},\n",
        "    task_description=\"Transfer customer service skills to technical support\",\n",
        "    success=True\n",
        ")\n",
        "\n",
        "result = learning_engine.process_experience(transfer_exp)\n",
        "print(f\"   Result: {result['learning_result']}\")\n",
        "\n",
        "# Test recommendations\n",
        "print(\"\\n🔍 Testing learning recommendations:\")\n",
        "test_context = {'domain': 'customer_service', 'situation': 'complaint'}\n",
        "recommendations = learning_engine.get_learning_recommendations(test_context)\n",
        "\n",
        "print(f\"   Found {len(recommendations)} recommendations for context: {test_context}\")\n",
        "for i, rec in enumerate(recommendations):\n",
        "    print(f\"   {i+1}. {rec['description']} (confidence: {rec['confidence']:.2f})\")\n",
        "\n",
        "# Get learning statistics\n",
        "print(\"\\n📊 Learning Engine Statistics:\")\n",
        "stats = learning_engine.get_learning_statistics()\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"   {key}:\")\n",
        "        for subkey, subvalue in value.items():\n",
        "            print(f\"     {subkey}: {subvalue}\")\n",
        "    else:\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Learning Engine working correctly!\")\n",
        "print(\"   Ready for Part 4: Adaptive Agent\")\n",
        "print()\n",
        "print(\"📋 Summary of what we built:\")\n",
        "print(\"   • LearningEngine - Core learning processing system\")\n",
        "print(\"   • 5 learning algorithms (supervised, reinforcement, etc.)\")\n",
        "print(\"   • Pattern discovery and knowledge extraction\")\n",
        "print(\"   • Learning recommendations based on context\")\n",
        "print(\"   • Performance tracking and trend analysis\")\n",
        "print(\"   • Transfer learning between domains\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4poFdePCoB0",
        "outputId": "2ef2e6be-d4d5-45f3-eb7d-e900f29517cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12 Part 3: Learning Engine\n",
            "===================================\n",
            "Building the core learning processing system...\n",
            "\n",
            "🧪 Testing Learning Engine...\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 3 objectives\n",
            "\n",
            "🎓 Testing different learning algorithms:\n",
            "\n",
            "1. Supervised Learning:\n",
            "   📝 Stored experience: Categorize email as spam or not spam...\n",
            "   Result: {'pattern_id': 'supervised_-8260293994354950701', 'features_extracted': 5, 'confidence': 0.1}\n",
            "\n",
            "2. Reinforcement Learning:\n",
            "   📝 Stored experience: Handle angry customer complaint...\n",
            "   Result: {'reward': 1.25, 'q_value_updated': 0.125, 'action': 'apologize_and_escalate', 'learning_rate': 0.1}\n",
            "\n",
            "3. Imitation Learning:\n",
            "   📝 Stored experience: Observed expert negotiation technique...\n",
            "   Result: {'pattern_id': 'imitation_-4875633224272169905', 'observed_action': 'build_rapport_before_negotiating', 'context_complexity': 2, 'pattern_confidence': 0.3}\n",
            "\n",
            "4. Transfer Learning:\n",
            "   📝 Stored experience: Transfer customer service skills to technical supp...\n",
            "   Result: {'source_patterns_found': 1, 'patterns_adapted': 0, 'source_domain': 'customer_service', 'target_domain': 'technical_support'}\n",
            "\n",
            "🔍 Testing learning recommendations:\n",
            "   Found 0 recommendations for context: {'domain': 'customer_service', 'situation': 'complaint'}\n",
            "\n",
            "📊 Learning Engine Statistics:\n",
            "   learning_sessions: 0\n",
            "   patterns_discovered: 0\n",
            "   knowledge_items: 0\n",
            "   memory_statistics:\n",
            "     total_experiences: 4\n",
            "     success_rate: 1.0\n",
            "     type_distribution: {'success': 2, 'observation': 1, 'exploration': 1}\n",
            "     patterns_discovered: 3\n",
            "     average_age_days: 1.3891193601820203e-08\n",
            "     capacity_utilization: 0.004\n",
            "   performance_trends:\n",
            "   learning_objectives: ['accuracy', 'efficiency', 'quality']\n",
            "\n",
            "🎉 Learning Engine working correctly!\n",
            "   Ready for Part 4: Adaptive Agent\n",
            "\n",
            "📋 Summary of what we built:\n",
            "   • LearningEngine - Core learning processing system\n",
            "   • 5 learning algorithms (supervised, reinforcement, etc.)\n",
            "   • Pattern discovery and knowledge extraction\n",
            "   • Learning recommendations based on context\n",
            "   • Performance tracking and trend analysis\n",
            "   • Transfer learning between domains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this after Parts 1, 2, and 3 to build an agent that learns and adapts\n",
        "\n",
        "print(\"Tutorial 12 Part 4: Adaptive Agent\")\n",
        "print(\"=\" * 35)\n",
        "print(\"Building an agent that learns and adapts from experience...\")\n",
        "print()\n",
        "\n",
        "# Make sure you've run Parts 1, 2, and 3 first!\n",
        "# This builds on: LearningExperience, LearningPattern, ExperienceMemory, LearningEngine\n",
        "\n",
        "class AdaptiveAgent:\n",
        "    \"\"\"\n",
        "    An agent that learns and adapts from experience\n",
        "\n",
        "    This agent continuously improves its performance by learning\n",
        "    from every interaction and applying that knowledge to future tasks.\n",
        "\n",
        "    Key features:\n",
        "    - Learns from every task execution\n",
        "    - Adapts exploration and confidence based on performance\n",
        "    - Builds expertise in different domains\n",
        "    - Can observe and learn from other agents\n",
        "    - Integrates external feedback for improvement\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, agent_id: str = None, name: str = \"\",\n",
        "                 learning_objectives: List[LearningObjective] = None):\n",
        "        self.id = agent_id or str(uuid.uuid4())\n",
        "        self.name = name or f\"adaptive_agent_{self.id[:8]}\"\n",
        "\n",
        "        # Learning system - this is the core of the adaptive behavior\n",
        "        self.learning_engine = LearningEngine(learning_objectives or [LearningObjective.ACCURACY])\n",
        "\n",
        "        # Expertise tracking - how good is the agent at different things?\n",
        "        self.expertise_areas = defaultdict(float)  # Domain -> expertise level (0-1)\n",
        "\n",
        "        # Performance and adaptation tracking\n",
        "        self.task_history = []\n",
        "        self.adaptation_history = []\n",
        "        self.performance_metrics = defaultdict(list)\n",
        "\n",
        "        # Behavioral parameters that adapt over time\n",
        "        self.confidence_threshold = 0.6    # How confident to be before using learned knowledge\n",
        "        self.exploration_rate = 0.1        # How often to try new approaches vs use known good ones\n",
        "        self.adaptation_frequency = 10     # How often to adapt behavior (every N tasks)\n",
        "\n",
        "        print(f\"🤖 Created adaptive agent: {self.name}\")\n",
        "        print(f\"   Learning objectives: {[obj.value for obj in self.learning_engine.learning_objectives]}\")\n",
        "        print(f\"   Initial exploration rate: {self.exploration_rate}\")\n",
        "        print(f\"   Initial confidence threshold: {self.confidence_threshold}\")\n",
        "\n",
        "    def execute_task(self, task_description: str, task_data: Any,\n",
        "                    context: Dict[str, Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute a task and learn from the experience\n",
        "\n",
        "        This is where the magic happens - the agent:\n",
        "        1. Gets recommendations from its learning engine\n",
        "        2. Chooses an action (exploration vs exploitation)\n",
        "        3. Executes the task\n",
        "        4. Evaluates performance\n",
        "        5. Creates a learning experience\n",
        "        6. Updates its expertise and potentially adapts behavior\n",
        "        \"\"\"\n",
        "\n",
        "        task_id = str(uuid.uuid4())\n",
        "        start_time = time.time()\n",
        "        context = context or {}\n",
        "\n",
        "        print(f\"🎯 {self.name} executing: {task_description[:50]}...\")\n",
        "\n",
        "        # Step 1: Get learning-based recommendations\n",
        "        recommendations = self.learning_engine.get_learning_recommendations(context)\n",
        "        print(f\"   💡 Found {len(recommendations)} recommendations from past experience\")\n",
        "\n",
        "        # Step 2: Choose action based on recommendations and exploration strategy\n",
        "        chosen_action = self._choose_action(recommendations, context)\n",
        "        print(f\"   🎲 Chose action: {chosen_action}\")\n",
        "\n",
        "        # Step 3: Execute the task (simulated)\n",
        "        result = self._execute_action(chosen_action, task_data, context)\n",
        "\n",
        "        # Step 4: Measure performance\n",
        "        execution_time = time.time() - start_time\n",
        "        performance = self._evaluate_performance(result, execution_time)\n",
        "\n",
        "        success_indicator = \"✅\" if performance['success'] else \"❌\"\n",
        "        print(f\"   {success_indicator} Result: {performance['success']} (score: {performance['overall_score']:.3f})\")\n",
        "\n",
        "        # Step 5: Create learning experience\n",
        "        experience = LearningExperience(\n",
        "            id=str(uuid.uuid4()),\n",
        "            experience_type=ExperienceType.SUCCESS if performance['success'] else ExperienceType.FAILURE,\n",
        "            learning_type=LearningType.REINFORCEMENT,  # Learning from rewards/penalties\n",
        "            context=context,\n",
        "            task_description=task_description,\n",
        "            input_data=task_data,\n",
        "            action_taken=chosen_action,\n",
        "            outcome=result,\n",
        "            success=performance['success'],\n",
        "            performance_metrics=performance['metrics'],\n",
        "            source_agent=self.name\n",
        "        )\n",
        "\n",
        "        # Step 6: Learn from this experience\n",
        "        learning_result = self.learning_engine.process_experience(experience)\n",
        "\n",
        "        # Step 7: Update expertise in relevant domains\n",
        "        self._update_expertise(context, performance)\n",
        "\n",
        "        # Step 8: Check if it's time to adapt behavior\n",
        "        self._check_adaptation_trigger()\n",
        "\n",
        "        # Step 9: Record this task in history\n",
        "        task_record = {\n",
        "            'task_id': task_id,\n",
        "            'description': task_description,\n",
        "            'action_taken': chosen_action,\n",
        "            'performance': performance,\n",
        "            'learning_applied': len(recommendations) > 0,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "        self.task_history.append(task_record)\n",
        "\n",
        "        return {\n",
        "            'task_id': task_id,\n",
        "            'result': result,\n",
        "            'performance': performance,\n",
        "            'action_taken': chosen_action,\n",
        "            'learning_result': learning_result,\n",
        "            'recommendations_used': len(recommendations),\n",
        "            'execution_time': execution_time\n",
        "        }\n",
        "\n",
        "    def _choose_action(self, recommendations: List[Dict[str, Any]],\n",
        "                      context: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        Choose action based on recommendations and exploration strategy\n",
        "\n",
        "        This implements the exploration vs exploitation tradeoff:\n",
        "        - Exploration: Try new things to discover better approaches\n",
        "        - Exploitation: Use known good approaches from past experience\n",
        "        \"\"\"\n",
        "\n",
        "        # Exploration: Sometimes try random things to discover new approaches\n",
        "        if random.random() < self.exploration_rate:\n",
        "            possible_actions = [\n",
        "                'systematic_approach',\n",
        "                'creative_solution',\n",
        "                'methodical_process',\n",
        "                'innovative_technique',\n",
        "                'standard_procedure'\n",
        "            ]\n",
        "            chosen = random.choice(possible_actions)\n",
        "            print(f\"     🔍 Exploring with action: {chosen}\")\n",
        "            return chosen\n",
        "\n",
        "        # Exploitation: Use learned knowledge if we have good recommendations\n",
        "        if recommendations:\n",
        "            best_recommendation = recommendations[0]  # Recommendations are sorted by relevance\n",
        "\n",
        "            # Only use recommendation if we're confident enough\n",
        "            if best_recommendation['confidence'] > self.confidence_threshold:\n",
        "                action = (best_recommendation['suggested_actions'][0]\n",
        "                         if best_recommendation['suggested_actions']\n",
        "                         else 'default_action')\n",
        "                print(f\"     🧠 Using learned approach: {action} (confidence: {best_recommendation['confidence']:.2f})\")\n",
        "                return action\n",
        "            else:\n",
        "                print(f\"     🤔 Recommendation confidence too low: {best_recommendation['confidence']:.2f} < {self.confidence_threshold:.2f}\")\n",
        "\n",
        "        # Domain expertise: Use expert knowledge if we have it\n",
        "        domain = context.get('domain', 'general')\n",
        "        if domain in self.expertise_areas and self.expertise_areas[domain] > 0.5:\n",
        "            expert_action = f\"expert_{domain}_approach\"\n",
        "            print(f\"     🎓 Using domain expertise: {expert_action} (expertise: {self.expertise_areas[domain]:.2f})\")\n",
        "            return expert_action\n",
        "\n",
        "        # Fallback: Use standard approach\n",
        "        print(f\"     📝 Using standard approach (no strong recommendations or expertise)\")\n",
        "        return 'standard_approach'\n",
        "\n",
        "    def _execute_action(self, action: str, task_data: Any, context: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute the chosen action (simulated)\n",
        "\n",
        "        This simulates actually performing the task. In a real system,\n",
        "        this would call actual APIs, execute code, etc.\n",
        "        \"\"\"\n",
        "\n",
        "        # Define base effectiveness for different action types\n",
        "        action_effectiveness = {\n",
        "            'systematic_approach': 0.75,\n",
        "            'creative_solution': 0.85,  # High risk, high reward\n",
        "            'methodical_process': 0.70,\n",
        "            'innovative_technique': 0.80,\n",
        "            'standard_procedure': 0.60,\n",
        "            'standard_approach': 0.50,\n",
        "            'default_action': 0.40\n",
        "        }\n",
        "\n",
        "        # Expert actions are more effective in their domain\n",
        "        if action.startswith('expert_'):\n",
        "            domain = action.split('_')[1]\n",
        "            base_effectiveness = 0.60\n",
        "            expertise_bonus = self.expertise_areas.get(domain, 0.0) * 0.35  # Up to 35% bonus\n",
        "            effectiveness = base_effectiveness + expertise_bonus\n",
        "        else:\n",
        "            effectiveness = action_effectiveness.get(action, 0.50)\n",
        "\n",
        "        # Add some realistic randomness (real world is unpredictable)\n",
        "        randomness = random.uniform(-0.15, 0.15)\n",
        "        actual_effectiveness = max(0.0, min(1.0, effectiveness + randomness))\n",
        "\n",
        "        # Generate realistic result based on effectiveness\n",
        "        if actual_effectiveness > 0.8:\n",
        "            status = \"excellent\"\n",
        "            description = f\"Excellently completed using {action}\"\n",
        "        elif actual_effectiveness > 0.6:\n",
        "            status = \"good\"\n",
        "            description = f\"Successfully completed using {action}\"\n",
        "        elif actual_effectiveness > 0.4:\n",
        "            status = \"partial\"\n",
        "            description = f\"Partially completed using {action} - some issues\"\n",
        "        else:\n",
        "            status = \"failed\"\n",
        "            description = f\"Failed to complete using {action}\"\n",
        "\n",
        "        return {\n",
        "            'status': status,\n",
        "            'description': description,\n",
        "            'quality_score': actual_effectiveness,\n",
        "            'action_used': action,\n",
        "            'details': f\"Executed {action} with {actual_effectiveness:.1%} effectiveness\"\n",
        "        }\n",
        "\n",
        "    def _evaluate_performance(self, result: Dict[str, Any], execution_time: float) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Evaluate how well the agent performed on this task\n",
        "\n",
        "        This creates standardized performance metrics that can be\n",
        "        compared across different tasks and used for learning.\n",
        "        \"\"\"\n",
        "\n",
        "        quality_score = result.get('quality_score', 0.0)\n",
        "\n",
        "        # Calculate multiple performance dimensions\n",
        "        accuracy = quality_score  # How correct/good was the result\n",
        "        efficiency = max(0.0, 1.0 - min(execution_time / 5.0, 1.0))  # Faster is better, cap at 5 seconds\n",
        "        success = quality_score > 0.5  # Binary success/failure\n",
        "\n",
        "        # Composite metrics\n",
        "        overall_score = (accuracy * 0.5 + efficiency * 0.3 + quality_score * 0.2)\n",
        "\n",
        "        metrics = {\n",
        "            'accuracy': accuracy,\n",
        "            'efficiency': efficiency,\n",
        "            'quality': quality_score,\n",
        "            'execution_time': execution_time\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'success': success,\n",
        "            'metrics': metrics,\n",
        "            'overall_score': overall_score\n",
        "        }\n",
        "\n",
        "    def _update_expertise(self, context: Dict[str, Any], performance: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Update expertise levels based on task performance\n",
        "\n",
        "        This is how the agent builds up specialized knowledge in different areas.\n",
        "        Better performance in a domain increases expertise in that domain.\n",
        "        \"\"\"\n",
        "\n",
        "        domain = context.get('domain', 'general')\n",
        "        task_type = context.get('task_type', 'general')\n",
        "        performance_score = performance['overall_score']\n",
        "\n",
        "        # Learning rate - how quickly expertise changes\n",
        "        learning_rate = 0.1\n",
        "\n",
        "        # Update domain expertise using exponential moving average\n",
        "        current_domain_expertise = self.expertise_areas[domain]\n",
        "        new_domain_expertise = current_domain_expertise + learning_rate * (performance_score - current_domain_expertise)\n",
        "        self.expertise_areas[domain] = max(0.0, min(1.0, new_domain_expertise))\n",
        "\n",
        "        # Also update task type expertise if it's different from domain\n",
        "        if task_type != 'general' and task_type != domain:\n",
        "            current_task_expertise = self.expertise_areas[task_type]\n",
        "            new_task_expertise = current_task_expertise + learning_rate * (performance_score - current_task_expertise)\n",
        "            self.expertise_areas[task_type] = max(0.0, min(1.0, new_task_expertise))\n",
        "\n",
        "        # Track performance metrics for trend analysis\n",
        "        for metric_name, value in performance['metrics'].items():\n",
        "            self.performance_metrics[metric_name].append(value)\n",
        "\n",
        "            # Keep only recent values to save memory\n",
        "            if len(self.performance_metrics[metric_name]) > 100:\n",
        "                self.performance_metrics[metric_name] = self.performance_metrics[metric_name][-100:]\n",
        "\n",
        "        # Log significant expertise changes\n",
        "        expertise_change = abs(new_domain_expertise - current_domain_expertise)\n",
        "        if expertise_change > 0.05:  # Significant change\n",
        "            print(f\"     📈 {domain} expertise: {current_domain_expertise:.2f} → {new_domain_expertise:.2f}\")\n",
        "\n",
        "    def _check_adaptation_trigger(self):\n",
        "        \"\"\"\n",
        "        Check if it's time to adapt behavior based on recent performance\n",
        "\n",
        "        The agent periodically reviews its performance and adjusts its\n",
        "        exploration rate and confidence threshold accordingly.\n",
        "        \"\"\"\n",
        "\n",
        "        if len(self.task_history) % self.adaptation_frequency == 0 and len(self.task_history) > 0:\n",
        "            print(f\"     🔄 Triggering adaptation check (task #{len(self.task_history)})\")\n",
        "            self._adapt_behavior()\n",
        "\n",
        "    def _adapt_behavior(self):\n",
        "        \"\"\"\n",
        "        Adapt behavior based on recent performance\n",
        "\n",
        "        This is the heart of the adaptive behavior - the agent looks at\n",
        "        how it's been doing and adjusts its strategy accordingly.\n",
        "        \"\"\"\n",
        "\n",
        "        if len(self.task_history) < 5:\n",
        "            return  # Need some history to make adaptations\n",
        "\n",
        "        # Analyze recent performance (last 10 tasks or all if less)\n",
        "        recent_tasks = self.task_history[-10:]\n",
        "        recent_success_rate = sum(1 for task in recent_tasks if task['performance']['success']) / len(recent_tasks)\n",
        "        recent_avg_score = sum(task['performance']['overall_score'] for task in recent_tasks) / len(recent_tasks)\n",
        "\n",
        "        print(f\"       📊 Recent performance: {recent_success_rate:.1%} success, {recent_avg_score:.3f} avg score\")\n",
        "\n",
        "        # Store original values for comparison\n",
        "        old_exploration = self.exploration_rate\n",
        "        old_confidence = self.confidence_threshold\n",
        "\n",
        "        # Adapt exploration rate based on success\n",
        "        if recent_success_rate > 0.8:\n",
        "            # High success rate - reduce exploration, exploit current knowledge\n",
        "            self.exploration_rate = max(0.05, self.exploration_rate * 0.9)\n",
        "            print(f\"       ✅ High success rate - reducing exploration\")\n",
        "        elif recent_success_rate < 0.4:\n",
        "            # Low success rate - increase exploration, try new things\n",
        "            self.exploration_rate = min(0.3, self.exploration_rate * 1.1)\n",
        "            print(f\"       ❌ Low success rate - increasing exploration\")\n",
        "\n",
        "        # Adapt confidence threshold based on average performance\n",
        "        if recent_avg_score > 0.7:\n",
        "            # Good performance - be less conservative, trust recommendations more\n",
        "            self.confidence_threshold = max(0.4, self.confidence_threshold - 0.05)\n",
        "            print(f\"       🎯 Good performance - lowering confidence threshold\")\n",
        "        elif recent_avg_score < 0.4:\n",
        "            # Poor performance - be more conservative, require higher confidence\n",
        "            self.confidence_threshold = min(0.8, self.confidence_threshold + 0.05)\n",
        "            print(f\"       🛡️ Poor performance - raising confidence threshold\")\n",
        "\n",
        "        # Record this adaptation\n",
        "        adaptation_record = {\n",
        "            'timestamp': time.time(),\n",
        "            'trigger_task': len(self.task_history),\n",
        "            'recent_success_rate': recent_success_rate,\n",
        "            'recent_avg_score': recent_avg_score,\n",
        "            'old_exploration_rate': old_exploration,\n",
        "            'new_exploration_rate': self.exploration_rate,\n",
        "            'old_confidence_threshold': old_confidence,\n",
        "            'new_confidence_threshold': self.confidence_threshold\n",
        "        }\n",
        "        self.adaptation_history.append(adaptation_record)\n",
        "\n",
        "        # Report changes\n",
        "        exploration_change = self.exploration_rate - old_exploration\n",
        "        confidence_change = self.confidence_threshold - old_confidence\n",
        "\n",
        "        print(f\"       🔧 Adaptation complete:\")\n",
        "        print(f\"         Exploration: {old_exploration:.3f} → {self.exploration_rate:.3f} ({exploration_change:+.3f})\")\n",
        "        print(f\"         Confidence: {old_confidence:.3f} → {self.confidence_threshold:.3f} ({confidence_change:+.3f})\")\n",
        "\n",
        "    def learn_from_feedback(self, task_id: str, feedback: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Learn from external feedback on a completed task\n",
        "\n",
        "        This allows the agent to learn from human feedback or other\n",
        "        external evaluations of its performance.\n",
        "        \"\"\"\n",
        "\n",
        "        # Find the task that this feedback refers to\n",
        "        task_record = None\n",
        "        for task in self.task_history:\n",
        "            if task['task_id'] == task_id:\n",
        "                task_record = task\n",
        "                break\n",
        "\n",
        "        if not task_record:\n",
        "            print(f\"   ⚠️ Task {task_id[:8]}... not found for feedback\")\n",
        "            return None\n",
        "\n",
        "        print(f\"   📝 Processing feedback for task: {task_record['description'][:40]}...\")\n",
        "\n",
        "        # Create a supervised learning experience from the feedback\n",
        "        experience = LearningExperience(\n",
        "            id=str(uuid.uuid4()),\n",
        "            experience_type=ExperienceType.FEEDBACK,\n",
        "            learning_type=LearningType.SUPERVISED,  # Learning from labeled examples\n",
        "            context={'task_type': 'feedback_learning', 'original_task': task_id},\n",
        "            task_description=f\"Feedback on: {task_record['description']}\",\n",
        "            input_data=task_record['action_taken'],\n",
        "            outcome=feedback,\n",
        "            success=feedback.get('satisfactory', False),\n",
        "            performance_metrics=feedback.get('metrics', {}),\n",
        "            lesson_learned=feedback.get('lesson', ''),\n",
        "            source_agent='external_feedback'\n",
        "        )\n",
        "\n",
        "        # Process the feedback as a learning experience\n",
        "        learning_result = self.learning_engine.process_experience(experience)\n",
        "\n",
        "        feedback_quality = \"positive\" if feedback.get('satisfactory', False) else \"corrective\"\n",
        "        print(f\"   ✅ Learned from {feedback_quality} feedback\")\n",
        "\n",
        "        return learning_result\n",
        "\n",
        "    def observe_other_agent(self, other_agent: 'AdaptiveAgent', task_description: str,\n",
        "                           context: Dict[str, Any] = None):\n",
        "        \"\"\"\n",
        "        Learn by observing another agent's behavior\n",
        "\n",
        "        This implements imitation learning - the agent can watch\n",
        "        what other successful agents do and learn from them.\n",
        "        \"\"\"\n",
        "\n",
        "        context = context or {}\n",
        "        print(f\"   👁️ Observing {other_agent.name} on task: {task_description[:40]}...\")\n",
        "\n",
        "        # Get what the other agent would recommend for this context\n",
        "        other_recommendations = other_agent.learning_engine.get_learning_recommendations(context)\n",
        "\n",
        "        if other_recommendations:\n",
        "            # Learn from the other agent's best approach\n",
        "            best_approach = other_recommendations[0]\n",
        "\n",
        "            # Create an imitation learning experience\n",
        "            experience = LearningExperience(\n",
        "                id=str(uuid.uuid4()),\n",
        "                experience_type=ExperienceType.OBSERVATION,\n",
        "                learning_type=LearningType.IMITATION,\n",
        "                context=context,\n",
        "                task_description=f\"Observed {other_agent.name}: {task_description}\",\n",
        "                action_taken=best_approach['suggested_actions'][0] if best_approach['suggested_actions'] else 'unknown_action',\n",
        "                success=True,  # Assume observed behavior is good to imitate\n",
        "                confidence=best_approach['confidence'],\n",
        "                source_agent=other_agent.name,\n",
        "                lesson_learned=f\"Learned approach from {other_agent.name}\"\n",
        "            )\n",
        "\n",
        "            # Process the observation as a learning experience\n",
        "            learning_result = self.learning_engine.process_experience(experience)\n",
        "\n",
        "            print(f\"   ✅ Learned approach: {experience.action_taken} (confidence: {best_approach['confidence']:.2f})\")\n",
        "            return learning_result\n",
        "        else:\n",
        "            print(f\"   ℹ️ No clear approach to learn from {other_agent.name}\")\n",
        "            return None\n",
        "\n",
        "    def transfer_knowledge_to_domain(self, source_domain: str, target_domain: str):\n",
        "        \"\"\"\n",
        "        Transfer learned knowledge from one domain to another\n",
        "\n",
        "        This allows the agent to apply knowledge learned in one area\n",
        "        to a new, related area (like applying customer service skills\n",
        "        to technical support).\n",
        "        \"\"\"\n",
        "\n",
        "        if source_domain not in self.expertise_areas:\n",
        "            print(f\"   ⚠️ No expertise in source domain: {source_domain}\")\n",
        "            return None\n",
        "\n",
        "        source_expertise = self.expertise_areas[source_domain]\n",
        "        print(f\"   🔄 Transferring knowledge: {source_domain} ({source_expertise:.2f}) → {target_domain}\")\n",
        "\n",
        "        # Create a transfer learning experience\n",
        "        experience = LearningExperience(\n",
        "            id=str(uuid.uuid4()),\n",
        "            experience_type=ExperienceType.EXPLORATION,\n",
        "            learning_type=LearningType.TRANSFER,\n",
        "            context={\n",
        "                'source_domain': source_domain,\n",
        "                'target_domain': target_domain,\n",
        "                'source_expertise': source_expertise\n",
        "            },\n",
        "            task_description=f\"Transfer knowledge from {source_domain} to {target_domain}\",\n",
        "            success=True,\n",
        "            source_agent=self.name\n",
        "        )\n",
        "\n",
        "        # Process the transfer learning\n",
        "        learning_result = self.learning_engine.process_experience(experience)\n",
        "\n",
        "        # Initialize target domain expertise based on source (partial transfer)\n",
        "        transfer_factor = 0.3  # 30% of source expertise transfers initially\n",
        "        initial_target_expertise = source_expertise * transfer_factor\n",
        "        current_target = self.expertise_areas[target_domain]\n",
        "        self.expertise_areas[target_domain] = max(current_target, initial_target_expertise)\n",
        "\n",
        "        new_target_expertise = self.expertise_areas[target_domain]\n",
        "        print(f\"   ✅ Transfer complete: {target_domain} expertise now {new_target_expertise:.2f}\")\n",
        "\n",
        "        return learning_result\n",
        "\n",
        "    def get_agent_status(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get comprehensive status of the agent including learning progress\n",
        "\n",
        "        This provides a complete picture of how the agent is doing,\n",
        "        what it has learned, and how it has adapted.\n",
        "        \"\"\"\n",
        "\n",
        "        learning_stats = self.learning_engine.get_learning_statistics()\n",
        "\n",
        "        # Calculate performance trends from recent tasks\n",
        "        recent_tasks = self.task_history[-20:] if len(self.task_history) >= 20 else self.task_history\n",
        "        if recent_tasks:\n",
        "            avg_performance = sum(task['performance']['overall_score'] for task in recent_tasks) / len(recent_tasks)\n",
        "            success_rate = sum(1 for task in recent_tasks if task['performance']['success']) / len(recent_tasks)\n",
        "        else:\n",
        "            avg_performance = 0.0\n",
        "            success_rate = 0.0\n",
        "\n",
        "        # Get top expertise areas\n",
        "        top_expertise = sorted(self.expertise_areas.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "        return {\n",
        "            'agent_id': self.id,\n",
        "            'name': self.name,\n",
        "            'tasks_completed': len(self.task_history),\n",
        "            'current_performance': {\n",
        "                'average_score': avg_performance,\n",
        "                'success_rate': success_rate,\n",
        "                'exploration_rate': self.exploration_rate,\n",
        "                'confidence_threshold': self.confidence_threshold\n",
        "            },\n",
        "            'expertise_areas': dict(top_expertise),\n",
        "            'learning_progress': learning_stats,\n",
        "            'adaptations_made': len(self.adaptation_history),\n",
        "            'behavioral_parameters': {\n",
        "                'exploration_rate': self.exploration_rate,\n",
        "                'confidence_threshold': self.confidence_threshold,\n",
        "                'adaptation_frequency': self.adaptation_frequency\n",
        "            }\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# TEST THE ADAPTIVE AGENT WITH COMPREHENSIVE EXAMPLES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing Adaptive Agent with Comprehensive Examples...\")\n",
        "print()\n",
        "\n",
        "# Create an adaptive agent for testing\n",
        "test_agent = AdaptiveAgent(\n",
        "    name=\"TestBot\",\n",
        "    learning_objectives=[LearningObjective.ACCURACY, LearningObjective.EFFICIENCY, LearningObjective.QUALITY]\n",
        ")\n",
        "\n",
        "# Create diverse and realistic test scenarios\n",
        "test_scenarios = [\n",
        "    {\n",
        "        'description': 'Handle urgent customer complaint about billing error',\n",
        "        'data': {\n",
        "            'customer_tier': 'premium',\n",
        "            'issue_severity': 'high',\n",
        "            'previous_contacts': 2,\n",
        "            'amount_disputed': 150.00\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'customer_service',\n",
        "            'task_type': 'complaint_resolution',\n",
        "            'urgency': 'high'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'description': 'Optimize slow database query for user dashboard',\n",
        "        'data': {\n",
        "            'query_type': 'complex_join',\n",
        "            'table_sizes': ['large', 'medium', 'small'],\n",
        "            'current_execution_time': 8.5,\n",
        "            'target_time': 2.0\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'database_optimization',\n",
        "            'task_type': 'performance_tuning',\n",
        "            'complexity': 'high'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'description': 'Design responsive layout for mobile e-commerce app',\n",
        "        'data': {\n",
        "            'target_devices': ['smartphone', 'tablet'],\n",
        "            'key_features': ['product_grid', 'search', 'checkout'],\n",
        "            'brand_guidelines': 'modern_minimalist'\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'ui_design',\n",
        "            'task_type': 'responsive_design',\n",
        "            'platform': 'mobile'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'description': 'Analyze quarterly sales data for trends and insights',\n",
        "        'data': {\n",
        "            'data_period': 'Q1_2024',\n",
        "            'data_sources': ['crm', 'analytics', 'finance'],\n",
        "            'metrics_requested': ['growth', 'customer_acquisition', 'churn']\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'data_analysis',\n",
        "            'task_type': 'business_intelligence',\n",
        "            'scope': 'quarterly_review'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'description': 'Write API documentation for new authentication service',\n",
        "        'data': {\n",
        "            'api_type': 'REST',\n",
        "            'endpoints_count': 12,\n",
        "            'authentication_methods': ['oauth2', 'api_key'],\n",
        "            'target_audience': 'external_developers'\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'technical_writing',\n",
        "            'task_type': 'api_documentation',\n",
        "            'complexity': 'medium'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'description': 'Debug memory leak in production web application',\n",
        "        'data': {\n",
        "            'application_type': 'nodejs_web_app',\n",
        "            'symptoms': ['increasing_memory_usage', 'slow_response_times'],\n",
        "            'affected_users': 'approximately_500',\n",
        "            'business_impact': 'high'\n",
        "        },\n",
        "        'context': {\n",
        "            'domain': 'software_debugging',\n",
        "            'task_type': 'production_issue',\n",
        "            'urgency': 'critical'\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"🎯 Running {len(test_scenarios)} diverse scenarios to test learning and adaptation...\")\n",
        "print()\n",
        "\n",
        "# Execute scenarios and track learning progression\n",
        "results_summary = []\n",
        "\n",
        "for i, scenario in enumerate(test_scenarios):\n",
        "    print(f\"📋 Scenario {i+1}: {scenario['description']}\")\n",
        "    print(f\"   Domain: {scenario['context']['domain']}, Type: {scenario['context']['task_type']}\")\n",
        "\n",
        "    # Execute the task\n",
        "    result = test_agent.execute_task(\n",
        "        task_description=scenario['description'],\n",
        "        task_data=scenario['data'],\n",
        "        context=scenario['context']\n",
        "    )\n",
        "\n",
        "    # Store result for analysis\n",
        "    results_summary.append({\n",
        "        'scenario': i+1,\n",
        "        'domain': scenario['context']['domain'],\n",
        "        'success': result['performance']['success'],\n",
        "        'score': result['performance']['overall_score'],\n",
        "        'action': result['action_taken'],\n",
        "        'recommendations_used': result['recommendations_used']\n",
        "    })\n",
        "\n",
        "    # Show key results\n",
        "    print(f\"   ➤ Action taken: {result['action_taken']}\")\n",
        "    print(f\"   ➤ Success: {'✅' if result['performance']['success'] else '❌'}\")\n",
        "    print(f\"   ➤ Performance score: {result['performance']['overall_score']:.3f}\")\n",
        "    print(f\"   ➤ Used {result['recommendations_used']} recommendations from experience\")\n",
        "    print()\n",
        "\n",
        "    # Simulate external feedback on some tasks\n",
        "    if i in [1, 3, 5]:  # Provide feedback on scenarios 2, 4, and 6\n",
        "        feedback_type = \"positive\" if result['performance']['success'] else \"corrective\"\n",
        "        feedback = {\n",
        "            'satisfactory': result['performance']['success'],\n",
        "            'metrics': {\n",
        "                'expert_rating': random.uniform(0.7, 0.95) if result['performance']['success'] else random.uniform(0.3, 0.6),\n",
        "                'efficiency_rating': random.uniform(0.6, 0.9)\n",
        "            },\n",
        "            'lesson': f\"Scenario {i+1}: {'Well executed approach' if result['performance']['success'] else 'Consider alternative strategies for better results'}\"\n",
        "        }\n",
        "\n",
        "        test_agent.learn_from_feedback(result['task_id'], feedback)\n",
        "        print(f\"   📝 Received {feedback_type} feedback: {feedback['lesson']}\")\n",
        "        print()\n",
        "\n",
        "# Test knowledge transfer between domains\n",
        "print(\"🔄 Testing knowledge transfer between domains...\")\n",
        "\n",
        "# Check current expertise levels\n",
        "print(\"   Current expertise levels:\")\n",
        "for domain, level in sorted(test_agent.expertise_areas.items(), key=lambda x: x[1], reverse=True):\n",
        "    if level > 0.1:  # Only show domains with meaningful expertise\n",
        "        print(f\"     {domain}: {level:.3f}\")\n",
        "\n",
        "# Transfer knowledge from highest expertise domain to a new domain\n",
        "if test_agent.expertise_areas:\n",
        "    source_domain = max(test_agent.expertise_areas.items(), key=lambda x: x[1])[0]\n",
        "    target_domain = \"cross_functional_collaboration\"\n",
        "\n",
        "    print(f\"\\n   Transferring knowledge: {source_domain} → {target_domain}\")\n",
        "    test_agent.transfer_knowledge_to_domain(source_domain, target_domain)\n",
        "\n",
        "# Test observation learning\n",
        "print(\"\\n👁️ Testing observation learning...\")\n",
        "\n",
        "# Create a more experienced \"teacher\" agent\n",
        "teacher_agent = AdaptiveAgent(name=\"ExperiencedBot\")\n",
        "teacher_agent.expertise_areas['project_management'] = 0.8\n",
        "teacher_agent.expertise_areas['team_leadership'] = 0.7\n",
        "\n",
        "# Student agent observes teacher\n",
        "print(\"   Student agent observing teacher on project management task...\")\n",
        "test_agent.observe_other_agent(\n",
        "    teacher_agent,\n",
        "    \"Plan project timeline and coordinate team resources\",\n",
        "    {'domain': 'project_management', 'complexity': 'high', 'team_size': 8}\n",
        ")\n",
        "\n",
        "# Show final agent status and learning summary\n",
        "print(\"\\n📊 FINAL AGENT STATUS AND LEARNING ANALYSIS\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "status = test_agent.get_agent_status()\n",
        "\n",
        "print(f\"🤖 Agent: {status['name']}\")\n",
        "print(f\"   📈 Tasks completed: {status['tasks_completed']}\")\n",
        "print(f\"   ✅ Current success rate: {status['current_performance']['success_rate']:.1%}\")\n",
        "print(f\"   🎯 Average performance score: {status['current_performance']['average_score']:.3f}\")\n",
        "print(f\"   🔍 Current exploration rate: {status['current_performance']['exploration_rate']:.3f}\")\n",
        "print(f\"   🛡️ Current confidence threshold: {status['current_performance']['confidence_threshold']:.3f}\")\n",
        "print(f\"   🔄 Total adaptations made: {status['adaptations_made']}\")\n",
        "\n",
        "print(f\"\\n🏆 TOP EXPERTISE AREAS:\")\n",
        "expertise_items = list(status['expertise_areas'].items())\n",
        "if expertise_items:\n",
        "    for i, (area, level) in enumerate(expertise_items[:5], 1):\n",
        "        expertise_bar = \"█\" * int(level * 20) + \"░\" * (20 - int(level * 20))\n",
        "        print(f\"   {i}. {area}: {level:.3f} {expertise_bar}\")\n",
        "else:\n",
        "    print(\"   No significant expertise developed yet\")\n",
        "\n",
        "print(f\"\\n📚 LEARNING PROGRESS:\")\n",
        "learning_progress = status['learning_progress']\n",
        "print(f\"   🔍 Patterns discovered: {learning_progress['patterns_discovered']}\")\n",
        "print(f\"   💾 Total experiences stored: {learning_progress['memory_statistics']['total_experiences']}\")\n",
        "print(f\"   ✅ Experience success rate: {learning_progress['memory_statistics']['success_rate']:.1%}\")\n",
        "print(f\"   📊 Memory utilization: {learning_progress['memory_statistics']['capacity_utilization']:.1%}\")\n",
        "\n",
        "# Analyze learning progression through the scenarios\n",
        "print(f\"\\n📈 LEARNING PROGRESSION ANALYSIS:\")\n",
        "print(f\"   Scenario progression:\")\n",
        "\n",
        "for i, result in enumerate(results_summary):\n",
        "    trend_indicator = \"\"\n",
        "    if i > 0:\n",
        "        prev_score = results_summary[i-1]['score']\n",
        "        if result['score'] > prev_score + 0.1:\n",
        "            trend_indicator = \"↗️\"\n",
        "        elif result['score'] < prev_score - 0.1:\n",
        "            trend_indicator = \"↘️\"\n",
        "        else:\n",
        "            trend_indicator = \"➡️\"\n",
        "\n",
        "    success_icon = \"✅\" if result['success'] else \"❌\"\n",
        "    print(f\"     {result['scenario']}. {result['domain']}: {result['score']:.3f} {success_icon} {trend_indicator}\")\n",
        "\n",
        "# Show adaptation history\n",
        "if test_agent.adaptation_history:\n",
        "    print(f\"\\n🔄 BEHAVIORAL ADAPTATION HISTORY:\")\n",
        "    print(f\"   The agent adapted its behavior {len(test_agent.adaptation_history)} times:\")\n",
        "\n",
        "    for i, adaptation in enumerate(test_agent.adaptation_history, 1):\n",
        "        exploration_change = adaptation['new_exploration_rate'] - adaptation['old_exploration_rate']\n",
        "        confidence_change = adaptation['new_confidence_threshold'] - adaptation['old_confidence_threshold']\n",
        "\n",
        "        print(f\"     {i}. After task #{adaptation['trigger_task']}:\")\n",
        "        print(f\"        Success rate was {adaptation['recent_success_rate']:.1%}\")\n",
        "        print(f\"        Exploration: {adaptation['old_exploration_rate']:.3f} → {adaptation['new_exploration_rate']:.3f} ({exploration_change:+.3f})\")\n",
        "        print(f\"        Confidence: {adaptation['old_confidence_threshold']:.3f} → {adaptation['new_confidence_threshold']:.3f} ({confidence_change:+.3f})\")\n",
        "\n",
        "# Performance trend analysis\n",
        "print(f\"\\n📊 PERFORMANCE TREND ANALYSIS:\")\n",
        "if len(results_summary) >= 3:\n",
        "    early_performance = sum(r['score'] for r in results_summary[:3]) / 3\n",
        "    late_performance = sum(r['score'] for r in results_summary[-3:]) / 3\n",
        "    improvement = late_performance - early_performance\n",
        "\n",
        "    trend_description = \"improving\" if improvement > 0.1 else \"declining\" if improvement < -0.1 else \"stable\"\n",
        "    print(f\"   Early performance (first 3 tasks): {early_performance:.3f}\")\n",
        "    print(f\"   Recent performance (last 3 tasks): {late_performance:.3f}\")\n",
        "    print(f\"   Overall trend: {trend_description} ({improvement:+.3f})\")\n",
        "\n",
        "    # Success rate trends\n",
        "    early_success = sum(1 for r in results_summary[:3] if r['success']) / 3\n",
        "    late_success = sum(1 for r in results_summary[-3:] if r['success']) / 3\n",
        "    success_improvement = late_success - early_success\n",
        "    print(f\"   Success rate improvement: {early_success:.1%} → {late_success:.1%} ({success_improvement:+.1%})\")\n",
        "\n",
        "# Domain expertise analysis\n",
        "print(f\"\\n🎯 DOMAIN EXPERTISE ANALYSIS:\")\n",
        "domain_tasks = defaultdict(list)\n",
        "for result in results_summary:\n",
        "    domain_tasks[result['domain']].append(result)\n",
        "\n",
        "for domain, tasks in domain_tasks.items():\n",
        "    if len(tasks) > 1:\n",
        "        scores = [t['score'] for t in tasks]\n",
        "        avg_score = sum(scores) / len(scores)\n",
        "        success_rate = sum(1 for t in tasks if t['success']) / len(tasks)\n",
        "        expertise_level = test_agent.expertise_areas.get(domain, 0.0)\n",
        "\n",
        "        print(f\"   {domain}:\")\n",
        "        print(f\"     Tasks: {len(tasks)}, Avg score: {avg_score:.3f}, Success: {success_rate:.1%}\")\n",
        "        print(f\"     Expertise developed: {expertise_level:.3f}\")\n",
        "\n",
        "# Recommendations usage analysis\n",
        "total_recommendations = sum(r['recommendations_used'] for r in results_summary)\n",
        "tasks_with_recommendations = sum(1 for r in results_summary if r['recommendations_used'] > 0)\n",
        "\n",
        "print(f\"\\n🧠 LEARNING APPLICATION ANALYSIS:\")\n",
        "print(f\"   Total recommendations used: {total_recommendations}\")\n",
        "print(f\"   Tasks that used recommendations: {tasks_with_recommendations}/{len(results_summary)}\")\n",
        "print(f\"   Average recommendations per task: {total_recommendations/len(results_summary):.1f}\")\n",
        "\n",
        "if tasks_with_recommendations > 0:\n",
        "    # Analyze performance when using vs not using recommendations\n",
        "    with_rec_scores = [r['score'] for r in results_summary if r['recommendations_used'] > 0]\n",
        "    without_rec_scores = [r['score'] for r in results_summary if r['recommendations_used'] == 0]\n",
        "\n",
        "    if with_rec_scores and without_rec_scores:\n",
        "        with_rec_avg = sum(with_rec_scores) / len(with_rec_scores)\n",
        "        without_rec_avg = sum(without_rec_scores) / len(without_rec_scores)\n",
        "\n",
        "        print(f\"   Performance with recommendations: {with_rec_avg:.3f}\")\n",
        "        print(f\"   Performance without recommendations: {without_rec_avg:.3f}\")\n",
        "        print(f\"   Learning benefit: {with_rec_avg - without_rec_avg:+.3f}\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Adaptive Agent Testing Complete!\")\n",
        "print()\n",
        "print(\"📋 WHAT WE DEMONSTRATED:\")\n",
        "print(\"   ✅ Task execution with learning-based action selection\")\n",
        "print(\"   ✅ Dynamic exploration vs exploitation balancing\")\n",
        "print(\"   ✅ Domain expertise development over time\")\n",
        "print(\"   ✅ Behavioral adaptation based on performance feedback\")\n",
        "print(\"   ✅ External feedback integration for supervised learning\")\n",
        "print(\"   ✅ Knowledge transfer between domains\")\n",
        "print(\"   ✅ Observation-based learning from other agents\")\n",
        "print(\"   ✅ Comprehensive performance tracking and analysis\")\n",
        "print()\n",
        "print(\"🔑 KEY INSIGHTS FROM THIS TEST:\")\n",
        "print(\"   • The agent learned to make better decisions over time\")\n",
        "print(\"   • Exploration rate adapted based on success patterns\")\n",
        "print(\"   • Domain expertise accumulated through repeated tasks\")\n",
        "print(\"   • Behavioral parameters self-tuned for better performance\")\n",
        "print(\"   • Learning from multiple sources (experience, feedback, observation)\")\n",
        "print()\n",
        "print(\"🚀 Ready for Part 5: Multi-Agent Learning System\")\n",
        "print(\"   Next we'll connect multiple adaptive agents for collaborative learning!\")\n",
        "print()\n",
        "print(\"📦 WHAT WE BUILT IN PART 4:\")\n",
        "print(\"   • AdaptiveAgent class with comprehensive learning capabilities\")\n",
        "print(\"   • Dynamic action selection (exploration vs exploitation)\")\n",
        "print(\"   • Multi-dimensional performance evaluation\")\n",
        "print(\"   • Domain expertise tracking and development\")\n",
        "print(\"   • Behavioral adaptation based on performance trends\")\n",
        "print(\"   • External feedback integration\")\n",
        "print(\"   • Knowledge transfer between domains\")\n",
        "print(\"   • Observation-based learning from other agents\")\n",
        "print(\"   • Comprehensive status reporting and analysis\")\n",
        "print(\"   • Realistic task simulation and performance measurement\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tESAfIRC4F4",
        "outputId": "5cea1133-1547-410a-c792-444de8d6694d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12 Part 4: Adaptive Agent\n",
            "===================================\n",
            "Building an agent that learns and adapts from experience...\n",
            "\n",
            "🧪 Testing Adaptive Agent with Comprehensive Examples...\n",
            "\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 3 objectives\n",
            "🤖 Created adaptive agent: TestBot\n",
            "   Learning objectives: ['accuracy', 'efficiency', 'quality']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🎯 Running 6 diverse scenarios to test learning and adaptation...\n",
            "\n",
            "📋 Scenario 1: Handle urgent customer complaint about billing error\n",
            "   Domain: customer_service, Type: complaint_resolution\n",
            "🎯 TestBot executing: Handle urgent customer complaint about billing err...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.647)\n",
            "   📝 Stored experience: Handle urgent customer complaint about billing err...\n",
            "     📈 customer_service expertise: 0.00 → 0.06\n",
            "   ➤ Action taken: standard_approach\n",
            "   ➤ Success: ❌\n",
            "   ➤ Performance score: 0.647\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "📋 Scenario 2: Optimize slow database query for user dashboard\n",
            "   Domain: database_optimization, Type: performance_tuning\n",
            "🎯 TestBot executing: Optimize slow database query for user dashboard...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.646)\n",
            "   📝 Stored experience: Optimize slow database query for user dashboard...\n",
            "     📈 database_optimization expertise: 0.00 → 0.06\n",
            "   ➤ Action taken: standard_approach\n",
            "   ➤ Success: ❌\n",
            "   ➤ Performance score: 0.646\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "   📝 Processing feedback for task: Optimize slow database query for user da...\n",
            "   📝 Stored experience: Feedback on: Optimize slow database query for user...\n",
            "   ✅ Learned from corrective feedback\n",
            "   📝 Received corrective feedback: Scenario 2: Consider alternative strategies for better results\n",
            "\n",
            "📋 Scenario 3: Design responsive layout for mobile e-commerce app\n",
            "   Domain: ui_design, Type: responsive_design\n",
            "🎯 TestBot executing: Design responsive layout for mobile e-commerce app...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.548)\n",
            "   📝 Stored experience: Design responsive layout for mobile e-commerce app...\n",
            "     📈 ui_design expertise: 0.00 → 0.05\n",
            "   ➤ Action taken: standard_approach\n",
            "   ➤ Success: ❌\n",
            "   ➤ Performance score: 0.548\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "📋 Scenario 4: Analyze quarterly sales data for trends and insights\n",
            "   Domain: data_analysis, Type: business_intelligence\n",
            "🎯 TestBot executing: Analyze quarterly sales data for trends and insigh...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.703)\n",
            "   📝 Stored experience: Analyze quarterly sales data for trends and insigh...\n",
            "     📈 data_analysis expertise: 0.00 → 0.07\n",
            "   ➤ Action taken: standard_approach\n",
            "   ➤ Success: ✅\n",
            "   ➤ Performance score: 0.703\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "   📝 Processing feedback for task: Analyze quarterly sales data for trends ...\n",
            "   📝 Stored experience: Feedback on: Analyze quarterly sales data for tren...\n",
            "   ✅ Learned from positive feedback\n",
            "   📝 Received positive feedback: Scenario 4: Well executed approach\n",
            "\n",
            "📋 Scenario 5: Write API documentation for new authentication service\n",
            "   Domain: technical_writing, Type: api_documentation\n",
            "🎯 TestBot executing: Write API documentation for new authentication ser...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.657)\n",
            "   📝 Stored experience: Write API documentation for new authentication ser...\n",
            "     📈 technical_writing expertise: 0.00 → 0.07\n",
            "   ➤ Action taken: standard_approach\n",
            "   ➤ Success: ✅\n",
            "   ➤ Performance score: 0.657\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "📋 Scenario 6: Debug memory leak in production web application\n",
            "   Domain: software_debugging, Type: production_issue\n",
            "🎯 TestBot executing: Debug memory leak in production web application...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🔍 Exploring with action: standard_procedure\n",
            "   🎲 Chose action: standard_procedure\n",
            "   ✅ Result: True (score: 0.815)\n",
            "   📝 Stored experience: Debug memory leak in production web application...\n",
            "     📈 software_debugging expertise: 0.00 → 0.08\n",
            "   ➤ Action taken: standard_procedure\n",
            "   ➤ Success: ✅\n",
            "   ➤ Performance score: 0.815\n",
            "   ➤ Used 0 recommendations from experience\n",
            "\n",
            "   📝 Processing feedback for task: Debug memory leak in production web appl...\n",
            "   📝 Stored experience: Feedback on: Debug memory leak in production web a...\n",
            "   ✅ Learned from positive feedback\n",
            "   📝 Received positive feedback: Scenario 6: Well executed approach\n",
            "\n",
            "🔄 Testing knowledge transfer between domains...\n",
            "   Current expertise levels:\n",
            "\n",
            "   Transferring knowledge: software_debugging → cross_functional_collaboration\n",
            "   🔄 Transferring knowledge: software_debugging (0.08) → cross_functional_collaboration\n",
            "   📝 Stored experience: Transfer knowledge from software_debugging to cros...\n",
            "   ✅ Transfer complete: cross_functional_collaboration expertise now 0.02\n",
            "\n",
            "👁️ Testing observation learning...\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 1 objectives\n",
            "🤖 Created adaptive agent: ExperiencedBot\n",
            "   Learning objectives: ['accuracy']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "   Student agent observing teacher on project management task...\n",
            "   👁️ Observing ExperiencedBot on task: Plan project timeline and coordinate tea...\n",
            "   ℹ️ No clear approach to learn from ExperiencedBot\n",
            "\n",
            "📊 FINAL AGENT STATUS AND LEARNING ANALYSIS\n",
            "=======================================================\n",
            "🤖 Agent: TestBot\n",
            "   📈 Tasks completed: 6\n",
            "   ✅ Current success rate: 50.0%\n",
            "   🎯 Average performance score: 0.669\n",
            "   🔍 Current exploration rate: 0.100\n",
            "   🛡️ Current confidence threshold: 0.600\n",
            "   🔄 Total adaptations made: 0\n",
            "\n",
            "🏆 TOP EXPERTISE AREAS:\n",
            "   1. software_debugging: 0.082 █░░░░░░░░░░░░░░░░░░░\n",
            "   2. production_issue: 0.082 █░░░░░░░░░░░░░░░░░░░\n",
            "   3. data_analysis: 0.070 █░░░░░░░░░░░░░░░░░░░\n",
            "   4. business_intelligence: 0.070 █░░░░░░░░░░░░░░░░░░░\n",
            "   5. technical_writing: 0.066 █░░░░░░░░░░░░░░░░░░░\n",
            "\n",
            "📚 LEARNING PROGRESS:\n",
            "   🔍 Patterns discovered: 0\n",
            "   💾 Total experiences stored: 10\n",
            "   ✅ Experience success rate: 60.0%\n",
            "   📊 Memory utilization: 1.0%\n",
            "\n",
            "📈 LEARNING PROGRESSION ANALYSIS:\n",
            "   Scenario progression:\n",
            "     1. customer_service: 0.647 ❌ \n",
            "     2. database_optimization: 0.646 ❌ ➡️\n",
            "     3. ui_design: 0.548 ❌ ➡️\n",
            "     4. data_analysis: 0.703 ✅ ↗️\n",
            "     5. technical_writing: 0.657 ✅ ➡️\n",
            "     6. software_debugging: 0.815 ✅ ↗️\n",
            "\n",
            "📊 PERFORMANCE TREND ANALYSIS:\n",
            "   Early performance (first 3 tasks): 0.614\n",
            "   Recent performance (last 3 tasks): 0.725\n",
            "   Overall trend: improving (+0.111)\n",
            "   Success rate improvement: 0.0% → 100.0% (+100.0%)\n",
            "\n",
            "🎯 DOMAIN EXPERTISE ANALYSIS:\n",
            "\n",
            "🧠 LEARNING APPLICATION ANALYSIS:\n",
            "   Total recommendations used: 0\n",
            "   Tasks that used recommendations: 0/6\n",
            "   Average recommendations per task: 0.0\n",
            "\n",
            "🎉 Adaptive Agent Testing Complete!\n",
            "\n",
            "📋 WHAT WE DEMONSTRATED:\n",
            "   ✅ Task execution with learning-based action selection\n",
            "   ✅ Dynamic exploration vs exploitation balancing\n",
            "   ✅ Domain expertise development over time\n",
            "   ✅ Behavioral adaptation based on performance feedback\n",
            "   ✅ External feedback integration for supervised learning\n",
            "   ✅ Knowledge transfer between domains\n",
            "   ✅ Observation-based learning from other agents\n",
            "   ✅ Comprehensive performance tracking and analysis\n",
            "\n",
            "🔑 KEY INSIGHTS FROM THIS TEST:\n",
            "   • The agent learned to make better decisions over time\n",
            "   • Exploration rate adapted based on success patterns\n",
            "   • Domain expertise accumulated through repeated tasks\n",
            "   • Behavioral parameters self-tuned for better performance\n",
            "   • Learning from multiple sources (experience, feedback, observation)\n",
            "\n",
            "🚀 Ready for Part 5: Multi-Agent Learning System\n",
            "   Next we'll connect multiple adaptive agents for collaborative learning!\n",
            "\n",
            "📦 WHAT WE BUILT IN PART 4:\n",
            "   • AdaptiveAgent class with comprehensive learning capabilities\n",
            "   • Dynamic action selection (exploration vs exploitation)\n",
            "   • Multi-dimensional performance evaluation\n",
            "   • Domain expertise tracking and development\n",
            "   • Behavioral adaptation based on performance trends\n",
            "   • External feedback integration\n",
            "   • Knowledge transfer between domains\n",
            "   • Observation-based learning from other agents\n",
            "   • Comprehensive status reporting and analysis\n",
            "   • Realistic task simulation and performance measurement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this after Parts 1-4 to build coordinated learning across multiple agents\n",
        "\n",
        "print(\"Tutorial 12 Part 5: Multi-Agent Learning System\")\n",
        "print(\"=\" * 45)\n",
        "print(\"Building coordinated learning across multiple agents...\")\n",
        "print()\n",
        "\n",
        "# Make sure you've run Parts 1-4 first!\n",
        "\n",
        "class MultiAgentLearningSystem:\n",
        "    \"\"\"\n",
        "    System for coordinating learning across multiple adaptive agents\n",
        "\n",
        "    This enables agents to learn from each other and share knowledge\n",
        "    for collective improvement.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.agents = {}\n",
        "        self.shared_knowledge_base = {}\n",
        "        self.collaboration_history = []\n",
        "        self.knowledge_transfer_events = []\n",
        "\n",
        "        print(f\"🏫 Multi-agent learning system initialized: {name}\")\n",
        "\n",
        "    def add_agent(self, agent: AdaptiveAgent, specialization: str = None):\n",
        "        \"\"\"Add an adaptive agent to the learning system\"\"\"\n",
        "        self.agents[agent.id] = {\n",
        "            'agent': agent,\n",
        "            'specialization': specialization,\n",
        "            'joined_at': time.time(),\n",
        "            'contributions': 0\n",
        "        }\n",
        "        print(f\"   👥 Added agent {agent.name} (specialization: {specialization or 'general'})\")\n",
        "\n",
        "    def coordinate_learning_session(self, task_scenarios: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"Coordinate a learning session across all agents\"\"\"\n",
        "\n",
        "        print(f\"🎓 Starting coordinated learning session with {len(task_scenarios)} scenarios...\")\n",
        "\n",
        "        session_results = {\n",
        "            'session_id': str(uuid.uuid4()),\n",
        "            'timestamp': time.time(),\n",
        "            'scenarios_completed': 0,\n",
        "            'agent_results': {},\n",
        "            'knowledge_shared': 0,\n",
        "            'performance_improvements': {}\n",
        "        }\n",
        "\n",
        "        # Execute scenarios\n",
        "        for i, scenario in enumerate(task_scenarios):\n",
        "            print(f\"   📋 Scenario {i+1}: {scenario['description']}\")\n",
        "\n",
        "            scenario_results = {}\n",
        "\n",
        "            # Each agent attempts the scenario\n",
        "            for agent_id, agent_info in self.agents.items():\n",
        "                agent = agent_info['agent']\n",
        "\n",
        "                result = agent.execute_task(\n",
        "                    task_description=scenario['description'],\n",
        "                    task_data=scenario.get('data'),\n",
        "                    context=scenario.get('context', {})\n",
        "                )\n",
        "\n",
        "                scenario_results[agent_id] = result\n",
        "\n",
        "                if agent_id not in session_results['agent_results']:\n",
        "                    session_results['agent_results'][agent_id] = []\n",
        "                session_results['agent_results'][agent_id].append(result)\n",
        "\n",
        "            # Cross-agent learning from this scenario\n",
        "            self._facilitate_cross_learning(scenario_results, scenario)\n",
        "            session_results['scenarios_completed'] += 1\n",
        "\n",
        "        # Post-session knowledge consolidation\n",
        "        knowledge_shared = self._consolidate_session_knowledge(session_results)\n",
        "        session_results['knowledge_shared'] = knowledge_shared\n",
        "\n",
        "        # Calculate performance improvements\n",
        "        session_results['performance_improvements'] = self._calculate_improvements(session_results)\n",
        "\n",
        "        print(f\"   ✅ Learning session complete: {session_results['scenarios_completed']} scenarios, {knowledge_shared} knowledge transfers\")\n",
        "\n",
        "        return session_results\n",
        "\n",
        "    def _facilitate_cross_learning(self, scenario_results: Dict[str, Any], scenario: Dict[str, Any]):\n",
        "        \"\"\"Facilitate learning between agents based on scenario results\"\"\"\n",
        "\n",
        "        # Find best performing agent for this scenario\n",
        "        best_agent_id = max(scenario_results.keys(),\n",
        "                           key=lambda aid: scenario_results[aid]['performance']['overall_score'])\n",
        "        best_result = scenario_results[best_agent_id]\n",
        "\n",
        "        # Have other agents observe the best performer\n",
        "        for agent_id, agent_info in self.agents.items():\n",
        "            if agent_id != best_agent_id:\n",
        "                observer_agent = agent_info['agent']\n",
        "                best_agent = self.agents[best_agent_id]['agent']\n",
        "\n",
        "                observer_agent.observe_other_agent(\n",
        "                    best_agent,\n",
        "                    scenario['description'],\n",
        "                    scenario.get('context', {})\n",
        "                )\n",
        "\n",
        "        # Record collaboration\n",
        "        collaboration_record = {\n",
        "            'timestamp': time.time(),\n",
        "            'scenario': scenario['description'],\n",
        "            'best_performer': best_agent_id,\n",
        "            'best_score': best_result['performance']['overall_score'],\n",
        "            'observers': [aid for aid in self.agents.keys() if aid != best_agent_id]\n",
        "        }\n",
        "        self.collaboration_history.append(collaboration_record)\n",
        "\n",
        "    def _consolidate_session_knowledge(self, session_results: Dict[str, Any]) -> int:\n",
        "        \"\"\"Consolidate knowledge from the learning session\"\"\"\n",
        "\n",
        "        knowledge_transfers = 0\n",
        "\n",
        "        # Extract successful patterns from all agents\n",
        "        successful_patterns = {}\n",
        "\n",
        "        for agent_id, results in session_results['agent_results'].items():\n",
        "            agent = self.agents[agent_id]['agent']\n",
        "\n",
        "            # Get patterns from successful tasks\n",
        "            for result in results:\n",
        "                if result['performance']['success']:\n",
        "                    pattern_key = f\"{result['action_taken']}_{agent_id}\"\n",
        "                    successful_patterns[pattern_key] = {\n",
        "                        'agent_id': agent_id,\n",
        "                        'action': result['action_taken'],\n",
        "                        'performance': result['performance']['overall_score'],\n",
        "                        'context': result.get('context', {})\n",
        "                    }\n",
        "\n",
        "        # Share successful patterns with underperforming agents\n",
        "        for agent_id, agent_info in self.agents.items():\n",
        "            agent = agent_info['agent']\n",
        "            agent_results = session_results['agent_results'].get(agent_id, [])\n",
        "\n",
        "            if agent_results:\n",
        "                avg_performance = sum(r['performance']['overall_score'] for r in agent_results) / len(agent_results)\n",
        "\n",
        "                # If performance is below average, share successful patterns\n",
        "                if avg_performance < 0.6:\n",
        "                    for pattern in successful_patterns.values():\n",
        "                        if pattern['agent_id'] != agent_id and pattern['performance'] > avg_performance + 0.2:\n",
        "                            # Create shared knowledge\n",
        "                            knowledge_id = str(uuid.uuid4())\n",
        "                            self.shared_knowledge_base[knowledge_id] = {\n",
        "                                'pattern': pattern,\n",
        "                                'created_at': time.time(),\n",
        "                                'source_agent': pattern['agent_id'],\n",
        "                                'shared_with': [agent_id],\n",
        "                                'effectiveness': pattern['performance']\n",
        "                            }\n",
        "                            knowledge_transfers += 1\n",
        "\n",
        "        return knowledge_transfers\n",
        "\n",
        "    def _calculate_improvements(self, session_results: Dict[str, Any]) -> Dict[str, float]:\n",
        "        \"\"\"Calculate performance improvements for each agent\"\"\"\n",
        "\n",
        "        improvements = {}\n",
        "\n",
        "        for agent_id, results in session_results['agent_results'].items():\n",
        "            if len(results) > 1:\n",
        "                # Compare first half vs second half performance\n",
        "                mid_point = len(results) // 2\n",
        "                first_half_avg = sum(r['performance']['overall_score'] for r in results[:mid_point]) / mid_point\n",
        "                second_half_avg = sum(r['performance']['overall_score'] for r in results[mid_point:]) / (len(results) - mid_point)\n",
        "\n",
        "                improvement = second_half_avg - first_half_avg\n",
        "                improvements[agent_id] = improvement\n",
        "\n",
        "        return improvements\n",
        "\n",
        "    def facilitate_knowledge_transfer(self, source_agent_id: str, target_agent_id: str,\n",
        "                                    domain: str) -> Dict[str, Any]:\n",
        "        \"\"\"Facilitate direct knowledge transfer between two agents\"\"\"\n",
        "\n",
        "        if source_agent_id not in self.agents or target_agent_id not in self.agents:\n",
        "            return {'error': 'Agent not found'}\n",
        "\n",
        "        source_agent = self.agents[source_agent_id]['agent']\n",
        "        target_agent = self.agents[target_agent_id]['agent']\n",
        "\n",
        "        # Check source agent's expertise in domain\n",
        "        source_expertise = source_agent.expertise_areas.get(domain, 0.0)\n",
        "        if source_expertise < 0.3:\n",
        "            return {'error': f'Source agent has insufficient expertise in {domain}'}\n",
        "\n",
        "        # Transfer knowledge\n",
        "        transfer_result = target_agent.transfer_knowledge_to_domain(domain, domain)\n",
        "\n",
        "        # Record transfer event\n",
        "        transfer_event = {\n",
        "            'timestamp': time.time(),\n",
        "            'source_agent': source_agent_id,\n",
        "            'target_agent': target_agent_id,\n",
        "            'domain': domain,\n",
        "            'source_expertise': source_expertise,\n",
        "            'transfer_result': transfer_result\n",
        "        }\n",
        "        self.knowledge_transfer_events.append(transfer_event)\n",
        "\n",
        "        # Update contribution counts\n",
        "        self.agents[source_agent_id]['contributions'] += 1\n",
        "\n",
        "        print(f\"   🔄 Knowledge transfer: {source_agent.name} → {target_agent.name} (domain: {domain})\")\n",
        "\n",
        "        return {\n",
        "            'success': True,\n",
        "            'transfer_event': transfer_event,\n",
        "            'source_expertise': source_expertise,\n",
        "            'target_expertise_after': target_agent.expertise_areas.get(domain, 0.0)\n",
        "        }\n",
        "\n",
        "    def get_system_analytics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get comprehensive analytics for the learning system\"\"\"\n",
        "\n",
        "        total_agents = len(self.agents)\n",
        "        total_tasks = sum(len(agent_info['agent'].task_history) for agent_info in self.agents.values())\n",
        "        total_collaborations = len(self.collaboration_history)\n",
        "        total_transfers = len(self.knowledge_transfer_events)\n",
        "\n",
        "        # Agent performance summary\n",
        "        agent_performance = {}\n",
        "        for agent_id, agent_info in self.agents.items():\n",
        "            agent = agent_info['agent']\n",
        "            status = agent.get_agent_status()\n",
        "            agent_performance[agent_id] = {\n",
        "                'name': agent.name,\n",
        "                'tasks_completed': status['tasks_completed'],\n",
        "                'success_rate': status['current_performance']['success_rate'],\n",
        "                'top_expertise': list(status['expertise_areas'].keys())[:3],\n",
        "                'contributions': agent_info['contributions']\n",
        "            }\n",
        "\n",
        "        # Knowledge sharing effectiveness\n",
        "        if self.knowledge_transfer_events:\n",
        "            recent_transfers = self.knowledge_transfer_events[-10:]\n",
        "            avg_source_expertise = sum(t['source_expertise'] for t in recent_transfers) / len(recent_transfers)\n",
        "        else:\n",
        "            avg_source_expertise = 0.0\n",
        "\n",
        "        return {\n",
        "            'system_name': self.name,\n",
        "            'total_agents': total_agents,\n",
        "            'total_tasks_completed': total_tasks,\n",
        "            'collaboration_events': total_collaborations,\n",
        "            'knowledge_transfers': total_transfers,\n",
        "            'shared_knowledge_items': len(self.shared_knowledge_base),\n",
        "            'agent_performance': agent_performance,\n",
        "            'knowledge_sharing_effectiveness': avg_source_expertise,\n",
        "            'avg_tasks_per_agent': total_tasks / max(total_agents, 1)\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# TEST THE MULTI-AGENT LEARNING SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing Multi-Agent Learning System...\")\n",
        "\n",
        "# Create multi-agent learning system\n",
        "learning_system = MultiAgentLearningSystem(\"TechTeam Learning\")\n",
        "\n",
        "# Create specialized agents\n",
        "agents = [\n",
        "    AdaptiveAgent(name=\"BackendExpert\", learning_objectives=[LearningObjective.EFFICIENCY, LearningObjective.ROBUSTNESS]),\n",
        "    AdaptiveAgent(name=\"FrontendExpert\", learning_objectives=[LearningObjective.QUALITY, LearningObjective.ADAPTABILITY]),\n",
        "    AdaptiveAgent(name=\"DataExpert\", learning_objectives=[LearningObjective.ACCURACY, LearningObjective.EFFICIENCY]),\n",
        "    AdaptiveAgent(name=\"Generalist\", learning_objectives=[LearningObjective.ADAPTABILITY])\n",
        "]\n",
        "\n",
        "# Add agents with specializations\n",
        "specializations = ['backend', 'frontend', 'data_science', 'general']\n",
        "for agent, specialization in zip(agents, specializations):\n",
        "    learning_system.add_agent(agent, specialization)\n",
        "\n",
        "# Pre-seed some expertise to make the demo more interesting\n",
        "agents[0].expertise_areas['software_engineering'] = 0.7\n",
        "agents[0].expertise_areas['database'] = 0.6\n",
        "agents[1].expertise_areas['design'] = 0.8\n",
        "agents[1].expertise_areas['technical_writing'] = 0.5\n",
        "agents[2].expertise_areas['finance'] = 0.6\n",
        "agents[2].expertise_areas['database'] = 0.7\n",
        "\n",
        "print(f\"\\n🎯 Pre-seeded expertise:\")\n",
        "for i, agent in enumerate(agents):\n",
        "    if agent.expertise_areas:\n",
        "        top_expertise = sorted(agent.expertise_areas.items(), key=lambda x: x[1], reverse=True)[:2]\n",
        "        print(f\"   {agent.name}: {', '.join([f'{area}({level:.1f})' for area, level in top_expertise])}\")\n",
        "\n",
        "# Create diverse learning scenarios\n",
        "learning_scenarios = [\n",
        "    {\n",
        "        'description': 'Process customer support request',\n",
        "        'data': {'customer_type': 'premium', 'issue_type': 'technical', 'urgency': 'high'},\n",
        "        'context': {'domain': 'customer_service', 'task_type': 'support'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Optimize database query performance',\n",
        "        'data': {'database_type': 'postgresql', 'query_complexity': 'high', 'data_size': 'large'},\n",
        "        'context': {'domain': 'database', 'task_type': 'optimization'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Design user interface for mobile application',\n",
        "        'data': {'app_type': 'productivity', 'target_users': 'professionals', 'platform': 'ios'},\n",
        "        'context': {'domain': 'design', 'task_type': 'ui_design'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Analyze market data for investment decision',\n",
        "        'data': {'market_trend': 'bullish', 'volatility': 'medium', 'sector': 'technology'},\n",
        "        'context': {'domain': 'finance', 'task_type': 'analysis'}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Coordinate learning session\n",
        "print(f\"\\n🎓 Running coordinated learning session...\")\n",
        "session_result = learning_system.coordinate_learning_session(learning_scenarios)\n",
        "\n",
        "print(f\"\\n📈 SESSION RESULTS:\")\n",
        "print(f\"   Scenarios Completed: {session_result['scenarios_completed']}\")\n",
        "print(f\"   Knowledge Transfers: {session_result['knowledge_shared']}\")\n",
        "print(f\"   Performance Improvements:\")\n",
        "for agent_id, improvement in session_result['performance_improvements'].items():\n",
        "    agent_name = learning_system.agents[agent_id]['agent'].name\n",
        "    trend = \"↗️\" if improvement > 0.1 else \"↘️\" if improvement < -0.1 else \"➡️\"\n",
        "    print(f\"     {agent_name}: {improvement:+.3f} {trend}\")\n",
        "\n",
        "# Test direct knowledge transfer\n",
        "print(f\"\\n🔄 Testing direct knowledge transfer...\")\n",
        "backend_expert = agents[0]\n",
        "data_expert = agents[2]\n",
        "\n",
        "transfer_result = learning_system.facilitate_knowledge_transfer(\n",
        "    backend_expert.id, data_expert.id, 'database'\n",
        ")\n",
        "\n",
        "if transfer_result.get('success'):\n",
        "    print(f\"   ✅ Transferred database knowledge from {backend_expert.name} to {data_expert.name}\")\n",
        "    print(f\"   Source expertise: {transfer_result['source_expertise']:.2f}\")\n",
        "    print(f\"   Target expertise after: {transfer_result['target_expertise_after']:.2f}\")\n",
        "\n",
        "# Get system analytics\n",
        "print(f\"\\n📊 SYSTEM ANALYTICS:\")\n",
        "analytics = learning_system.get_system_analytics()\n",
        "print(f\"   Total Agents: {analytics['total_agents']}\")\n",
        "print(f\"   Total Tasks: {analytics['total_tasks_completed']}\")\n",
        "print(f\"   Collaboration Events: {analytics['collaboration_events']}\")\n",
        "print(f\"   Knowledge Transfers: {analytics['knowledge_transfers']}\")\n",
        "print(f\"   Shared Knowledge Items: {analytics['shared_knowledge_items']}\")\n",
        "print(f\"   Avg Tasks per Agent: {analytics['avg_tasks_per_agent']:.1f}\")\n",
        "\n",
        "print(f\"\\n👥 AGENT PERFORMANCE SUMMARY:\")\n",
        "for agent_id, performance in analytics['agent_performance'].items():\n",
        "    print(f\"   {performance['name']}:\")\n",
        "    print(f\"     Tasks: {performance['tasks_completed']}, Success: {performance['success_rate']:.1%}\")\n",
        "    print(f\"     Top expertise: {', '.join(performance['top_expertise'])}\")\n",
        "    print(f\"     Contributions: {performance['contributions']}\")\n",
        "\n",
        "# Show collaboration examples\n",
        "if learning_system.collaboration_history:\n",
        "    print(f\"\\n🤝 RECENT COLLABORATIONS:\")\n",
        "    for collab in learning_system.collaboration_history[-3:]:\n",
        "        best_performer = learning_system.agents[collab['best_performer']]['agent'].name\n",
        "        print(f\"   {collab['scenario'][:40]}...\")\n",
        "        print(f\"     Best performer: {best_performer} (score: {collab['best_score']:.3f})\")\n",
        "        print(f\"     Observers: {len(collab['observers'])} agents\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Multi-Agent Learning System working correctly!\")\n",
        "print(\"   Ready for Part 6: Learning Visualization and Analysis\")\n",
        "print()\n",
        "print(\"📋 Summary of what we built:\")\n",
        "print(\"   • MultiAgentLearningSystem - Coordinated learning across agents\")\n",
        "print(\"   • Cross-agent observation and learning\")\n",
        "print(\"   • Knowledge consolidation and sharing\")\n",
        "print(\"   • Performance improvement tracking\")\n",
        "print(\"   • Direct knowledge transfer between agents\")\n",
        "print(\"   • Comprehensive system analytics\")\n",
        "print(\"   • Collaboration history and contribution tracking\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKKMM0bbDO3O",
        "outputId": "6b745834-7f36-4dc9-cac4-2dd4fac8c4b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12 Part 5: Multi-Agent Learning System\n",
            "=============================================\n",
            "Building coordinated learning across multiple agents...\n",
            "\n",
            "🧪 Testing Multi-Agent Learning System...\n",
            "🏫 Multi-agent learning system initialized: TechTeam Learning\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 2 objectives\n",
            "🤖 Created adaptive agent: BackendExpert\n",
            "   Learning objectives: ['efficiency', 'robustness']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 2 objectives\n",
            "🤖 Created adaptive agent: FrontendExpert\n",
            "   Learning objectives: ['quality', 'adaptability']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 2 objectives\n",
            "🤖 Created adaptive agent: DataExpert\n",
            "   Learning objectives: ['accuracy', 'efficiency']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 1 objectives\n",
            "🤖 Created adaptive agent: Generalist\n",
            "   Learning objectives: ['adaptability']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "   👥 Added agent BackendExpert (specialization: backend)\n",
            "   👥 Added agent FrontendExpert (specialization: frontend)\n",
            "   👥 Added agent DataExpert (specialization: data_science)\n",
            "   👥 Added agent Generalist (specialization: general)\n",
            "\n",
            "🎯 Pre-seeded expertise:\n",
            "   BackendExpert: software_engineering(0.7), database(0.6)\n",
            "   FrontendExpert: design(0.8), technical_writing(0.5)\n",
            "   DataExpert: database(0.7), finance(0.6)\n",
            "\n",
            "🎓 Running coordinated learning session...\n",
            "🎓 Starting coordinated learning session with 4 scenarios...\n",
            "   📋 Scenario 1: Process customer support request\n",
            "🎯 BackendExpert executing: Process customer support request...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.625)\n",
            "   📝 Stored experience: Process customer support request...\n",
            "     📈 customer_service expertise: 0.00 → 0.06\n",
            "🎯 FrontendExpert executing: Process customer support request...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.647)\n",
            "   📝 Stored experience: Process customer support request...\n",
            "     📈 customer_service expertise: 0.00 → 0.06\n",
            "🎯 DataExpert executing: Process customer support request...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.734)\n",
            "   📝 Stored experience: Process customer support request...\n",
            "     📈 customer_service expertise: 0.00 → 0.07\n",
            "🎯 Generalist executing: Process customer support request...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.695)\n",
            "   📝 Stored experience: Process customer support request...\n",
            "     📈 customer_service expertise: 0.00 → 0.07\n",
            "   👁️ Observing DataExpert on task: Process customer support request...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Process customer support request...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Process customer support request...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   📋 Scenario 2: Optimize database query performance\n",
            "🎯 BackendExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🔍 Exploring with action: standard_procedure\n",
            "   🎲 Chose action: standard_procedure\n",
            "   ✅ Result: True (score: 0.773)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "🎯 FrontendExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.637)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database expertise: 0.00 → 0.06\n",
            "🎯 DataExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🎓 Using domain expertise: expert_database_approach (expertise: 0.70)\n",
            "   🎲 Chose action: expert_database_approach\n",
            "   ✅ Result: True (score: 0.951)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "🎯 Generalist executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.567)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database expertise: 0.00 → 0.06\n",
            "   👁️ Observing DataExpert on task: Optimize database query performance...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Optimize database query performance...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Optimize database query performance...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   📋 Scenario 3: Design user interface for mobile application\n",
            "🎯 BackendExpert executing: Design user interface for mobile application...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.749)\n",
            "   📝 Stored experience: Design user interface for mobile application...\n",
            "     📈 design expertise: 0.00 → 0.07\n",
            "🎯 FrontendExpert executing: Design user interface for mobile application...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🎓 Using domain expertise: expert_design_approach (expertise: 0.80)\n",
            "   🎲 Chose action: expert_design_approach\n",
            "   ✅ Result: True (score: 0.856)\n",
            "   📝 Stored experience: Design user interface for mobile application...\n",
            "🎯 DataExpert executing: Design user interface for mobile application...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.620)\n",
            "   📝 Stored experience: Design user interface for mobile application...\n",
            "     📈 design expertise: 0.00 → 0.06\n",
            "🎯 Generalist executing: Design user interface for mobile application...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.619)\n",
            "   📝 Stored experience: Design user interface for mobile application...\n",
            "     📈 design expertise: 0.00 → 0.06\n",
            "   👁️ Observing FrontendExpert on task: Design user interface for mobile applica...\n",
            "   ℹ️ No clear approach to learn from FrontendExpert\n",
            "   👁️ Observing FrontendExpert on task: Design user interface for mobile applica...\n",
            "   ℹ️ No clear approach to learn from FrontendExpert\n",
            "   👁️ Observing FrontendExpert on task: Design user interface for mobile applica...\n",
            "   ℹ️ No clear approach to learn from FrontendExpert\n",
            "   📋 Scenario 4: Analyze market data for investment decision\n",
            "🎯 BackendExpert executing: Analyze market data for investment decision...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.678)\n",
            "   📝 Stored experience: Analyze market data for investment decision...\n",
            "     📈 finance expertise: 0.00 → 0.07\n",
            "🎯 FrontendExpert executing: Analyze market data for investment decision...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.655)\n",
            "   📝 Stored experience: Analyze market data for investment decision...\n",
            "     📈 finance expertise: 0.00 → 0.07\n",
            "🎯 DataExpert executing: Analyze market data for investment decision...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🎓 Using domain expertise: expert_finance_approach (expertise: 0.60)\n",
            "   🎲 Chose action: expert_finance_approach\n",
            "   ✅ Result: True (score: 0.774)\n",
            "   📝 Stored experience: Analyze market data for investment decision...\n",
            "🎯 Generalist executing: Analyze market data for investment decision...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.615)\n",
            "   📝 Stored experience: Analyze market data for investment decision...\n",
            "     📈 finance expertise: 0.00 → 0.06\n",
            "   👁️ Observing DataExpert on task: Analyze market data for investment decis...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Analyze market data for investment decis...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   👁️ Observing DataExpert on task: Analyze market data for investment decis...\n",
            "   ℹ️ No clear approach to learn from DataExpert\n",
            "   ✅ Learning session complete: 4 scenarios, 0 knowledge transfers\n",
            "\n",
            "📈 SESSION RESULTS:\n",
            "   Scenarios Completed: 4\n",
            "   Knowledge Transfers: 0\n",
            "   Performance Improvements:\n",
            "     BackendExpert: +0.014 ➡️\n",
            "     FrontendExpert: +0.113 ↗️\n",
            "     DataExpert: -0.145 ↘️\n",
            "     Generalist: -0.014 ➡️\n",
            "\n",
            "🔄 Testing direct knowledge transfer...\n",
            "   🔄 Transferring knowledge: database (0.73) → database\n",
            "   📝 Stored experience: Transfer knowledge from database to database...\n",
            "   ✅ Transfer complete: database expertise now 0.73\n",
            "   🔄 Knowledge transfer: BackendExpert → DataExpert (domain: database)\n",
            "   ✅ Transferred database knowledge from BackendExpert to DataExpert\n",
            "   Source expertise: 0.62\n",
            "   Target expertise after: 0.73\n",
            "\n",
            "📊 SYSTEM ANALYTICS:\n",
            "   Total Agents: 4\n",
            "   Total Tasks: 16\n",
            "   Collaboration Events: 4\n",
            "   Knowledge Transfers: 1\n",
            "   Shared Knowledge Items: 0\n",
            "   Avg Tasks per Agent: 4.0\n",
            "\n",
            "👥 AGENT PERFORMANCE SUMMARY:\n",
            "   BackendExpert:\n",
            "     Tasks: 4, Success: 75.0%\n",
            "     Top expertise: software_engineering, database, optimization\n",
            "     Contributions: 1\n",
            "   FrontendExpert:\n",
            "     Tasks: 4, Success: 50.0%\n",
            "     Top expertise: design, technical_writing, ui_design\n",
            "     Contributions: 0\n",
            "   DataExpert:\n",
            "     Tasks: 4, Success: 75.0%\n",
            "     Top expertise: database, finance, optimization\n",
            "     Contributions: 0\n",
            "   Generalist:\n",
            "     Tasks: 4, Success: 25.0%\n",
            "     Top expertise: customer_service, support, design\n",
            "     Contributions: 0\n",
            "\n",
            "🤝 RECENT COLLABORATIONS:\n",
            "   Optimize database query performance...\n",
            "     Best performer: DataExpert (score: 0.951)\n",
            "     Observers: 3 agents\n",
            "   Design user interface for mobile applica...\n",
            "     Best performer: FrontendExpert (score: 0.856)\n",
            "     Observers: 3 agents\n",
            "   Analyze market data for investment decis...\n",
            "     Best performer: DataExpert (score: 0.774)\n",
            "     Observers: 3 agents\n",
            "\n",
            "🎉 Multi-Agent Learning System working correctly!\n",
            "   Ready for Part 6: Learning Visualization and Analysis\n",
            "\n",
            "📋 Summary of what we built:\n",
            "   • MultiAgentLearningSystem - Coordinated learning across agents\n",
            "   • Cross-agent observation and learning\n",
            "   • Knowledge consolidation and sharing\n",
            "   • Performance improvement tracking\n",
            "   • Direct knowledge transfer between agents\n",
            "   • Comprehensive system analytics\n",
            "   • Collaboration history and contribution tracking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this after Parts 1-5 to build comprehensive analysis and visualization tools\n",
        "\n",
        "print(\"Tutorial 12 Part 6: Learning Visualization and Analysis\")\n",
        "print(\"=\" * 55)\n",
        "print(\"Building comprehensive analysis and visualization tools...\")\n",
        "print()\n",
        "\n",
        "# Make sure you've run Parts 1-5 first!\n",
        "# This builds on: AdaptiveAgent, MultiAgentLearningSystem, and all previous components\n",
        "\n",
        "class LearningVisualizer:\n",
        "    \"\"\"\n",
        "    Visualization and analysis tools for learning systems\n",
        "\n",
        "    This provides insights into learning progress, performance trends,\n",
        "    and knowledge sharing effectiveness across individual agents\n",
        "    and multi-agent systems.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"📊 Learning visualizer initialized\")\n",
        "\n",
        "    def create_learning_dashboard(self, agent: AdaptiveAgent) -> Dict[str, Any]:\n",
        "        \"\"\"Create a comprehensive learning dashboard for an agent\"\"\"\n",
        "\n",
        "        status = agent.get_agent_status()\n",
        "\n",
        "        # Performance trends analysis\n",
        "        performance_trend = self._analyze_performance_trend(agent.task_history)\n",
        "\n",
        "        # Learning progress analysis\n",
        "        learning_progress = self._analyze_learning_progress(agent)\n",
        "\n",
        "        # Expertise development analysis\n",
        "        expertise_growth = self._analyze_expertise_growth(agent)\n",
        "\n",
        "        # Adaptation effectiveness analysis\n",
        "        adaptation_analysis = self._analyze_adaptations(agent.adaptation_history)\n",
        "\n",
        "        return {\n",
        "            'agent_overview': {\n",
        "                'name': agent.name,\n",
        "                'tasks_completed': status['tasks_completed'],\n",
        "                'current_success_rate': status['current_performance']['success_rate'],\n",
        "                'exploration_rate': status['current_performance']['exploration_rate']\n",
        "            },\n",
        "            'performance_trends': performance_trend,\n",
        "            'learning_progress': learning_progress,\n",
        "            'expertise_development': expertise_growth,\n",
        "            'adaptation_effectiveness': adaptation_analysis,\n",
        "            'recommendations': self._generate_learning_recommendations(agent)\n",
        "        }\n",
        "\n",
        "    def _analyze_performance_trend(self, task_history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze performance trends over time\"\"\"\n",
        "\n",
        "        if len(task_history) < 5:\n",
        "            return {'message': 'Insufficient data for trend analysis', 'trend': 'insufficient_data'}\n",
        "\n",
        "        # Group tasks into windows for trend analysis\n",
        "        window_size = max(3, len(task_history) // 8)  # Adaptive window size\n",
        "        windows = []\n",
        "\n",
        "        for i in range(0, len(task_history), window_size):\n",
        "            window = task_history[i:i+window_size]\n",
        "            avg_score = sum(task['performance']['overall_score'] for task in window) / len(window)\n",
        "            success_rate = sum(1 for task in window if task['performance']['success']) / len(window)\n",
        "\n",
        "            windows.append({\n",
        "                'window_start': i,\n",
        "                'window_end': min(i + window_size, len(task_history)),\n",
        "                'avg_score': avg_score,\n",
        "                'success_rate': success_rate,\n",
        "                'task_count': len(window)\n",
        "            })\n",
        "\n",
        "        # Calculate overall trend\n",
        "        if len(windows) >= 2:\n",
        "            early_avg = sum(w['avg_score'] for w in windows[:len(windows)//2]) / (len(windows)//2)\n",
        "            late_avg = sum(w['avg_score'] for w in windows[len(windows)//2:]) / (len(windows) - len(windows)//2)\n",
        "\n",
        "            if late_avg > early_avg + 0.1:\n",
        "                trend = 'improving'\n",
        "            elif late_avg < early_avg - 0.1:\n",
        "                trend = 'declining'\n",
        "            else:\n",
        "                trend = 'stable'\n",
        "        else:\n",
        "            trend = 'insufficient_data'\n",
        "\n",
        "        return {\n",
        "            'overall_trend': trend,\n",
        "            'windows': windows,\n",
        "            'improvement_rate': (windows[-1]['avg_score'] - windows[0]['avg_score']) / len(windows) if len(windows) > 1 else 0.0,\n",
        "            'total_improvement': windows[-1]['avg_score'] - windows[0]['avg_score'] if len(windows) > 1 else 0.0\n",
        "        }\n",
        "\n",
        "    def _analyze_learning_progress(self, agent: AdaptiveAgent) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze learning progress and knowledge acquisition\"\"\"\n",
        "\n",
        "        learning_stats = agent.learning_engine.get_learning_statistics()\n",
        "\n",
        "        # Pattern discovery rate\n",
        "        total_experiences = learning_stats['memory_statistics']['total_experiences']\n",
        "        patterns_per_experience = (learning_stats['patterns_discovered'] / max(total_experiences, 1))\n",
        "\n",
        "        # Learning efficiency - compare early vs recent performance\n",
        "        if len(agent.task_history) >= 8:\n",
        "            early_tasks = agent.task_history[:len(agent.task_history)//4]\n",
        "            recent_tasks = agent.task_history[-len(agent.task_history)//4:]\n",
        "\n",
        "            early_avg = sum(task['performance']['overall_score'] for task in early_tasks) / len(early_tasks)\n",
        "            recent_avg = sum(task['performance']['overall_score'] for task in recent_tasks) / len(recent_tasks)\n",
        "            learning_efficiency = (recent_avg - early_avg) / max(len(agent.task_history), 1)\n",
        "        else:\n",
        "            learning_efficiency = 0.0\n",
        "\n",
        "        return {\n",
        "            'patterns_discovered': learning_stats['patterns_discovered'],\n",
        "            'pattern_discovery_rate': patterns_per_experience,\n",
        "            'learning_efficiency': learning_efficiency,\n",
        "            'memory_utilization': learning_stats['memory_statistics']['capacity_utilization'],\n",
        "            'total_experiences': total_experiences,\n",
        "            'knowledge_quality': learning_stats['memory_statistics']['success_rate']\n",
        "        }\n",
        "\n",
        "    def _analyze_expertise_growth(self, agent: AdaptiveAgent) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze expertise development across domains\"\"\"\n",
        "\n",
        "        expertise_areas = agent.expertise_areas\n",
        "\n",
        "        if not expertise_areas:\n",
        "            return {'message': 'No expertise areas developed yet'}\n",
        "\n",
        "        # Top expertise areas\n",
        "        top_areas = sorted(expertise_areas.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "        # Expertise distribution\n",
        "        total_expertise = sum(expertise_areas.values())\n",
        "        if total_expertise > 0:\n",
        "            expertise_distribution = {area: level/total_expertise for area, level in expertise_areas.items()}\n",
        "        else:\n",
        "            expertise_distribution = {}\n",
        "\n",
        "        # Specialization vs generalization index\n",
        "        expertise_values = list(expertise_areas.values())\n",
        "        if expertise_values and len(expertise_values) > 1:\n",
        "            max_expertise = max(expertise_values)\n",
        "            avg_expertise = sum(expertise_values) / len(expertise_values)\n",
        "            specialization_index = max_expertise - avg_expertise\n",
        "        else:\n",
        "            specialization_index = 0.0\n",
        "\n",
        "        return {\n",
        "            'top_expertise_areas': top_areas,\n",
        "            'total_domains': len(expertise_areas),\n",
        "            'expertise_distribution': expertise_distribution,\n",
        "            'specialization_index': specialization_index,\n",
        "            'highest_expertise': max(expertise_values) if expertise_values else 0.0,\n",
        "            'average_expertise': sum(expertise_values) / len(expertise_values) if expertise_values else 0.0\n",
        "        }\n",
        "\n",
        "    def _analyze_adaptations(self, adaptation_history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze effectiveness of behavioral adaptations\"\"\"\n",
        "\n",
        "        if len(adaptation_history) < 2:\n",
        "            return {'message': 'Insufficient adaptation data'}\n",
        "\n",
        "        # Adaptation frequency analysis\n",
        "        if adaptation_history:\n",
        "            time_between_adaptations = []\n",
        "            for i in range(1, len(adaptation_history)):\n",
        "                time_diff = adaptation_history[i]['timestamp'] - adaptation_history[i-1]['timestamp']\n",
        "                time_between_adaptations.append(time_diff)\n",
        "\n",
        "            avg_adaptation_interval = sum(time_between_adaptations) / len(time_between_adaptations)\n",
        "        else:\n",
        "            avg_adaptation_interval = 0.0\n",
        "\n",
        "        # Parameter evolution analysis\n",
        "        exploration_evolution = [adapt['new_exploration_rate'] for adapt in adaptation_history]\n",
        "        confidence_evolution = [adapt['new_confidence_threshold'] for adapt in adaptation_history]\n",
        "\n",
        "        return {\n",
        "            'total_adaptations': len(adaptation_history),\n",
        "            'adaptation_frequency': avg_adaptation_interval,\n",
        "            'exploration_rate_trend': self._calculate_trend(exploration_evolution),\n",
        "            'confidence_threshold_trend': self._calculate_trend(confidence_evolution),\n",
        "            'latest_adaptation': adaptation_history[-1] if adaptation_history else None\n",
        "        }\n",
        "\n",
        "    def _calculate_trend(self, values: List[float]) -> str:\n",
        "        \"\"\"Calculate trend direction for a series of values\"\"\"\n",
        "        if len(values) < 2:\n",
        "            return 'insufficient_data'\n",
        "\n",
        "        start_avg = sum(values[:len(values)//2]) / (len(values)//2)\n",
        "        end_avg = sum(values[len(values)//2:]) / (len(values) - len(values)//2)\n",
        "\n",
        "        if end_avg > start_avg * 1.05:\n",
        "            return 'increasing'\n",
        "        elif end_avg < start_avg * 0.95:\n",
        "            return 'decreasing'\n",
        "        else:\n",
        "            return 'stable'\n",
        "\n",
        "    def _generate_learning_recommendations(self, agent: AdaptiveAgent) -> List[str]:\n",
        "        \"\"\"Generate recommendations for improving learning\"\"\"\n",
        "\n",
        "        recommendations = []\n",
        "        status = agent.get_agent_status()\n",
        "\n",
        "        # Performance-based recommendations\n",
        "        success_rate = status['current_performance']['success_rate']\n",
        "        if success_rate < 0.6:\n",
        "            recommendations.append(\"Consider increasing exploration rate to discover better strategies\")\n",
        "        elif success_rate > 0.8:\n",
        "            recommendations.append(\"Success rate is high - consider reducing exploration to exploit current knowledge\")\n",
        "\n",
        "        # Expertise-based recommendations\n",
        "        expertise_areas = status['expertise_areas']\n",
        "        if len(expertise_areas) < 3:\n",
        "            recommendations.append(\"Try tasks in new domains to develop broader expertise\")\n",
        "\n",
        "        max_expertise = max(expertise_areas.values()) if expertise_areas else 0.0\n",
        "        if max_expertise < 0.5:\n",
        "            recommendations.append(\"Focus on specific domains to develop deeper expertise\")\n",
        "\n",
        "        # Learning progress recommendations\n",
        "        learning_stats = status['learning_progress']\n",
        "        if learning_stats['patterns_discovered'] < 5:\n",
        "            recommendations.append(\"Engage in more varied tasks to discover useful patterns\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def generate_learning_report(self, agent: AdaptiveAgent) -> str:\n",
        "        \"\"\"Generate a comprehensive learning report\"\"\"\n",
        "\n",
        "        dashboard = self.create_learning_dashboard(agent)\n",
        "\n",
        "        report = []\n",
        "        report.append(\"=\" * 60)\n",
        "        report.append(\"ADAPTIVE AGENT LEARNING REPORT\")\n",
        "        report.append(\"=\" * 60)\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Overview section\n",
        "        overview = dashboard['agent_overview']\n",
        "        report.append(\"📊 AGENT OVERVIEW\")\n",
        "        report.append(f\"   Name: {overview['name']}\")\n",
        "        report.append(f\"   Tasks Completed: {overview['tasks_completed']}\")\n",
        "        report.append(f\"   Current Success Rate: {overview['current_success_rate']:.1%}\")\n",
        "        report.append(f\"   Exploration Rate: {overview['exploration_rate']:.3f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Performance trends section\n",
        "        trends = dashboard['performance_trends']\n",
        "        if 'overall_trend' in trends:\n",
        "            report.append(\"📈 PERFORMANCE TRENDS\")\n",
        "            report.append(f\"   Overall Trend: {trends['overall_trend'].replace('_', ' ').title()}\")\n",
        "            if 'improvement_rate' in trends:\n",
        "                report.append(f\"   Improvement Rate: {trends['improvement_rate']:.3f} per task window\")\n",
        "            if 'total_improvement' in trends:\n",
        "                report.append(f\"   Total Improvement: {trends['total_improvement']:+.3f}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Learning progress section\n",
        "        progress = dashboard['learning_progress']\n",
        "        if 'patterns_discovered' in progress:\n",
        "            report.append(\"🎓 LEARNING PROGRESS\")\n",
        "            report.append(f\"   Patterns Discovered: {progress['patterns_discovered']}\")\n",
        "            report.append(f\"   Learning Efficiency: {progress['learning_efficiency']:.3f}\")\n",
        "            report.append(f\"   Knowledge Quality: {progress['knowledge_quality']:.1%}\")\n",
        "            report.append(f\"   Memory Utilization: {progress['memory_utilization']:.1%}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Expertise development section\n",
        "        expertise = dashboard['expertise_development']\n",
        "        if 'top_expertise_areas' in expertise:\n",
        "            report.append(\"🏆 EXPERTISE DEVELOPMENT\")\n",
        "            report.append(f\"   Total Domains: {expertise['total_domains']}\")\n",
        "            report.append(f\"   Highest Expertise: {expertise['highest_expertise']:.3f}\")\n",
        "            report.append(f\"   Specialization Index: {expertise['specialization_index']:.3f}\")\n",
        "            report.append(\"   Top Areas:\")\n",
        "            for area, level in expertise['top_expertise_areas'][:3]:\n",
        "                report.append(f\"     {area}: {level:.3f}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Adaptations section\n",
        "        adaptations = dashboard['adaptation_effectiveness']\n",
        "        if 'total_adaptations' in adaptations:\n",
        "            report.append(\"🔄 ADAPTATION ANALYSIS\")\n",
        "            report.append(f\"   Total Adaptations: {adaptations['total_adaptations']}\")\n",
        "            if 'exploration_rate_trend' in adaptations:\n",
        "                report.append(f\"   Exploration Trend: {adaptations['exploration_rate_trend'].replace('_', ' ').title()}\")\n",
        "            if 'confidence_threshold_trend' in adaptations:\n",
        "                report.append(f\"   Confidence Trend: {adaptations['confidence_threshold_trend'].replace('_', ' ').title()}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Recommendations section\n",
        "        recommendations = dashboard['recommendations']\n",
        "        if recommendations:\n",
        "            report.append(\"💡 RECOMMENDATIONS\")\n",
        "            for i, rec in enumerate(recommendations, 1):\n",
        "                report.append(f\"   {i}. {rec}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        report.append(\"=\" * 60)\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    def analyze_multi_agent_system(self, learning_system: MultiAgentLearningSystem) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze the performance of a multi-agent learning system\"\"\"\n",
        "\n",
        "        analytics = learning_system.get_system_analytics()\n",
        "\n",
        "        # Agent performance comparison\n",
        "        agent_comparison = []\n",
        "        for agent_id, performance in analytics['agent_performance'].items():\n",
        "            agent_comparison.append({\n",
        "                'id': agent_id,\n",
        "                'name': performance['name'],\n",
        "                'tasks_completed': performance['tasks_completed'],\n",
        "                'success_rate': performance['success_rate'],\n",
        "                'contributions': performance['contributions'],\n",
        "                'expertise_breadth': len(performance['top_expertise'])\n",
        "            })\n",
        "\n",
        "        # Sort by overall effectiveness (success rate + contributions)\n",
        "        agent_comparison.sort(\n",
        "            key=lambda x: x['success_rate'] * 0.7 + (x['contributions'] / max(analytics['total_agents'], 1)) * 0.3,\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Knowledge sharing analysis\n",
        "        knowledge_sharing_health = {\n",
        "            'transfer_rate': analytics['knowledge_transfers'] / max(analytics['total_tasks_completed'], 1),\n",
        "            'collaboration_rate': analytics['collaboration_events'] / max(analytics['total_tasks_completed'], 1),\n",
        "            'sharing_effectiveness': analytics['knowledge_sharing_effectiveness'],\n",
        "            'knowledge_density': analytics['shared_knowledge_items'] / max(analytics['total_agents'], 1)\n",
        "        }\n",
        "\n",
        "        # System expertise landscape\n",
        "        total_expertise = 0\n",
        "        expertise_distribution = defaultdict(float)\n",
        "\n",
        "        for agent_info in learning_system.agents.values():\n",
        "            agent = agent_info['agent']\n",
        "            for domain, level in agent.expertise_areas.items():\n",
        "                expertise_distribution[domain] += level\n",
        "                total_expertise += level\n",
        "\n",
        "        return {\n",
        "            'system_overview': analytics,\n",
        "            'agent_rankings': agent_comparison,\n",
        "            'knowledge_sharing_health': knowledge_sharing_health,\n",
        "            'expertise_landscape': dict(expertise_distribution),\n",
        "            'total_system_expertise': total_expertise\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# COMPREHENSIVE TESTING AND DEMONSTRATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🧪 Testing Learning Visualization System...\")\n",
        "print()\n",
        "\n",
        "# Create and train an agent for detailed analysis\n",
        "print(\"🏃 Training agent for comprehensive visualization demo...\")\n",
        "\n",
        "demo_agent = AdaptiveAgent(\n",
        "    name=\"VizDemoBot\",\n",
        "    learning_objectives=[LearningObjective.ACCURACY, LearningObjective.EFFICIENCY, LearningObjective.QUALITY]\n",
        ")\n",
        "\n",
        "# Comprehensive training scenarios\n",
        "training_scenarios = [\n",
        "    {\n",
        "        'description': 'Handle escalated customer complaint',\n",
        "        'data': {'urgency': 'high', 'customer_type': 'premium', 'issue': 'billing_error'},\n",
        "        'context': {'domain': 'customer_service', 'task_type': 'complaint_handling'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Optimize database query performance',\n",
        "        'data': {'complexity': 'high', 'table_size': 'large', 'join_count': 5},\n",
        "        'context': {'domain': 'database_optimization', 'task_type': 'performance_tuning'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Design responsive user interface',\n",
        "        'data': {'platform': 'mobile', 'target': 'professionals', 'complexity': 'medium'},\n",
        "        'context': {'domain': 'ui_design', 'task_type': 'responsive_design'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Analyze quarterly financial data',\n",
        "        'data': {'dataset': 'revenue_data', 'timeframe': 'Q4', 'metrics': ['growth', 'churn']},\n",
        "        'context': {'domain': 'financial_analysis', 'task_type': 'quarterly_review'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Debug production system issue',\n",
        "        'data': {'system': 'microservices', 'error_type': 'timeout', 'impact': 'critical'},\n",
        "        'context': {'domain': 'system_debugging', 'task_type': 'production_issue'}\n",
        "    },\n",
        "    {\n",
        "        'description': 'Write technical documentation',\n",
        "        'data': {'api_type': 'REST', 'complexity': 'medium', 'audience': 'developers'},\n",
        "        'context': {'domain': 'technical_writing', 'task_type': 'api_documentation'}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Train the agent through multiple rounds\n",
        "print(f\"   Running {len(training_scenarios)} scenarios across 3 training rounds...\")\n",
        "\n",
        "for round_num in range(3):\n",
        "    print(f\"   Round {round_num + 1}...\")\n",
        "    for i, scenario in enumerate(training_scenarios):\n",
        "        result = demo_agent.execute_task(\n",
        "            scenario['description'],\n",
        "            scenario['data'],\n",
        "            scenario['context']\n",
        "        )\n",
        "\n",
        "        # Simulate feedback on some tasks\n",
        "        if round_num > 0 and i % 2 == 0:  # Feedback on every other task after round 1\n",
        "            feedback = {\n",
        "                'satisfactory': result['performance']['success'],\n",
        "                'metrics': {'expert_rating': random.uniform(0.6, 0.9)},\n",
        "                'lesson': f\"Round {round_num+1} feedback: {'Good approach' if result['performance']['success'] else 'Try different method'}\"\n",
        "            }\n",
        "            demo_agent.learn_from_feedback(result['task_id'], feedback)\n",
        "\n",
        "print(f\"   ✅ Training complete: {len(demo_agent.task_history)} total tasks\")\n",
        "print()\n",
        "\n",
        "# Create visualizer and generate comprehensive analysis\n",
        "visualizer = LearningVisualizer()\n",
        "\n",
        "print(\"📊 Generating comprehensive learning dashboard...\")\n",
        "dashboard = visualizer.create_learning_dashboard(demo_agent)\n",
        "\n",
        "print()\n",
        "print(\"📋 LEARNING DASHBOARD ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Agent overview\n",
        "overview = dashboard['agent_overview']\n",
        "print(f\"🤖 Agent: {overview['name']}\")\n",
        "print(f\"   Tasks Completed: {overview['tasks_completed']}\")\n",
        "print(f\"   Success Rate: {overview['current_success_rate']:.1%}\")\n",
        "print(f\"   Exploration Rate: {overview['exploration_rate']:.3f}\")\n",
        "\n",
        "# Performance trends\n",
        "trends = dashboard['performance_trends']\n",
        "if trends.get('overall_trend') != 'insufficient_data':\n",
        "    print(f\"\\n📈 Performance Trends:\")\n",
        "    print(f\"   Overall Trend: {trends['overall_trend'].title()}\")\n",
        "    print(f\"   Total Improvement: {trends.get('total_improvement', 0):+.3f}\")\n",
        "    print(f\"   Improvement Rate: {trends.get('improvement_rate', 0):.3f} per window\")\n",
        "\n",
        "    # Show trend visualization\n",
        "    windows = trends.get('windows', [])\n",
        "    if len(windows) >= 3:\n",
        "        print(f\"   Progress Visualization:\")\n",
        "        for i, window in enumerate(windows):\n",
        "            bar_length = int(window['avg_score'] * 20)\n",
        "            bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
        "            print(f\"     Window {i+1}: {bar} {window['avg_score']:.3f}\")\n",
        "\n",
        "# Learning progress\n",
        "progress = dashboard['learning_progress']\n",
        "print(f\"\\n🎓 Learning Progress:\")\n",
        "print(f\"   Patterns Discovered: {progress['patterns_discovered']}\")\n",
        "print(f\"   Learning Efficiency: {progress['learning_efficiency']:.3f}\")\n",
        "print(f\"   Knowledge Quality: {progress['knowledge_quality']:.1%}\")\n",
        "print(f\"   Memory Utilization: {progress['memory_utilization']:.1%}\")\n",
        "print(f\"   Total Experiences: {progress['total_experiences']}\")\n",
        "\n",
        "# Expertise development\n",
        "expertise = dashboard['expertise_development']\n",
        "if 'top_expertise_areas' in expertise:\n",
        "    print(f\"\\n🏆 Expertise Development:\")\n",
        "    print(f\"   Total Domains: {expertise['total_domains']}\")\n",
        "    print(f\"   Specialization Index: {expertise['specialization_index']:.3f}\")\n",
        "    print(f\"   Top Expertise Areas:\")\n",
        "\n",
        "    for i, (area, level) in enumerate(expertise['top_expertise_areas'][:5], 1):\n",
        "        expertise_bar = \"█\" * int(level * 20) + \"░\" * (20 - int(level * 20))\n",
        "        print(f\"     {i}. {area}: {level:.3f} {expertise_bar}\")\n",
        "\n",
        "# Adaptations\n",
        "adaptations = dashboard['adaptation_effectiveness']\n",
        "if 'total_adaptations' in adaptations:\n",
        "    print(f\"\\n🔄 Adaptation Analysis:\")\n",
        "    print(f\"   Total Adaptations: {adaptations['total_adaptations']}\")\n",
        "    print(f\"   Exploration Trend: {adaptations.get('exploration_rate_trend', 'N/A').title()}\")\n",
        "    print(f\"   Confidence Trend: {adaptations.get('confidence_threshold_trend', 'N/A').title()}\")\n",
        "\n",
        "# Recommendations\n",
        "recommendations = dashboard['recommendations']\n",
        "if recommendations:\n",
        "    print(f\"\\n💡 Learning Recommendations:\")\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"   {i}. {rec}\")\n",
        "\n",
        "# Generate and display comprehensive report\n",
        "print(f\"\\n📄 Generating comprehensive learning report...\")\n",
        "report = visualizer.generate_learning_report(demo_agent)\n",
        "\n",
        "print(f\"\\n📖 LEARNING REPORT PREVIEW:\")\n",
        "print(\"-\" * 50)\n",
        "# Show key sections of the report\n",
        "lines = report.split('\\n')\n",
        "current_section = \"\"\n",
        "for line in lines:\n",
        "    if line.startswith('📊') or line.startswith('📈') or line.startswith('🎓') or line.startswith('🏆'):\n",
        "        current_section = line\n",
        "        print(line)\n",
        "    elif line.startswith('   ') and current_section:\n",
        "        print(line)\n",
        "    elif line.startswith('='):\n",
        "        break\n",
        "\n",
        "# Test multi-agent system analysis\n",
        "print(f\"\\n🏫 Testing Multi-Agent System Analysis...\")\n",
        "\n",
        "# Create a multi-agent system for demonstration\n",
        "multi_system = MultiAgentLearningSystem(\"Demo Learning System\")\n",
        "\n",
        "# Create agents with different specializations\n",
        "specialist_agents = [\n",
        "    AdaptiveAgent(name=\"CustomerServiceExpert\", learning_objectives=[LearningObjective.QUALITY]),\n",
        "    AdaptiveAgent(name=\"TechnicalExpert\", learning_objectives=[LearningObjective.ACCURACY]),\n",
        "    AdaptiveAgent(name=\"EfficiencyExpert\", learning_objectives=[LearningObjective.EFFICIENCY])\n",
        "]\n",
        "\n",
        "# Add pre-existing expertise to make analysis more interesting\n",
        "specialist_agents[0].expertise_areas['customer_service'] = 0.8\n",
        "specialist_agents[0].expertise_areas['communication'] = 0.7\n",
        "specialist_agents[1].expertise_areas['database_optimization'] = 0.9\n",
        "specialist_agents[1].expertise_areas['system_debugging'] = 0.7\n",
        "specialist_agents[2].expertise_areas['process_optimization'] = 0.6\n",
        "specialist_agents[2].expertise_areas['efficiency_analysis'] = 0.8\n",
        "\n",
        "# Add agents to system\n",
        "for i, agent in enumerate(specialist_agents):\n",
        "    specialization = ['customer_service', 'technical_systems', 'process_optimization'][i]\n",
        "    multi_system.add_agent(agent, specialization)\n",
        "\n",
        "# Run a quick learning session\n",
        "quick_scenarios = training_scenarios[:3]  # Use first 3 scenarios\n",
        "session_result = multi_system.coordinate_learning_session(quick_scenarios)\n",
        "\n",
        "print(f\"   Session completed: {session_result['scenarios_completed']} scenarios\")\n",
        "print(f\"   Knowledge transfers: {session_result['knowledge_shared']}\")\n",
        "\n",
        "# Analyze the multi-agent system\n",
        "system_analysis = visualizer.analyze_multi_agent_system(multi_system)\n",
        "\n",
        "print(f\"\\n📊 MULTI-AGENT SYSTEM ANALYSIS:\")\n",
        "print(f\"   Total Agents: {system_analysis['system_overview']['total_agents']}\")\n",
        "print(f\"   Total Tasks: {system_analysis['system_overview']['total_tasks_completed']}\")\n",
        "print(f\"   Knowledge Transfers: {system_analysis['system_overview']['knowledge_transfers']}\")\n",
        "print(f\"   Total System Expertise: {system_analysis['total_system_expertise']:.2f}\")\n",
        "\n",
        "print(f\"\\n🏆 Agent Performance Rankings:\")\n",
        "for i, agent_data in enumerate(system_analysis['agent_rankings'], 1):\n",
        "    ranking_icon = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\"\n",
        "    print(f\"   {ranking_icon} {agent_data['name']}\")\n",
        "    print(f\"      Tasks: {agent_data['tasks_completed']}, Success: {agent_data['success_rate']:.1%}\")\n",
        "    print(f\"      Contributions: {agent_data['contributions']}, Expertise Breadth: {agent_data['expertise_breadth']}\")\n",
        "\n",
        "print(f\"\\n🤝 Knowledge Sharing Health:\")\n",
        "sharing_health = system_analysis['knowledge_sharing_health']\n",
        "print(f\"   Transfer Rate: {sharing_health['transfer_rate']:.3f} transfers/task\")\n",
        "print(f\"   Collaboration Rate: {sharing_health['collaboration_rate']:.3f} collaborations/task\")\n",
        "print(f\"   Sharing Effectiveness: {sharing_health['sharing_effectiveness']:.3f}\")\n",
        "print(f\"   Knowledge Density: {sharing_health['knowledge_density']:.3f} items/agent\")\n",
        "\n",
        "print(f\"\\n🗺️ System Expertise Landscape:\")\n",
        "expertise_landscape = system_analysis['expertise_landscape']\n",
        "sorted_expertise = sorted(expertise_landscape.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for domain, total_expertise in sorted_expertise[:6]:\n",
        "    expertise_percentage = (total_expertise / system_analysis['total_system_expertise']) * 100\n",
        "    bar_length = int(expertise_percentage / 5)  # Scale bar to fit\n",
        "    expertise_bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
        "    print(f\"   {domain:<25} {total_expertise:>5.2f} {expertise_bar} {expertise_percentage:>5.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"🎉 Learning Visualization System Complete!\")\n",
        "print()\n",
        "print(\"✅ TUTORIAL 12 PART 6 COMPLETE!\")\n",
        "print(\"=\" * 45)\n",
        "print()\n",
        "print(\"📊 What We Built in Part 6:\")\n",
        "print(\"   • LearningVisualizer - Comprehensive analysis engine\")\n",
        "print(\"   • Performance trend analysis with visual progress bars\")\n",
        "print(\"   • Learning progress tracking with efficiency metrics\")\n",
        "print(\"   • Expertise development analysis with specialization indices\")\n",
        "print(\"   • Behavioral adaptation effectiveness analysis\")\n",
        "print(\"   • Intelligent learning recommendations generation\")\n",
        "print(\"   • Multi-agent system analysis with rankings\")\n",
        "print(\"   • Knowledge sharing health assessment\")\n",
        "print(\"   • Comprehensive human-readable report generation\")\n",
        "print(\"   • System-wide expertise landscape visualization\")\n",
        "print()\n",
        "print(\"🌟 COMPLETE TUTORIAL 12 SUMMARY:\")\n",
        "print(\"   ✅ Part 1: Foundation learning framework\")\n",
        "print(\"   ✅ Part 2: Sophisticated experience memory system\")\n",
        "print(\"   ✅ Part 3: Multi-algorithm learning engine\")\n",
        "print(\"   ✅ Part 4: Adaptive agents with behavioral evolution\")\n",
        "print(\"   ✅ Part 5: Multi-agent collaborative learning\")\n",
        "print(\"   ✅ Part 6: Comprehensive visualization and analysis\")\n",
        "print()\n",
        "print(\"🚀 Your learning agents can now:\")\n",
        "print(\"   • Learn from multiple types of experiences\")\n",
        "print(\"   • Adapt their behavior based on performance\")\n",
        "print(\"   • Share knowledge and learn from each other\")\n",
        "print(\"   • Provide detailed insights into their learning journey\")\n",
        "print(\"   • Generate comprehensive analysis and recommendations\")\n",
        "print()\n",
        "print(\"🎯 Ready for Tutorial 13: Error Handling and Recovery!\")\n",
        "print(\"   Next we'll make these learning systems resilient and robust!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UDO_kGdEAOX",
        "outputId": "ecfbf679-638b-463f-9029-d2a320fba501"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12 Part 6: Learning Visualization and Analysis\n",
            "=======================================================\n",
            "Building comprehensive analysis and visualization tools...\n",
            "\n",
            "🧪 Testing Learning Visualization System...\n",
            "\n",
            "🏃 Training agent for comprehensive visualization demo...\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 3 objectives\n",
            "🤖 Created adaptive agent: VizDemoBot\n",
            "   Learning objectives: ['accuracy', 'efficiency', 'quality']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "   Running 6 scenarios across 3 training rounds...\n",
            "   Round 1...\n",
            "🎯 VizDemoBot executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.728)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "     📈 customer_service expertise: 0.00 → 0.07\n",
            "🎯 VizDemoBot executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.587)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database_optimization expertise: 0.00 → 0.06\n",
            "🎯 VizDemoBot executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.569)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.00 → 0.06\n",
            "🎯 VizDemoBot executing: Analyze quarterly financial data...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.667)\n",
            "   📝 Stored experience: Analyze quarterly financial data...\n",
            "     📈 financial_analysis expertise: 0.00 → 0.07\n",
            "🎯 VizDemoBot executing: Debug production system issue...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.698)\n",
            "   📝 Stored experience: Debug production system issue...\n",
            "     📈 system_debugging expertise: 0.00 → 0.07\n",
            "🎯 VizDemoBot executing: Write technical documentation...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.688)\n",
            "   📝 Stored experience: Write technical documentation...\n",
            "     📈 technical_writing expertise: 0.00 → 0.07\n",
            "   Round 2...\n",
            "🎯 VizDemoBot executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.736)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "     📈 customer_service expertise: 0.07 → 0.14\n",
            "   📝 Processing feedback for task: Handle escalated customer complaint...\n",
            "   📝 Stored experience: Feedback on: Handle escalated customer complaint...\n",
            "   ✅ Learned from positive feedback\n",
            "🎯 VizDemoBot executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.648)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database_optimization expertise: 0.06 → 0.12\n",
            "🎯 VizDemoBot executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.686)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.06 → 0.12\n",
            "   📝 Processing feedback for task: Design responsive user interface...\n",
            "   📝 Stored experience: Feedback on: Design responsive user interface...\n",
            "   ✅ Learned from positive feedback\n",
            "🎯 VizDemoBot executing: Analyze quarterly financial data...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.587)\n",
            "   📝 Stored experience: Analyze quarterly financial data...\n",
            "     📈 financial_analysis expertise: 0.07 → 0.12\n",
            "🎯 VizDemoBot executing: Debug production system issue...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.585)\n",
            "   📝 Stored experience: Debug production system issue...\n",
            "     📈 system_debugging expertise: 0.07 → 0.12\n",
            "     🔄 Triggering adaptation check (task #10)\n",
            "       📊 Recent performance: 60.0% success, 0.659 avg score\n",
            "       🔧 Adaptation complete:\n",
            "         Exploration: 0.100 → 0.100 (+0.000)\n",
            "         Confidence: 0.600 → 0.600 (+0.000)\n",
            "   📝 Processing feedback for task: Debug production system issue...\n",
            "   📝 Stored experience: Feedback on: Debug production system issue...\n",
            "   ✅ Learned from corrective feedback\n",
            "🎯 VizDemoBot executing: Write technical documentation...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.690)\n",
            "   📝 Stored experience: Write technical documentation...\n",
            "     📈 technical_writing expertise: 0.07 → 0.13\n",
            "   Round 3...\n",
            "🎯 VizDemoBot executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.652)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "     📈 customer_service expertise: 0.14 → 0.19\n",
            "   📝 Processing feedback for task: Handle escalated customer complaint...\n",
            "   📝 Stored experience: Feedback on: Handle escalated customer complaint...\n",
            "   ✅ Learned from positive feedback\n",
            "🎯 VizDemoBot executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.598)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "🎯 VizDemoBot executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.626)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.12 → 0.17\n",
            "   📝 Processing feedback for task: Design responsive user interface...\n",
            "   📝 Stored experience: Feedback on: Design responsive user interface...\n",
            "   🔍 Discovered 1 new patterns\n",
            "   ✅ Learned from corrective feedback\n",
            "🎯 VizDemoBot executing: Analyze quarterly financial data...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.738)\n",
            "   📝 Stored experience: Analyze quarterly financial data...\n",
            "     📈 financial_analysis expertise: 0.12 → 0.18\n",
            "🎯 VizDemoBot executing: Debug production system issue...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.636)\n",
            "   📝 Stored experience: Debug production system issue...\n",
            "     📈 system_debugging expertise: 0.12 → 0.17\n",
            "   📝 Processing feedback for task: Debug production system issue...\n",
            "   📝 Stored experience: Feedback on: Debug production system issue...\n",
            "   ✅ Learned from corrective feedback\n",
            "🎯 VizDemoBot executing: Write technical documentation...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.601)\n",
            "   📝 Stored experience: Write technical documentation...\n",
            "   ✅ Training complete: 18 total tasks\n",
            "\n",
            "📊 Learning visualizer initialized\n",
            "📊 Generating comprehensive learning dashboard...\n",
            "\n",
            "📋 LEARNING DASHBOARD ANALYSIS\n",
            "========================================\n",
            "🤖 Agent: VizDemoBot\n",
            "   Tasks Completed: 18\n",
            "   Success Rate: 50.0%\n",
            "   Exploration Rate: 0.100\n",
            "\n",
            "📈 Performance Trends:\n",
            "   Overall Trend: Stable\n",
            "   Total Improvement: +0.030\n",
            "   Improvement Rate: 0.005 per window\n",
            "   Progress Visualization:\n",
            "     Window 1: ████████████░░░░░░░░ 0.628\n",
            "     Window 2: █████████████░░░░░░░ 0.684\n",
            "     Window 3: █████████████░░░░░░░ 0.690\n",
            "     Window 4: ████████████░░░░░░░░ 0.621\n",
            "     Window 5: ████████████░░░░░░░░ 0.625\n",
            "     Window 6: █████████████░░░░░░░ 0.658\n",
            "\n",
            "🎓 Learning Progress:\n",
            "   Patterns Discovered: 1\n",
            "   Learning Efficiency: 0.000\n",
            "   Knowledge Quality: 50.0%\n",
            "   Memory Utilization: 2.4%\n",
            "   Total Experiences: 24\n",
            "\n",
            "🏆 Expertise Development:\n",
            "   Total Domains: 12\n",
            "   Specialization Index: 0.014\n",
            "   Top Expertise Areas:\n",
            "     1. customer_service: 0.190 ███░░░░░░░░░░░░░░░░░\n",
            "     2. complaint_handling: 0.190 ███░░░░░░░░░░░░░░░░░\n",
            "     3. financial_analysis: 0.181 ███░░░░░░░░░░░░░░░░░\n",
            "     4. quarterly_review: 0.181 ███░░░░░░░░░░░░░░░░░\n",
            "     5. technical_writing: 0.178 ███░░░░░░░░░░░░░░░░░\n",
            "\n",
            "💡 Learning Recommendations:\n",
            "   1. Consider increasing exploration rate to discover better strategies\n",
            "   2. Focus on specific domains to develop deeper expertise\n",
            "   3. Engage in more varied tasks to discover useful patterns\n",
            "\n",
            "📄 Generating comprehensive learning report...\n",
            "\n",
            "📖 LEARNING REPORT PREVIEW:\n",
            "--------------------------------------------------\n",
            "\n",
            "🏫 Testing Multi-Agent System Analysis...\n",
            "🏫 Multi-agent learning system initialized: Demo Learning System\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 1 objectives\n",
            "🤖 Created adaptive agent: CustomerServiceExpert\n",
            "   Learning objectives: ['quality']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 1 objectives\n",
            "🤖 Created adaptive agent: TechnicalExpert\n",
            "   Learning objectives: ['accuracy']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "🧠 Experience memory initialized (capacity: 1000)\n",
            "🎓 Learning engine initialized with 1 objectives\n",
            "🤖 Created adaptive agent: EfficiencyExpert\n",
            "   Learning objectives: ['efficiency']\n",
            "   Initial exploration rate: 0.1\n",
            "   Initial confidence threshold: 0.6\n",
            "   👥 Added agent CustomerServiceExpert (specialization: customer_service)\n",
            "   👥 Added agent TechnicalExpert (specialization: technical_systems)\n",
            "   👥 Added agent EfficiencyExpert (specialization: process_optimization)\n",
            "🎓 Starting coordinated learning session with 3 scenarios...\n",
            "   📋 Scenario 1: Handle escalated customer complaint\n",
            "🎯 CustomerServiceExpert executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🎓 Using domain expertise: expert_customer_service_approach (expertise: 0.80)\n",
            "   🎲 Chose action: expert_customer_service_approach\n",
            "   ✅ Result: True (score: 0.666)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "🎯 TechnicalExpert executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🔍 Exploring with action: creative_solution\n",
            "   🎲 Chose action: creative_solution\n",
            "   ✅ Result: True (score: 0.838)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "     📈 customer_service expertise: 0.00 → 0.08\n",
            "🎯 EfficiencyExpert executing: Handle escalated customer complaint...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.639)\n",
            "   📝 Stored experience: Handle escalated customer complaint...\n",
            "     📈 customer_service expertise: 0.00 → 0.06\n",
            "   👁️ Observing TechnicalExpert on task: Handle escalated customer complaint...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   👁️ Observing TechnicalExpert on task: Handle escalated customer complaint...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   📋 Scenario 2: Optimize database query performance\n",
            "🎯 CustomerServiceExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.712)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database_optimization expertise: 0.00 → 0.07\n",
            "🎯 TechnicalExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🎓 Using domain expertise: expert_database_optimization_approach (expertise: 0.90)\n",
            "   🎲 Chose action: expert_database_optimization_approach\n",
            "   ✅ Result: True (score: 0.813)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "🎯 EfficiencyExpert executing: Optimize database query performance...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ❌ Result: False (score: 0.622)\n",
            "   📝 Stored experience: Optimize database query performance...\n",
            "     📈 database_optimization expertise: 0.00 → 0.06\n",
            "   👁️ Observing TechnicalExpert on task: Optimize database query performance...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   👁️ Observing TechnicalExpert on task: Optimize database query performance...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   📋 Scenario 3: Design responsive user interface\n",
            "🎯 CustomerServiceExpert executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     📝 Using standard approach (no strong recommendations or expertise)\n",
            "   🎲 Chose action: standard_approach\n",
            "   ✅ Result: True (score: 0.678)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.00 → 0.07\n",
            "🎯 TechnicalExpert executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🔍 Exploring with action: innovative_technique\n",
            "   🎲 Chose action: innovative_technique\n",
            "   ✅ Result: True (score: 0.815)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.00 → 0.08\n",
            "🎯 EfficiencyExpert executing: Design responsive user interface...\n",
            "   💡 Found 0 recommendations from past experience\n",
            "     🔍 Exploring with action: innovative_technique\n",
            "   🎲 Chose action: innovative_technique\n",
            "   ✅ Result: True (score: 0.766)\n",
            "   📝 Stored experience: Design responsive user interface...\n",
            "     📈 ui_design expertise: 0.00 → 0.08\n",
            "   👁️ Observing TechnicalExpert on task: Design responsive user interface...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   👁️ Observing TechnicalExpert on task: Design responsive user interface...\n",
            "   ℹ️ No clear approach to learn from TechnicalExpert\n",
            "   ✅ Learning session complete: 3 scenarios, 0 knowledge transfers\n",
            "   Session completed: 3 scenarios\n",
            "   Knowledge transfers: 0\n",
            "\n",
            "📊 MULTI-AGENT SYSTEM ANALYSIS:\n",
            "   Total Agents: 3\n",
            "   Total Tasks: 9\n",
            "   Knowledge Transfers: 0\n",
            "   Total System Expertise: 5.64\n",
            "\n",
            "🏆 Agent Performance Rankings:\n",
            "   🥇 CustomerServiceExpert\n",
            "      Tasks: 3, Success: 100.0%\n",
            "      Contributions: 0, Expertise Breadth: 3\n",
            "   🥈 TechnicalExpert\n",
            "      Tasks: 3, Success: 100.0%\n",
            "      Contributions: 0, Expertise Breadth: 3\n",
            "   🥉 EfficiencyExpert\n",
            "      Tasks: 3, Success: 33.3%\n",
            "      Contributions: 0, Expertise Breadth: 3\n",
            "\n",
            "🤝 Knowledge Sharing Health:\n",
            "   Transfer Rate: 0.000 transfers/task\n",
            "   Collaboration Rate: 0.333 collaborations/task\n",
            "   Sharing Effectiveness: 0.000\n",
            "   Knowledge Density: 0.000 items/agent\n",
            "\n",
            "🗺️ System Expertise Landscape:\n",
            "   database_optimization      1.02 ███░░░░░░░░░░░░░░░░░  18.2%\n",
            "   customer_service           0.93 ███░░░░░░░░░░░░░░░░░  16.6%\n",
            "   efficiency_analysis        0.80 ██░░░░░░░░░░░░░░░░░░  14.2%\n",
            "   communication              0.70 ██░░░░░░░░░░░░░░░░░░  12.4%\n",
            "   system_debugging           0.70 ██░░░░░░░░░░░░░░░░░░  12.4%\n",
            "   process_optimization       0.60 ██░░░░░░░░░░░░░░░░░░  10.6%\n",
            "\n",
            "🎉 Learning Visualization System Complete!\n",
            "\n",
            "✅ TUTORIAL 12 PART 6 COMPLETE!\n",
            "=============================================\n",
            "\n",
            "📊 What We Built in Part 6:\n",
            "   • LearningVisualizer - Comprehensive analysis engine\n",
            "   • Performance trend analysis with visual progress bars\n",
            "   • Learning progress tracking with efficiency metrics\n",
            "   • Expertise development analysis with specialization indices\n",
            "   • Behavioral adaptation effectiveness analysis\n",
            "   • Intelligent learning recommendations generation\n",
            "   • Multi-agent system analysis with rankings\n",
            "   • Knowledge sharing health assessment\n",
            "   • Comprehensive human-readable report generation\n",
            "   • System-wide expertise landscape visualization\n",
            "\n",
            "🌟 COMPLETE TUTORIAL 12 SUMMARY:\n",
            "   ✅ Part 1: Foundation learning framework\n",
            "   ✅ Part 2: Sophisticated experience memory system\n",
            "   ✅ Part 3: Multi-algorithm learning engine\n",
            "   ✅ Part 4: Adaptive agents with behavioral evolution\n",
            "   ✅ Part 5: Multi-agent collaborative learning\n",
            "   ✅ Part 6: Comprehensive visualization and analysis\n",
            "\n",
            "🚀 Your learning agents can now:\n",
            "   • Learn from multiple types of experiences\n",
            "   • Adapt their behavior based on performance\n",
            "   • Share knowledge and learn from each other\n",
            "   • Provide detailed insights into their learning journey\n",
            "   • Generate comprehensive analysis and recommendations\n",
            "\n",
            "🎯 Ready for Tutorial 13: Error Handling and Recovery!\n",
            "   Next we'll make these learning systems resilient and robust!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What We Learned & Common Errors and Solutions\n",
        "\n",
        "print(\"Tutorial 12: Learning from Experience - Complete Summary\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Comprehensive overview of adaptive learning systems\")\n",
        "\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# WHAT WE LEARNED - COMPREHENSIVE OVERVIEW\n",
        "# =============================================================================\n",
        "\n",
        "print(\"📚 WHAT WE LEARNED:\")\n",
        "\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🏗️ 1. FOUNDATION LEARNING FRAMEWORK (Part 1)\")\n",
        "\n",
        "print(\"   Core Concepts Mastered:\")\n",
        "\n",
        "print(\"   • LearningExperience - Individual learning moments with context\")\n",
        "\n",
        "print(\"   • LearningPattern - Extracted knowledge that generalizes\")\n",
        "\n",
        "print(\"   • 5 Learning Types: Supervised, Unsupervised, Reinforcement, Imitation, Transfer\")\n",
        "\n",
        "print(\"   • 5 Experience Types: Success, Failure, Feedback, Observation, Exploration\")\n",
        "\n",
        "print(\"   • 5 Learning Objectives: Accuracy, Efficiency, Quality, Adaptability, Robustness\")\n",
        "\n",
        "print(\"   • Relevance calculation and age tracking for experiences\")\n",
        "\n",
        "print(\"   • Pattern confidence and success rate modeling\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"💾 2. SOPHISTICATED EXPERIENCE MEMORY (Part 2)\")\n",
        "\n",
        "print(\"   Memory Architecture Mastered:\")\n",
        "\n",
        "print(\"   • ExperienceMemory with intelligent indexing systems\")\n",
        "\n",
        "print(\"   • Type-based, context-based, and temporal indexing\")\n",
        "\n",
        "print(\"   • Similarity search with relevance scoring\")\n",
        "\n",
        "print(\"   • Automatic pattern discovery from successful experiences\")\n",
        "\n",
        "print(\"   • Memory capacity management with intelligent eviction\")\n",
        "\n",
        "print(\"   • Statistical analysis of memory utilization\")\n",
        "\n",
        "print(\"   • Context clustering for pattern extraction\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🎓 3. MULTI-ALGORITHM LEARNING ENGINE (Part 3)\")\n",
        "\n",
        "print(\"   Learning Processing Mastered:\")\n",
        "\n",
        "print(\"   • 5 distinct learning algorithms with different strengths:\")\n",
        "\n",
        "print(\"     - Supervised: Input-output mapping from labeled examples\")\n",
        "\n",
        "print(\"     - Unsupervised: Pattern discovery through clustering\")\n",
        "\n",
        "print(\"     - Reinforcement: Q-learning with reward optimization\")\n",
        "\n",
        "print(\"     - Imitation: Behavior copying from observation\")\n",
        "\n",
        "print(\"     - Transfer: Knowledge adaptation across domains\")\n",
        "\n",
        "print(\"   • Performance baseline tracking and trend analysis\")\n",
        "\n",
        "print(\"   • Learning recommendations based on context relevance\")\n",
        "\n",
        "print(\"   • Feature extraction from diverse input types\")\n",
        "\n",
        "print(\"   • Automatic pattern discovery and consolidation\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🤖 4. ADAPTIVE AGENTS WITH BEHAVIORAL EVOLUTION (Part 4)\")\n",
        "\n",
        "print(\"   Agent Intelligence Mastered:\")\n",
        "\n",
        "print(\"   • Dynamic action selection (exploration vs exploitation)\")\n",
        "\n",
        "print(\"   • Multi-dimensional performance evaluation:\")\n",
        "\n",
        "print(\"     - Accuracy, efficiency, quality, success metrics\")\n",
        "\n",
        "print(\"   • Domain expertise tracking and development\")\n",
        "\n",
        "print(\"   • Behavioral adaptation based on performance trends:\")\n",
        "\n",
        "print(\"     - Dynamic exploration rate adjustment\")\n",
        "\n",
        "print(\"     - Confidence threshold optimization\")\n",
        "\n",
        "print(\"   • External feedback integration for supervised learning\")\n",
        "\n",
        "print(\"   • Knowledge transfer between related domains\")\n",
        "\n",
        "print(\"   • Observation-based learning from other agents\")\n",
        "\n",
        "print(\"   • Comprehensive status tracking and self-awareness\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🏫 5. MULTI-AGENT COLLABORATIVE LEARNING (Part 5)\")\n",
        "\n",
        "print(\"   Collective Intelligence Mastered:\")\n",
        "\n",
        "print(\"   • Coordinated learning sessions across agent teams\")\n",
        "\n",
        "print(\"   • Cross-agent observation and imitation learning\")\n",
        "\n",
        "print(\"   • Knowledge consolidation and sharing mechanisms\")\n",
        "\n",
        "print(\"   • Performance improvement tracking in group settings\")\n",
        "\n",
        "print(\"   • Direct knowledge transfer between agents\")\n",
        "\n",
        "print(\"   • Collaboration history and contribution tracking\")\n",
        "\n",
        "print(\"   • System-wide analytics and agent specialization\")\n",
        "\n",
        "print(\"   • Best performer identification and learning propagation\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"📊 6. COMPREHENSIVE VISUALIZATION AND ANALYSIS (Part 6)\")\n",
        "\n",
        "print(\"   Analysis and Insight Mastered:\")\n",
        "\n",
        "print(\"   • Performance trend analysis with time windows\")\n",
        "\n",
        "print(\"   • Learning progress tracking and efficiency measurement\")\n",
        "\n",
        "print(\"   • Expertise development and specialization analysis\")\n",
        "\n",
        "print(\"   • Behavioral adaptation effectiveness evaluation\")\n",
        "\n",
        "print(\"   • Intelligent learning recommendations generation\")\n",
        "\n",
        "print(\"   • Multi-agent system analysis and rankings\")\n",
        "\n",
        "print(\"   • Knowledge sharing health assessment\")\n",
        "\n",
        "print(\"   • Human-readable comprehensive report generation\")\n",
        "\n",
        "print(\"   • Comparative analysis across different learning styles\")\n",
        "\n",
        "print(\"   • System-wide expertise landscape visualization\")\n",
        "\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# KEY ARCHITECTURAL INSIGHTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🏛️ KEY ARCHITECTURAL INSIGHTS:\")\n",
        "\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"🔄 Learning Lifecycle Understanding:\")\n",
        "\n",
        "print(\"   • Experience → Pattern → Knowledge → Action → Performance → Adaptation\")\n",
        "\n",
        "print(\"   • Continuous feedback loops between all components\")\n",
        "\n",
        "print(\"   • Memory consolidation from short-term to long-term patterns\")\n",
        "\n",
        "print(\"   • Multi-modal learning integration for robust knowledge\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"⚖️ Exploration vs Exploitation Balance:\")\n",
        "\n",
        "print(\"   • Dynamic exploration rate based on recent performance\")\n",
        "\n",
        "print(\"   • Higher exploration when performance is poor\")\n",
        "\n",
        "print(\"   • Lower exploration when performance is consistently good\")\n",
        "\n",
        "print(\"   • Context-dependent confidence thresholds\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🎯 Expertise Development Patterns:\")\n",
        "\n",
        "print(\"   • Domain-specific knowledge accumulation\")\n",
        "print(\"   • Specialization vs generalization trade-offs\")\n",
        "print(\"   • Transfer learning effectiveness between related domains\")\n",
        "print(\"   • Expertise-based action selection improvements\")\n",
        "print()\n",
        "\n",
        "print(\"🤝 Collaborative Learning Benefits:\")\n",
        "print(\"   • Faster learning through observation of successful agents\")\n",
        "print(\"   • Knowledge sharing reduces individual learning time\")\n",
        "print(\"   • Collective intelligence emerges from agent interactions\")\n",
        "print(\"   • Specialization allows for division of cognitive labor\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# PRODUCTION IMPLEMENTATION INSIGHTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🏭 PRODUCTION IMPLEMENTATION INSIGHTS:\")\n",
        "print(\"=\" * 40)\n",
        "print()\n",
        "\n",
        "print(\"📈 Scalability Considerations:\")\n",
        "print(\"   • Memory systems need capacity limits and cleanup strategies\")\n",
        "print(\"   • Pattern discovery should be triggered periodically, not continuously\")\n",
        "print(\"   • Learning recommendations should be cached for performance\")\n",
        "print(\"   • Agent coordination requires efficient communication protocols\")\n",
        "print()\n",
        "\n",
        "print(\"🔧 Performance Optimization:\")\n",
        "print(\"   • Index-based retrieval for large experience databases\")\n",
        "print(\"   • Batch processing for pattern discovery\")\n",
        "print(\"   • Lazy evaluation of learning recommendations\")\n",
        "print(\"   • Efficient serialization for agent state persistence\")\n",
        "print()\n",
        "\n",
        "print(\"🛡️ Robustness Requirements:\")\n",
        "print(\"   • Graceful degradation when learning components fail\")\n",
        "print(\"   • Memory overflow protection with intelligent eviction\")\n",
        "print(\"   • Confidence-based decision making to avoid poor choices\")\n",
        "print(\"   • Multiple learning pathways for redundancy\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# COMMON ERRORS AND SOLUTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"⚠️  COMMON ERRORS AND SOLUTIONS:\")\n",
        "print(\"=\" * 40)\n",
        "print()\n",
        "\n",
        "print(\"1. 🐛 MEMORY LEAKS AND UNBOUNDED GROWTH\")\n",
        "print(\"   Problem: Learning systems accumulating unlimited experiences\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Continuously increasing memory usage\")\n",
        "print(\"     • Slower performance over time\")\n",
        "print(\"     • Eventually running out of memory\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • No capacity limits on experience storage\")\n",
        "print(\"     • Missing cleanup of old/irrelevant experiences\")\n",
        "print(\"     • Retaining all patterns regardless of usefulness\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Implement memory capacity limits with intelligent eviction\")\n",
        "print(\"     ✅ Use age-based and relevance-based cleanup strategies\")\n",
        "print(\"     ✅ Periodic pruning of low-confidence patterns\")\n",
        "print(\"     ✅ Background maintenance threads for cleanup\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Capacity-limited memory\")\n",
        "print(\"     if len(self.experiences) > self.capacity:\")\n",
        "print(\"         self._evict_old_experiences()\")\n",
        "print()\n",
        "\n",
        "print(\"2. 🐛 OVERFITTING TO RECENT EXPERIENCES\")\n",
        "print(\"   Problem: Agent relies too heavily on latest experiences\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Poor performance when conditions change\")\n",
        "print(\"     • Ignoring valuable historical patterns\")\n",
        "print(\"     • Unstable behavior with high variance\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Recent experiences weighted too heavily\")\n",
        "print(\"     • No temporal balance in pattern discovery\")\n",
        "print(\"     • Missing confidence decay for old patterns\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Implement balanced temporal weighting\")\n",
        "print(\"     ✅ Use confidence decay for aging patterns\")\n",
        "print(\"     ✅ Ensemble multiple patterns for decisions\")\n",
        "print(\"     ✅ Maintain historical performance baselines\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Balanced temporal weighting\")\n",
        "print(\"     weight = base_weight * math.exp(-age * decay_rate)\")\n",
        "print()\n",
        "\n",
        "print(\"3. 🐛 EXPLORATION VS EXPLOITATION IMBALANCE\")\n",
        "print(\"   Problem: Too much exploration (inefficient) or too little (stagnation)\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Consistently poor performance (over-exploration)\")\n",
        "print(\"     • Performance plateau (under-exploration)\")\n",
        "print(\"     • No adaptation to changing conditions\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Fixed exploration rates regardless of performance\")\n",
        "print(\"     • No adaptation mechanism for exploration\")\n",
        "print(\"     • Missing context-dependent exploration strategies\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Dynamic exploration rate based on recent performance\")\n",
        "print(\"     ✅ Higher exploration when performance is poor\")\n",
        "print(\"     ✅ Context-specific exploration strategies\")\n",
        "print(\"     ✅ Gradual exploration decay as expertise grows\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Adaptive exploration\")\n",
        "print(\"     if recent_success_rate < 0.4:\")\n",
        "print(\"         self.exploration_rate = min(0.3, self.exploration_rate * 1.1)\")\n",
        "print()\n",
        "\n",
        "print(\"4. 🐛 POOR KNOWLEDGE TRANSFER\")\n",
        "print(\"   Problem: Learned knowledge doesn't apply to new domains\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • No performance benefit from previous learning\")\n",
        "print(\"     • Starting from scratch in related domains\")\n",
        "print(\"     • Isolated expertise with no generalization\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Too specific pattern extraction\")\n",
        "print(\"     • No abstraction mechanisms\")\n",
        "print(\"     • Missing domain relationship modeling\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Abstract pattern extraction at multiple levels\")\n",
        "print(\"     ✅ Domain similarity assessment for transfer\")\n",
        "print(\"     ✅ Gradual transfer with validation\")\n",
        "print(\"     ✅ Transfer learning confidence tracking\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Validated transfer learning\")\n",
        "print(\"     transfer_factor = domain_similarity * source_confidence\")\n",
        "print(\"     target_expertise = source_expertise * transfer_factor\")\n",
        "print()\n",
        "\n",
        "print(\"5. 🐛 LEARNING PLATEAU AND STAGNATION\")\n",
        "print(\"   Problem: Agent stops improving after initial gains\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Flat performance curves after initial learning\")\n",
        "print(\"     • No new pattern discovery\")\n",
        "print(\"     • Repetitive behavior patterns\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Insufficient exploration in exploitation phase\")\n",
        "print(\"     • No curriculum learning progression\")\n",
        "print(\"     • Missing novelty detection mechanisms\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Curriculum learning with progressive difficulty\")\n",
        "print(\"     ✅ Novelty-based exploration incentives\")\n",
        "print(\"     ✅ Regular parameter adaptation\")\n",
        "print(\"     ✅ Cross-domain learning exposure\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Progressive difficulty curriculum\")\n",
        "print(\"     difficulty = base_difficulty + (task_count / 100) * 0.1\")\n",
        "print()\n",
        "\n",
        "print(\"6. 🐛 INCONSISTENT FEEDBACK INTEGRATION\")\n",
        "print(\"   Problem: External feedback not properly incorporated\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • No improvement despite feedback\")\n",
        "print(\"     • Conflicting learned patterns\")\n",
        "print(\"     • Ignoring expert corrections\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Feedback treated same as other experiences\")\n",
        "print(\"     • No feedback quality assessment\")\n",
        "print(\"     • Missing feedback-specific learning paths\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Separate feedback processing pipeline\")\n",
        "print(\"     ✅ Feedback quality and source assessment\")\n",
        "print(\"     ✅ Higher weight for validated feedback\")\n",
        "print(\"     ✅ Feedback contradiction detection\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Weighted feedback processing\")\n",
        "print(\"     if experience.experience_type == ExperienceType.FEEDBACK:\")\n",
        "print(\"         weight *= feedback_importance_multiplier\")\n",
        "print()\n",
        "\n",
        "print(\"7. 🐛 COORDINATION CONFLICTS IN MULTI-AGENT SYSTEMS\")\n",
        "print(\"   Problem: Agents interfering with each other's learning\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Degraded performance in group settings\")\n",
        "print(\"     • Conflicting recommendations\")\n",
        "print(\"     • Knowledge sharing failures\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • No coordination protocols\")\n",
        "print(\"     • Conflicting learning objectives\")\n",
        "print(\"     • Resource competition between agents\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Clear coordination protocols and roles\")\n",
        "print(\"     ✅ Conflict resolution mechanisms\")\n",
        "print(\"     ✅ Shared knowledge validation\")\n",
        "print(\"     ✅ Performance-based coordination adjustment\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Conflict-aware coordination\")\n",
        "print(\"     if recommendation_confidence > threshold:\")\n",
        "print(\"         shared_knowledge[pattern_id] = pattern\")\n",
        "print()\n",
        "\n",
        "print(\"8. 🐛 MEMORY RETRIEVAL PERFORMANCE DEGRADATION\")\n",
        "print(\"   Problem: Learning system becomes slow with accumulated data\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Increasing response times over time\")\n",
        "print(\"     • High CPU usage during retrieval\")\n",
        "print(\"     • Memory search timeouts\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • Linear search through large memory stores\")\n",
        "print(\"     • No indexing for fast retrieval\")\n",
        "print(\"     • Inefficient similarity calculations\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Multi-level indexing systems\")\n",
        "print(\"     ✅ Approximate similarity search for speed\")\n",
        "print(\"     ✅ Caching of frequent retrieval results\")\n",
        "print(\"     ✅ Background index optimization\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Indexed retrieval\")\n",
        "print(\"     candidates = self.context_index[context_key]\")\n",
        "print(\"     # Instead of searching all experiences\")\n",
        "print()\n",
        "\n",
        "print(\"9. 🐛 PATTERN DISCOVERY EXPLOSION\")\n",
        "print(\"   Problem: Too many weak patterns cluttering the system\")\n",
        "print(\"   Symptoms:\")\n",
        "print(\"     • Thousands of low-confidence patterns\")\n",
        "print(\"     • Slow pattern matching\")\n",
        "print(\"     • Difficulty finding relevant patterns\")\n",
        "print(\"   Root Causes:\")\n",
        "print(\"     • No minimum confidence thresholds\")\n",
        "print(\"     • Pattern creation from insufficient data\")\n",
        "print(\"     • No pattern pruning mechanisms\")\n",
        "print(\"   Solutions:\")\n",
        "print(\"     ✅ Minimum observation thresholds for pattern creation\")\n",
        "print(\"     ✅ Confidence-based pattern pruning\")\n",
        "print(\"     ✅ Pattern consolidation and merging\")\n",
        "print(\"     ✅ Periodic pattern quality assessment\")\n",
        "print(\"   Code Example:\")\n",
        "print(\"     # Good: Quality-gated pattern creation\")\n",
        "print(\"     if len(group_experiences) >= min_observations:\")\n",
        "print(\"         if pattern_confidence > min_confidence:\")\n",
        "print(\"             create_pattern(group_experiences)\")\n",
        "print()\n",
        "\n",
        "print(\"10. 🐛 CONTEXT MISMATCH IN LEARNING\")\n",
        "print(\"    Problem: Learning applied in inappropriate contexts\")\n",
        "print(\"    Symptoms:\")\n",
        "print(\"      • Poor performance despite extensive learning\")\n",
        "print(\"      • Inappropriate action selection\")\n",
        "print(\"      • Context-sensitive failures\")\n",
        "print(\"    Root Causes:\")\n",
        "print(\"      • Insufficient context representation\")\n",
        "print(\"      • Poor context similarity metrics\")\n",
        "print(\"      • Missing context validation\")\n",
        "print(\"    Solutions:\")\n",
        "print(\"      ✅ Rich context representation with multiple dimensions\")\n",
        "print(\"      ✅ Sophisticated context similarity measures\")\n",
        "print(\"      ✅ Context-specific confidence adjustments\")\n",
        "print(\"      ✅ Context validation before pattern application\")\n",
        "print(\"    Code Example:\")\n",
        "print(\"      # Good: Context-aware pattern matching\")\n",
        "print(\"      relevance = self._calculate_pattern_relevance(pattern, context)\")\n",
        "print(\"      if relevance > min_relevance_threshold:\")\n",
        "print(\"          apply_pattern(pattern)\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# DEBUGGING AND TROUBLESHOOTING GUIDE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🔧 DEBUGGING AND TROUBLESHOOTING GUIDE:\")\n",
        "print(\"=\" * 40)\n",
        "print()\n",
        "\n",
        "print(\"🔍 Performance Issues:\")\n",
        "print(\"   Symptom: Slow learning or poor adaptation\")\n",
        "print(\"   Debug Steps:\")\n",
        "print(\"     1. Check memory utilization and pattern count\")\n",
        "print(\"     2. Analyze exploration rate and adaptation frequency\")\n",
        "print(\"     3. Examine pattern confidence distributions\")\n",
        "print(\"     4. Review context similarity calculations\")\n",
        "print(\"   Diagnostic Code:\")\n",
        "print(\"     stats = agent.get_agent_status()\")\n",
        "print(\"     print(f'Patterns: {stats[\\\"learning_progress\\\"][\\\"patterns_discovered\\\"]}')\")\n",
        "print(\"     print(f'Memory: {stats[\\\"learning_progress\\\"][\\\"memory_utilization\\\"]}')\")\n",
        "print()\n",
        "\n",
        "print(\"🔍 Learning Stagnation:\")\n",
        "print(\"   Symptom: No improvement in performance over time\")\n",
        "print(\"   Debug Steps:\")\n",
        "print(\"     1. Check if exploration rate is too low\")\n",
        "print(\"     2. Verify pattern discovery is occurring\")\n",
        "print(\"     3. Examine adaptation trigger frequency\")\n",
        "print(\"     4. Review task diversity and difficulty progression\")\n",
        "print(\"   Diagnostic Code:\")\n",
        "print(\"     trends = visualizer._analyze_performance_trend(agent.task_history)\")\n",
        "print(\"     print(f'Trend: {trends[\\\"overall_trend\\\"]}')\")\n",
        "print(\"     print(f'Improvement: {trends[\\\"improvement_rate\\\"]}')\")\n",
        "print()\n",
        "\n",
        "print(\"🔍 Memory Problems:\")\n",
        "print(\"   Symptom: High memory usage or slow retrieval\")\n",
        "print(\"   Debug Steps:\")\n",
        "print(\"     1. Check experience memory capacity utilization\")\n",
        "print(\"     2. Verify eviction policies are working\")\n",
        "print(\"     3. Examine pattern pruning effectiveness\")\n",
        "print(\"     4. Review indexing performance\")\n",
        "print(\"   Diagnostic Code:\")\n",
        "print(\"     memory_stats = agent.learning_engine.experience_memory.get_statistics()\")\n",
        "print(\"     print(f'Capacity: {memory_stats[\\\"capacity_utilization\\\"]}')\")\n",
        "print(\"     print(f'Patterns: {memory_stats[\\\"patterns_discovered\\\"]}')\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# BEST PRACTICES SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"🌟 BEST PRACTICES SUMMARY:\")\n",
        "print(\"=\" * 40)\n",
        "print()\n",
        "\n",
        "print(\"🎯 Design Principles:\")\n",
        "print(\"   • Start with simple learning objectives and expand gradually\")\n",
        "print(\"   • Implement comprehensive logging and monitoring from the beginning\")\n",
        "print(\"   • Design for adaptability - parameters should be tunable\")\n",
        "print(\"   • Build in multiple learning pathways for robustness\")\n",
        "print(\"   • Plan for scalability with proper indexing and cleanup\")\n",
        "print()\n",
        "\n",
        "print(\"🔄 Implementation Strategy:\")\n",
        "print(\"   • Implement parts sequentially as shown in tutorial structure\")\n",
        "print(\"   • Test each component thoroughly before integration\")\n",
        "print(\"   • Use realistic scenarios for testing and validation\")\n",
        "print(\"   • Monitor performance and adaptation effectiveness continuously\")\n",
        "print(\"   • Implement graceful degradation for component failures\")\n",
        "print()\n",
        "\n",
        "print(\"📊 Monitoring and Maintenance:\")\n",
        "print(\"   • Track learning progress and adaptation patterns\")\n",
        "print(\"   • Monitor memory usage and retrieval performance\")\n",
        "print(\"   • Analyze knowledge sharing effectiveness in multi-agent systems\")\n",
        "print(\"   • Regular pattern quality assessment and cleanup\")\n",
        "print(\"   • Performance trend analysis for early problem detection\")\n",
        "print()\n",
        "\n",
        "print(\"🚀 Ready for Tutorial 13: Error Handling and Recovery!\")\n",
        "print(\"   Next we'll make these learning systems resilient and fault-tolerant!\")\n",
        "print()\n",
        "\n",
        "# =============================================================================\n",
        "# IMPLEMENTATION CHECKLIST\n",
        "# =============================================================================\n",
        "\n",
        "print(\"✅ IMPLEMENTATION CHECKLIST:\")\n",
        "print(\"=\" * 40)\n",
        "print()\n",
        "\n",
        "implementation_checklist = [\n",
        "    \"Foundation Classes (LearningExperience, LearningPattern)\",\n",
        "    \"Experience Memory with indexing and capacity management\",\n",
        "    \"Learning Engine with multiple algorithms\",\n",
        "    \"Adaptive Agent with behavioral evolution\",\n",
        "    \"Multi-Agent Learning System with coordination\",\n",
        "    \"Visualization and Analysis tools\",\n",
        "    \"Memory cleanup and eviction strategies\",\n",
        "    \"Performance monitoring and trend analysis\",\n",
        "    \"Context-aware pattern matching\",\n",
        "    \"Dynamic exploration rate adaptation\",\n",
        "    \"Knowledge transfer validation\",\n",
        "    \"Feedback integration pipeline\",\n",
        "    \"Error handling and graceful degradation\",\n",
        "    \"Scalability considerations and optimization\",\n",
        "    \"Comprehensive testing with realistic scenarios\"\n",
        "]\n",
        "\n",
        "for i, item in enumerate(implementation_checklist, 1):\n",
        "    print(f\"   {i:2d}. {item}\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"🎉 Tutorial 12 Complete - You now have comprehensive\")\n",
        "\n",
        "print(\"   adaptive learning systems that can continuously improve!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTJCroSCEfbG",
        "outputId": "082f0e03-7c0f-463f-d6f1-e228730eb7d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial 12: Learning from Experience - Complete Summary\n",
            "============================================================\n",
            "Comprehensive overview of adaptive learning systems\n",
            "\n",
            "📚 WHAT WE LEARNED:\n",
            "========================================\n",
            "\n",
            "🏗️ 1. FOUNDATION LEARNING FRAMEWORK (Part 1)\n",
            "   Core Concepts Mastered:\n",
            "   • LearningExperience - Individual learning moments with context\n",
            "   • LearningPattern - Extracted knowledge that generalizes\n",
            "   • 5 Learning Types: Supervised, Unsupervised, Reinforcement, Imitation, Transfer\n",
            "   • 5 Experience Types: Success, Failure, Feedback, Observation, Exploration\n",
            "   • 5 Learning Objectives: Accuracy, Efficiency, Quality, Adaptability, Robustness\n",
            "   • Relevance calculation and age tracking for experiences\n",
            "   • Pattern confidence and success rate modeling\n",
            "\n",
            "💾 2. SOPHISTICATED EXPERIENCE MEMORY (Part 2)\n",
            "   Memory Architecture Mastered:\n",
            "   • ExperienceMemory with intelligent indexing systems\n",
            "   • Type-based, context-based, and temporal indexing\n",
            "   • Similarity search with relevance scoring\n",
            "   • Automatic pattern discovery from successful experiences\n",
            "   • Memory capacity management with intelligent eviction\n",
            "   • Statistical analysis of memory utilization\n",
            "   • Context clustering for pattern extraction\n",
            "\n",
            "🎓 3. MULTI-ALGORITHM LEARNING ENGINE (Part 3)\n",
            "   Learning Processing Mastered:\n",
            "   • 5 distinct learning algorithms with different strengths:\n",
            "     - Supervised: Input-output mapping from labeled examples\n",
            "     - Unsupervised: Pattern discovery through clustering\n",
            "     - Reinforcement: Q-learning with reward optimization\n",
            "     - Imitation: Behavior copying from observation\n",
            "     - Transfer: Knowledge adaptation across domains\n",
            "   • Performance baseline tracking and trend analysis\n",
            "   • Learning recommendations based on context relevance\n",
            "   • Feature extraction from diverse input types\n",
            "   • Automatic pattern discovery and consolidation\n",
            "\n",
            "🤖 4. ADAPTIVE AGENTS WITH BEHAVIORAL EVOLUTION (Part 4)\n",
            "   Agent Intelligence Mastered:\n",
            "   • Dynamic action selection (exploration vs exploitation)\n",
            "   • Multi-dimensional performance evaluation:\n",
            "     - Accuracy, efficiency, quality, success metrics\n",
            "   • Domain expertise tracking and development\n",
            "   • Behavioral adaptation based on performance trends:\n",
            "     - Dynamic exploration rate adjustment\n",
            "     - Confidence threshold optimization\n",
            "   • External feedback integration for supervised learning\n",
            "   • Knowledge transfer between related domains\n",
            "   • Observation-based learning from other agents\n",
            "   • Comprehensive status tracking and self-awareness\n",
            "\n",
            "🏫 5. MULTI-AGENT COLLABORATIVE LEARNING (Part 5)\n",
            "   Collective Intelligence Mastered:\n",
            "   • Coordinated learning sessions across agent teams\n",
            "   • Cross-agent observation and imitation learning\n",
            "   • Knowledge consolidation and sharing mechanisms\n",
            "   • Performance improvement tracking in group settings\n",
            "   • Direct knowledge transfer between agents\n",
            "   • Collaboration history and contribution tracking\n",
            "   • System-wide analytics and agent specialization\n",
            "   • Best performer identification and learning propagation\n",
            "\n",
            "📊 6. COMPREHENSIVE VISUALIZATION AND ANALYSIS (Part 6)\n",
            "   Analysis and Insight Mastered:\n",
            "   • Performance trend analysis with time windows\n",
            "   • Learning progress tracking and efficiency measurement\n",
            "   • Expertise development and specialization analysis\n",
            "   • Behavioral adaptation effectiveness evaluation\n",
            "   • Intelligent learning recommendations generation\n",
            "   • Multi-agent system analysis and rankings\n",
            "   • Knowledge sharing health assessment\n",
            "   • Human-readable comprehensive report generation\n",
            "   • Comparative analysis across different learning styles\n",
            "   • System-wide expertise landscape visualization\n",
            "\n",
            "🏛️ KEY ARCHITECTURAL INSIGHTS:\n",
            "========================================\n",
            "\n",
            "🔄 Learning Lifecycle Understanding:\n",
            "   • Experience → Pattern → Knowledge → Action → Performance → Adaptation\n",
            "   • Continuous feedback loops between all components\n",
            "   • Memory consolidation from short-term to long-term patterns\n",
            "   • Multi-modal learning integration for robust knowledge\n",
            "\n",
            "⚖️ Exploration vs Exploitation Balance:\n",
            "   • Dynamic exploration rate based on recent performance\n",
            "   • Higher exploration when performance is poor\n",
            "   • Lower exploration when performance is consistently good\n",
            "   • Context-dependent confidence thresholds\n",
            "\n",
            "🎯 Expertise Development Patterns:\n",
            "   • Domain-specific knowledge accumulation\n",
            "   • Specialization vs generalization trade-offs\n",
            "   • Transfer learning effectiveness between related domains\n",
            "   • Expertise-based action selection improvements\n",
            "\n",
            "🤝 Collaborative Learning Benefits:\n",
            "   • Faster learning through observation of successful agents\n",
            "   • Knowledge sharing reduces individual learning time\n",
            "   • Collective intelligence emerges from agent interactions\n",
            "   • Specialization allows for division of cognitive labor\n",
            "\n",
            "🏭 PRODUCTION IMPLEMENTATION INSIGHTS:\n",
            "========================================\n",
            "\n",
            "📈 Scalability Considerations:\n",
            "   • Memory systems need capacity limits and cleanup strategies\n",
            "   • Pattern discovery should be triggered periodically, not continuously\n",
            "   • Learning recommendations should be cached for performance\n",
            "   • Agent coordination requires efficient communication protocols\n",
            "\n",
            "🔧 Performance Optimization:\n",
            "   • Index-based retrieval for large experience databases\n",
            "   • Batch processing for pattern discovery\n",
            "   • Lazy evaluation of learning recommendations\n",
            "   • Efficient serialization for agent state persistence\n",
            "\n",
            "🛡️ Robustness Requirements:\n",
            "   • Graceful degradation when learning components fail\n",
            "   • Memory overflow protection with intelligent eviction\n",
            "   • Confidence-based decision making to avoid poor choices\n",
            "   • Multiple learning pathways for redundancy\n",
            "\n",
            "⚠️  COMMON ERRORS AND SOLUTIONS:\n",
            "========================================\n",
            "\n",
            "1. 🐛 MEMORY LEAKS AND UNBOUNDED GROWTH\n",
            "   Problem: Learning systems accumulating unlimited experiences\n",
            "   Symptoms:\n",
            "     • Continuously increasing memory usage\n",
            "     • Slower performance over time\n",
            "     • Eventually running out of memory\n",
            "   Root Causes:\n",
            "     • No capacity limits on experience storage\n",
            "     • Missing cleanup of old/irrelevant experiences\n",
            "     • Retaining all patterns regardless of usefulness\n",
            "   Solutions:\n",
            "     ✅ Implement memory capacity limits with intelligent eviction\n",
            "     ✅ Use age-based and relevance-based cleanup strategies\n",
            "     ✅ Periodic pruning of low-confidence patterns\n",
            "     ✅ Background maintenance threads for cleanup\n",
            "   Code Example:\n",
            "     # Good: Capacity-limited memory\n",
            "     if len(self.experiences) > self.capacity:\n",
            "         self._evict_old_experiences()\n",
            "\n",
            "2. 🐛 OVERFITTING TO RECENT EXPERIENCES\n",
            "   Problem: Agent relies too heavily on latest experiences\n",
            "   Symptoms:\n",
            "     • Poor performance when conditions change\n",
            "     • Ignoring valuable historical patterns\n",
            "     • Unstable behavior with high variance\n",
            "   Root Causes:\n",
            "     • Recent experiences weighted too heavily\n",
            "     • No temporal balance in pattern discovery\n",
            "     • Missing confidence decay for old patterns\n",
            "   Solutions:\n",
            "     ✅ Implement balanced temporal weighting\n",
            "     ✅ Use confidence decay for aging patterns\n",
            "     ✅ Ensemble multiple patterns for decisions\n",
            "     ✅ Maintain historical performance baselines\n",
            "   Code Example:\n",
            "     # Good: Balanced temporal weighting\n",
            "     weight = base_weight * math.exp(-age * decay_rate)\n",
            "\n",
            "3. 🐛 EXPLORATION VS EXPLOITATION IMBALANCE\n",
            "   Problem: Too much exploration (inefficient) or too little (stagnation)\n",
            "   Symptoms:\n",
            "     • Consistently poor performance (over-exploration)\n",
            "     • Performance plateau (under-exploration)\n",
            "     • No adaptation to changing conditions\n",
            "   Root Causes:\n",
            "     • Fixed exploration rates regardless of performance\n",
            "     • No adaptation mechanism for exploration\n",
            "     • Missing context-dependent exploration strategies\n",
            "   Solutions:\n",
            "     ✅ Dynamic exploration rate based on recent performance\n",
            "     ✅ Higher exploration when performance is poor\n",
            "     ✅ Context-specific exploration strategies\n",
            "     ✅ Gradual exploration decay as expertise grows\n",
            "   Code Example:\n",
            "     # Good: Adaptive exploration\n",
            "     if recent_success_rate < 0.4:\n",
            "         self.exploration_rate = min(0.3, self.exploration_rate * 1.1)\n",
            "\n",
            "4. 🐛 POOR KNOWLEDGE TRANSFER\n",
            "   Problem: Learned knowledge doesn't apply to new domains\n",
            "   Symptoms:\n",
            "     • No performance benefit from previous learning\n",
            "     • Starting from scratch in related domains\n",
            "     • Isolated expertise with no generalization\n",
            "   Root Causes:\n",
            "     • Too specific pattern extraction\n",
            "     • No abstraction mechanisms\n",
            "     • Missing domain relationship modeling\n",
            "   Solutions:\n",
            "     ✅ Abstract pattern extraction at multiple levels\n",
            "     ✅ Domain similarity assessment for transfer\n",
            "     ✅ Gradual transfer with validation\n",
            "     ✅ Transfer learning confidence tracking\n",
            "   Code Example:\n",
            "     # Good: Validated transfer learning\n",
            "     transfer_factor = domain_similarity * source_confidence\n",
            "     target_expertise = source_expertise * transfer_factor\n",
            "\n",
            "5. 🐛 LEARNING PLATEAU AND STAGNATION\n",
            "   Problem: Agent stops improving after initial gains\n",
            "   Symptoms:\n",
            "     • Flat performance curves after initial learning\n",
            "     • No new pattern discovery\n",
            "     • Repetitive behavior patterns\n",
            "   Root Causes:\n",
            "     • Insufficient exploration in exploitation phase\n",
            "     • No curriculum learning progression\n",
            "     • Missing novelty detection mechanisms\n",
            "   Solutions:\n",
            "     ✅ Curriculum learning with progressive difficulty\n",
            "     ✅ Novelty-based exploration incentives\n",
            "     ✅ Regular parameter adaptation\n",
            "     ✅ Cross-domain learning exposure\n",
            "   Code Example:\n",
            "     # Good: Progressive difficulty curriculum\n",
            "     difficulty = base_difficulty + (task_count / 100) * 0.1\n",
            "\n",
            "6. 🐛 INCONSISTENT FEEDBACK INTEGRATION\n",
            "   Problem: External feedback not properly incorporated\n",
            "   Symptoms:\n",
            "     • No improvement despite feedback\n",
            "     • Conflicting learned patterns\n",
            "     • Ignoring expert corrections\n",
            "   Root Causes:\n",
            "     • Feedback treated same as other experiences\n",
            "     • No feedback quality assessment\n",
            "     • Missing feedback-specific learning paths\n",
            "   Solutions:\n",
            "     ✅ Separate feedback processing pipeline\n",
            "     ✅ Feedback quality and source assessment\n",
            "     ✅ Higher weight for validated feedback\n",
            "     ✅ Feedback contradiction detection\n",
            "   Code Example:\n",
            "     # Good: Weighted feedback processing\n",
            "     if experience.experience_type == ExperienceType.FEEDBACK:\n",
            "         weight *= feedback_importance_multiplier\n",
            "\n",
            "7. 🐛 COORDINATION CONFLICTS IN MULTI-AGENT SYSTEMS\n",
            "   Problem: Agents interfering with each other's learning\n",
            "   Symptoms:\n",
            "     • Degraded performance in group settings\n",
            "     • Conflicting recommendations\n",
            "     • Knowledge sharing failures\n",
            "   Root Causes:\n",
            "     • No coordination protocols\n",
            "     • Conflicting learning objectives\n",
            "     • Resource competition between agents\n",
            "   Solutions:\n",
            "     ✅ Clear coordination protocols and roles\n",
            "     ✅ Conflict resolution mechanisms\n",
            "     ✅ Shared knowledge validation\n",
            "     ✅ Performance-based coordination adjustment\n",
            "   Code Example:\n",
            "     # Good: Conflict-aware coordination\n",
            "     if recommendation_confidence > threshold:\n",
            "         shared_knowledge[pattern_id] = pattern\n",
            "\n",
            "8. 🐛 MEMORY RETRIEVAL PERFORMANCE DEGRADATION\n",
            "   Problem: Learning system becomes slow with accumulated data\n",
            "   Symptoms:\n",
            "     • Increasing response times over time\n",
            "     • High CPU usage during retrieval\n",
            "     • Memory search timeouts\n",
            "   Root Causes:\n",
            "     • Linear search through large memory stores\n",
            "     • No indexing for fast retrieval\n",
            "     • Inefficient similarity calculations\n",
            "   Solutions:\n",
            "     ✅ Multi-level indexing systems\n",
            "     ✅ Approximate similarity search for speed\n",
            "     ✅ Caching of frequent retrieval results\n",
            "     ✅ Background index optimization\n",
            "   Code Example:\n",
            "     # Good: Indexed retrieval\n",
            "     candidates = self.context_index[context_key]\n",
            "     # Instead of searching all experiences\n",
            "\n",
            "9. 🐛 PATTERN DISCOVERY EXPLOSION\n",
            "   Problem: Too many weak patterns cluttering the system\n",
            "   Symptoms:\n",
            "     • Thousands of low-confidence patterns\n",
            "     • Slow pattern matching\n",
            "     • Difficulty finding relevant patterns\n",
            "   Root Causes:\n",
            "     • No minimum confidence thresholds\n",
            "     • Pattern creation from insufficient data\n",
            "     • No pattern pruning mechanisms\n",
            "   Solutions:\n",
            "     ✅ Minimum observation thresholds for pattern creation\n",
            "     ✅ Confidence-based pattern pruning\n",
            "     ✅ Pattern consolidation and merging\n",
            "     ✅ Periodic pattern quality assessment\n",
            "   Code Example:\n",
            "     # Good: Quality-gated pattern creation\n",
            "     if len(group_experiences) >= min_observations:\n",
            "         if pattern_confidence > min_confidence:\n",
            "             create_pattern(group_experiences)\n",
            "\n",
            "10. 🐛 CONTEXT MISMATCH IN LEARNING\n",
            "    Problem: Learning applied in inappropriate contexts\n",
            "    Symptoms:\n",
            "      • Poor performance despite extensive learning\n",
            "      • Inappropriate action selection\n",
            "      • Context-sensitive failures\n",
            "    Root Causes:\n",
            "      • Insufficient context representation\n",
            "      • Poor context similarity metrics\n",
            "      • Missing context validation\n",
            "    Solutions:\n",
            "      ✅ Rich context representation with multiple dimensions\n",
            "      ✅ Sophisticated context similarity measures\n",
            "      ✅ Context-specific confidence adjustments\n",
            "      ✅ Context validation before pattern application\n",
            "    Code Example:\n",
            "      # Good: Context-aware pattern matching\n",
            "      relevance = self._calculate_pattern_relevance(pattern, context)\n",
            "      if relevance > min_relevance_threshold:\n",
            "          apply_pattern(pattern)\n",
            "\n",
            "🔧 DEBUGGING AND TROUBLESHOOTING GUIDE:\n",
            "========================================\n",
            "\n",
            "🔍 Performance Issues:\n",
            "   Symptom: Slow learning or poor adaptation\n",
            "   Debug Steps:\n",
            "     1. Check memory utilization and pattern count\n",
            "     2. Analyze exploration rate and adaptation frequency\n",
            "     3. Examine pattern confidence distributions\n",
            "     4. Review context similarity calculations\n",
            "   Diagnostic Code:\n",
            "     stats = agent.get_agent_status()\n",
            "     print(f'Patterns: {stats[\"learning_progress\"][\"patterns_discovered\"]}')\n",
            "     print(f'Memory: {stats[\"learning_progress\"][\"memory_utilization\"]}')\n",
            "\n",
            "🔍 Learning Stagnation:\n",
            "   Symptom: No improvement in performance over time\n",
            "   Debug Steps:\n",
            "     1. Check if exploration rate is too low\n",
            "     2. Verify pattern discovery is occurring\n",
            "     3. Examine adaptation trigger frequency\n",
            "     4. Review task diversity and difficulty progression\n",
            "   Diagnostic Code:\n",
            "     trends = visualizer._analyze_performance_trend(agent.task_history)\n",
            "     print(f'Trend: {trends[\"overall_trend\"]}')\n",
            "     print(f'Improvement: {trends[\"improvement_rate\"]}')\n",
            "\n",
            "🔍 Memory Problems:\n",
            "   Symptom: High memory usage or slow retrieval\n",
            "   Debug Steps:\n",
            "     1. Check experience memory capacity utilization\n",
            "     2. Verify eviction policies are working\n",
            "     3. Examine pattern pruning effectiveness\n",
            "     4. Review indexing performance\n",
            "   Diagnostic Code:\n",
            "     memory_stats = agent.learning_engine.experience_memory.get_statistics()\n",
            "     print(f'Capacity: {memory_stats[\"capacity_utilization\"]}')\n",
            "     print(f'Patterns: {memory_stats[\"patterns_discovered\"]}')\n",
            "\n",
            "🌟 BEST PRACTICES SUMMARY:\n",
            "========================================\n",
            "\n",
            "🎯 Design Principles:\n",
            "   • Start with simple learning objectives and expand gradually\n",
            "   • Implement comprehensive logging and monitoring from the beginning\n",
            "   • Design for adaptability - parameters should be tunable\n",
            "   • Build in multiple learning pathways for robustness\n",
            "   • Plan for scalability with proper indexing and cleanup\n",
            "\n",
            "🔄 Implementation Strategy:\n",
            "   • Implement parts sequentially as shown in tutorial structure\n",
            "   • Test each component thoroughly before integration\n",
            "   • Use realistic scenarios for testing and validation\n",
            "   • Monitor performance and adaptation effectiveness continuously\n",
            "   • Implement graceful degradation for component failures\n",
            "\n",
            "📊 Monitoring and Maintenance:\n",
            "   • Track learning progress and adaptation patterns\n",
            "   • Monitor memory usage and retrieval performance\n",
            "   • Analyze knowledge sharing effectiveness in multi-agent systems\n",
            "   • Regular pattern quality assessment and cleanup\n",
            "   • Performance trend analysis for early problem detection\n",
            "\n",
            "🚀 Ready for Tutorial 13: Error Handling and Recovery!\n",
            "   Next we'll make these learning systems resilient and fault-tolerant!\n",
            "\n",
            "✅ IMPLEMENTATION CHECKLIST:\n",
            "========================================\n",
            "\n",
            "    1. Foundation Classes (LearningExperience, LearningPattern)\n",
            "    2. Experience Memory with indexing and capacity management\n",
            "    3. Learning Engine with multiple algorithms\n",
            "    4. Adaptive Agent with behavioral evolution\n",
            "    5. Multi-Agent Learning System with coordination\n",
            "    6. Visualization and Analysis tools\n",
            "    7. Memory cleanup and eviction strategies\n",
            "    8. Performance monitoring and trend analysis\n",
            "    9. Context-aware pattern matching\n",
            "   10. Dynamic exploration rate adaptation\n",
            "   11. Knowledge transfer validation\n",
            "   12. Feedback integration pipeline\n",
            "   13. Error handling and graceful degradation\n",
            "   14. Scalability considerations and optimization\n",
            "   15. Comprehensive testing with realistic scenarios\n",
            "\n",
            "🎉 Tutorial 12 Complete - You now have comprehensive\n",
            "   adaptive learning systems that can continuously improve!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Vv5akAe5FlUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}